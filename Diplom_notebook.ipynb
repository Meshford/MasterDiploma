{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950b3649-1d36-494d-a552-6334268d0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363b040a-50e5-44d0-8066-a5733ef70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetric:\n",
    "    def __init__(self,\n",
    "                 monitor: Literal['p', 'qrs', 't', 'all'] = 'all',\n",
    "                 orientation_type: Literal['onset', 'offset', 'all'] = 'all',\n",
    "                 return_type: Literal['precision', 'recall', 'f1', 'confusion_matrix'] = 'confusion_matrix',\n",
    "                 samples=75):\n",
    "\n",
    "        assert monitor in ['p', 'qrs', 't', 'all']\n",
    "        assert orientation_type in ['onset', 'offset', 'all']\n",
    "        assert return_type in ['precision', 'recall', 'f1', 'confusion_matrix']\n",
    "\n",
    "        self.samples = samples\n",
    "        self.monitor = monitor\n",
    "        self.orientation_type = orientation_type\n",
    "        self.return_type = return_type\n",
    "        \n",
    "        self.metric_to_func = {'precision': self.__precision,\n",
    "                               'recall': self.__recall,\n",
    "                               'f1': self.__f1}\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        assert len(y_pred.shape) == 2\n",
    "        \n",
    "        matrix = np.zeros((2, 2), dtype=int)\n",
    "        monitors = ['p', 'qrs', 't'] if self.monitor == 'all' else [self.monitor]\n",
    "        orientations = ['onset', 'offset'] if self.orientation_type == 'all' else [self.orientation_type]\n",
    "        for wave in monitors:\n",
    "            for orientation in orientations:\n",
    "                matrix += self.__handle(y_pred, y_true, wave, orientation)\n",
    "        \n",
    "        if self.return_type == 'confusion_matrix':\n",
    "            return matrix\n",
    "\n",
    "        return self.metric_to_func[self.return_type](matrix[0, 1], matrix[1, 0], matrix[1, 1])\n",
    "\n",
    "    def __handle(self, y_pred, y_true, wave, orientation) -> tuple[int, int, int]:\n",
    "        \n",
    "        index = ['p', 'qrs', 't'].index(wave) + 1\n",
    "        orientation = 2 * ['offset', 'onset'].index(orientation) - 1\n",
    "        y_pred[y_true == 4] = 0\n",
    "\n",
    "        y_true, y_pred = (y_true == index), (y_pred == index)\n",
    "\n",
    "        wave_true = np.logical_and(np.roll(y_true, orientation) != 1, y_true == 1).astype(int)\n",
    "        wave_pred = np.logical_and(np.roll(y_pred, orientation) != 1, y_pred == 1).astype(int)\n",
    "\n",
    "        true_batch, true_indexes = np.where(wave_true == 1)\n",
    "        \n",
    "        tp = fn = 0\n",
    "        \n",
    "        for batch, x in zip(true_batch, true_indexes):\n",
    "            wave = wave_pred[batch][x - self.samples // 2: x + self.samples // 2]\n",
    "            if wave.sum():\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            wave[:] = -1\n",
    "        \n",
    "        fp = (wave_pred[:, self.samples:-self.samples] == 1).sum()\n",
    "        return np.array([[0, fp], [fn, tp]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __precision(fp, fn, tp):\n",
    "        if fp + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __recall(fp, fn, tp):\n",
    "        if fn + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __f1(fp, fn, tp):\n",
    "        precision = SegmentationMetric.__precision(fp, fn, tp)\n",
    "        recall = SegmentationMetric.__recall(fp, fn, tp)\n",
    "        if precision + recall == 0:\n",
    "            return 1\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.monitor}_{self.orientation_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ffa1a9e-6378-4b50-84dc-a912267a40df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.size = torch.Size([2, 12, 5000])\n",
      "signal.size = torch.Size([2, 12, 5000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data_folder, label_folder, max_length=5000):\n",
    "        self.data_files = glob.glob(f'{data_folder}/*.npy')\n",
    "        self.label_files = glob.glob(f'{label_folder}/*.npy')\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_files[idx])\n",
    "        labels = np.load(self.label_files[idx])\n",
    "\n",
    "        # Обрезка данных и меток, если длина превышает max_length\n",
    "        if data.shape[1] > self.max_length:\n",
    "            data = data[:, :self.max_length]\n",
    "            labels = labels[:, :self.max_length]\n",
    "\n",
    "        return torch.from_numpy(data).float(), torch.from_numpy(labels).long()\n",
    "\n",
    "# Использование DataLoader\n",
    "data_folder = '/home/meshalkin/Diplom/ludb/data/signals'\n",
    "label_folder = '/home/meshalkin/Diplom/ludb/data/masks'\n",
    "dataset = SignalDataset(data_folder, label_folder)\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "for i, (signal, label) in enumerate(data_loader):\n",
    "    print(f\"label.size = {label.shape}\")\n",
    "    print(f\"signal.size = {signal.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db80ec24-4b2d-407b-89b2-f79cb945a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 4, 5000])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesSegmentationNet(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes, length):\n",
    "        super(TimeSeriesSegmentationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, num_channels * 8, kernel_size=3, padding=1, groups=num_channels)\n",
    "        self.conv2 = nn.Conv1d(num_channels * 8, num_channels * 16, kernel_size=3, padding=1, groups=num_channels)\n",
    "        self.conv3 = nn.Conv1d(num_channels * 16, num_channels * num_classes, kernel_size=3, padding=1, groups=num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1, num_channels, num_classes)  # изменение формы для выравнивания по каналам и классам\n",
    "        x = x.permute(0, 2, 3, 1)  # Перестановка для получения [batch_size, num_channels, length, num_classes]\n",
    "        return x\n",
    "        \n",
    "# Параметры модели\n",
    "num_channels = 12\n",
    "num_classes = 4\n",
    "length = 5000\n",
    "batch_size = 2\n",
    "\n",
    "# Создание и тестирование модели\n",
    "model = TimeSeriesSegmentationNet(num_channels, num_classes, length)\n",
    "x = torch.randn(batch_size, num_channels, length)\n",
    "output = model(x)\n",
    "print(output.shape)  # Должно быть torch.Size([batch_size, num_channels, length])\n",
    "print(output.dtype)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "199223ef-c246-4df2-8394-4676d41714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.386100938788316\n",
      "Epoch 2/10, Loss: 1.3858506067211513\n",
      "Epoch 3/10, Loss: 1.3858189950218747\n",
      "Epoch 4/10, Loss: 1.3858009195451773\n",
      "Epoch 5/10, Loss: 1.3857999412229065\n",
      "Epoch 6/10, Loss: 1.3858155991848176\n",
      "Epoch 7/10, Loss: 1.3858340090365961\n",
      "Epoch 8/10, Loss: 1.3858852857731099\n",
      "Epoch 9/10, Loss: 1.3859277655151327\n",
      "Epoch 10/10, Loss: 1.3861314238125388\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)  # [batch_size, num_channels, length, num_classes]\n",
    "            outputs = outputs.permute(0, 3, 1, 2)  # [batch, num_classes, num_channels, length]\n",
    "            \n",
    "            # labels должны быть в формате [batch_size, num_channels, length]\n",
    "            # Перестраиваем labels для соответствия ожидаемой размерности CrossEntropyLoss\n",
    "            labels = labels.view(-1)  # Превращаем в одномерный массив\n",
    "\n",
    "            # Так как CrossEntropyLoss ожидает вход в размерности [N, C, d1, d2, ...], где C - количество классов,\n",
    "            # мы должны также изменить размер outputs\n",
    "            outputs = outputs.view(-1, num_classes)  # [N * d1 * d2, C]\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader.dataset)}')\n",
    "    \n",
    "    print('Training complete.')\n",
    "train_model(model, data_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041957bc-c436-47d4-8306-22cba75520ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = SegmentationMetric()\n",
    "\n",
    "# def validate_model(model, valid_loader):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.eval()  # Переключаемся в режим оценки\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():  # Отключаем вычисление градиентов\n",
    "#         for inputs, labels in valid_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             predicted = torch.argmax(outputs, dim=3)  # Получаем предсказанные классы\n",
    "\n",
    "#             # Считаем количество правильных предсказаний\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             total += inputs.size(0) * inputs.size(2) * inputs.size(1)  # Общее количество предсказаний\n",
    "\n",
    "#     accuracy = correct / total\n",
    "#     print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# # Пример использования:\n",
    "# # Создание DataLoader для валидационного набора данных\n",
    "# # valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Проведение валидации\n",
    "# validate_model(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e8403-3764-4a0a-b251-ba6be897cb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6aaae-435c-4c86-9f17-8e2ea9d1df11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
