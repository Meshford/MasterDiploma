{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a9bc94-9e56-45be-8f17-1967b4735b18",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    Министерство науки и высшего образования Российской Федерации<br>\n",
    "    Федеральное государственное автономное образовательное учреждение высшего образования «Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»<br>\n",
    "    <br>\n",
    "    Институт Информационных технологий, математики и механики<br>\n",
    "    <br><br><br>\n",
    "    Выпускная квалифиционная работа магистра<br>\n",
    "    <h1 style=\"text-align: center;\">Исследование влияния различных способов улучшения точности сегментации ЭКГ</h1>\n",
    "</p>\n",
    "<br><br><br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Выполнил:<br>\n",
    "    студент гр. 381803-1<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Мешалкин Н.А.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Проверил:<br>\n",
    "    директор ИИТММ<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Золотых Ю.Н.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br><br>\n",
    "<p style=\"text-align: center\">\n",
    "    Нижний Новгород<br>\n",
    "    2024\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ee604-547d-491f-8e46-4b392d303403",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefc748-69f6-4e31-9531-996e3bbfcd20",
   "metadata": {},
   "source": [
    "**Описание работы:**\n",
    "Данная работа направлена на изучения влияния на точность сегментационных нейросетей различных способов улучшения точности сегментации. В этом исследовании будет рассмотрено несколько вариантов нейросетей с различными внутренними слоями от самых простых до самых сложных. В качестве нейронной сети, результаты которой следует превзойти, представлена сегментационная нейросеть, подготовленная учеными ННГУ. Данная сеть написана на основе популярной сегментационной сети U-Net. Отличие лишь в том, что данная нейросеть адаптирована под 1D сигнал. Также в качестве базы данных была выбрана собственная база данных ЭКГ, собранная сотрудниками ННГУ. В основе этой базы данных лежат сигналы ЭКГ в 12 отведениях 746 пациентов с частотой дискретизации 500 Гц."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419446d8-cb93-4294-8cf9-9fcce472d1a2",
   "metadata": {},
   "source": [
    "**Цель работы:**\n",
    "Необходимо проанализировать влияние на точность нейросети различных внутренних слоев. Провести сравнительный анализ, а также сделать заключение о налиучшем варианте нейронной сети, которая будет показывать наилучшую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fc8da-647d-4044-8e2e-1fafb7913b0a",
   "metadata": {},
   "source": [
    "Данная работа состоит из двух частей: \n",
    "1) Разработка собственной нейросети для сегментации сигналов ЭКГ. Разработка будет разобрана шаг за шагом, чтобы можно было отследить влияние на точность различных внутренних слоев, которые будут постепенно добавляться в нейронную сеть.\n",
    "2) Работа над сегментационной нейросетью от ученых ННГУ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8eb98e-bb96-4663-bd38-93e406ad6c0d",
   "metadata": {},
   "source": [
    "## Часть 1. Разработка собственной нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6a853-1504-49c5-90f3-64c6b0e69f6c",
   "metadata": {},
   "source": [
    "Данный раздел состоит из множества шагов, потому что разработка нейронной сети сложный и трудоемкий процесс. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12ab64-0136-4ebe-acf1-f1ab3649f632",
   "metadata": {},
   "source": [
    "### 1.1 Анализ данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c0746-42dc-4e9a-b475-520c6870e59a",
   "metadata": {},
   "source": [
    "В качестве данных мы используем сигнал ЭКГ в 12 отведениях с частотой дискретизации 500Гц. В первую очередь необходимо посмотреть на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33a81426-acf2-4f0a-a7f0-69e4cb122525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import Module\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.nn.functional as functional\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94c1d760-ab9c-4250-a954-a7fbc7d0bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции, превращающие маску в сегментацию\n",
    "sample_rate = 500\n",
    "v_to_del = {1:'p', 2:'qrs', 3:'t'}\n",
    "\n",
    "def remove_small(signal):\n",
    "    max_dist = 12\n",
    "    last_zero = 0\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 0:\n",
    "            if i - last_zero < max_dist:\n",
    "                signal[last_zero:i] = 0\n",
    "            last_zero = i\n",
    "\n",
    "def merge_small(signal):\n",
    "    max_dist = 12\n",
    "    lasts = np.full(signal.max() + 1, -(max_dist+1))\n",
    "    for i in range(len(signal)):\n",
    "        m = signal[i]\n",
    "        if i - lasts[m] < max_dist and m > 0:\n",
    "            signal[lasts[m]:i] = m\n",
    "        lasts[m] = i\n",
    "\n",
    "def mask_to_delineation(mask):\n",
    "    merge_small(mask)\n",
    "    remove_small(mask)\n",
    "    delineation = {'p':[], 'qrs':[], 't':[]}\n",
    "    i = 0\n",
    "    mask_length = len(mask)\n",
    "    while i < mask_length:\n",
    "        v = mask[i]\n",
    "        if v > 0:\n",
    "            delineation[v_to_del[v]].append([i, 0])\n",
    "            while i < mask_length and mask[i] == v:\n",
    "                delineation[v_to_del[v]][-1][1] = i\n",
    "                i += 1\n",
    "            t = delineation[v_to_del[v]][-1]\n",
    "        i += 1\n",
    "    return delineation\n",
    "\n",
    "wave_type_to_color = {\n",
    "    \"p\": \"yellow\",\n",
    "    \"qrs\": \"red\",\n",
    "    \"t\": \"green\"\n",
    "}\n",
    "\n",
    "def plot_signal_with_mask(signal, mask):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.title(\"Сигнал с маской\")\n",
    "    plt.xlabel(\"Время (сек)\")\n",
    "    plt.ylabel(\"Амплитуда (мВ)\")\n",
    "    x_axis_values = np.linspace(0, len(signal) / sample_rate, len(signal))\n",
    "    plt.plot(x_axis_values, signal, linewidth=2, color=\"black\")\n",
    "    \n",
    "    delineation = mask_to_delineation(mask)\n",
    "    for wave_type in [\"p\", \"qrs\", \"t\"]:\n",
    "        color = wave_type_to_color[wave_type]\n",
    "        for begin, end in delineation[wave_type]:\n",
    "            begin /= sample_rate\n",
    "            end /= sample_rate\n",
    "            plt.axvspan(begin, end, facecolor=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "950b3649-1d36-494d-a552-6334268d0d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABcUAAAHWCAYAAAC2WuEzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeZgcVdk+/ru7Z59MJvtkJQt7hBAICGEV3yiogCiyKAoGDP7AiBBFjL4QgVdB9kVkiQRQ2VFAvuwGwiKJgYQYyEr2dSYzSWZfeqa7fn90qvpUd1V1VS9V1afuz3Vx0dPTM6lwOFXnPOc5zwkpiqKAiIiIiIiIiIiIiCgAwl5fABERERERERERERGRWxgUJyIiIiIiIiIiIqLAYFCciIiIiIiIiIiIiAKDQXEiIiIiIiIiIiIiCgwGxYmIiIiIiIiIiIgoMBgUJyIiIiIiIiIiIqLAYFCciIiIiIiIiIiIiAKDQXEiIiIiIiIiIiIiCgwGxYmIiIiIiIiIiIgoMBgUJyIiIiKiQPrjH/+I5uZm7eu7774bHR0d3l0QEREREbmCQXEiIiIikt769evx4x//GBMmTEBFRQX69++PE044Affccw+6urq8vjzyyMsvv4zf/va32Lp1K5544glcd911qKys9PqyiIiIiKjAQoqiKF5fBBERERFRobzyyis499xzUV5ejosuugiHHXYYotEoPvjgA/z973/HD3/4Qzz88MNeXyZ54N1338VZZ52F1tZWhMNh3HHHHbjqqqu8viwiIiIiKjAGxYmIiIhIWhs3bsSkSZMwevRovP322xgxYoTu++vWrcMrr7yCn/3sZx5dIXmtubkZq1atwpgxYzB69GivL4eIiIiIXMDyKUREREQkrVtvvRXt7e145JFH0gLiAHDAAQfoAuKhUAi//e1vdZ+57bbbEAqF8KUvfUl7b8GCBQiFQob/fPDBBwCA3/72twiFQmhqatL9vo8//hihUAiPPfaY9t7y5cvxwx/+UCvvMnz4cFxyySXYvXu34d9r3Lhxhn/2ggULMv43Wb16Nc477zwMHToUlZWVOPjgg/Gb3/zG8mfEv++yZct039u+fTsikQhCoRCef/75rP5O27dvx6WXXoqRI0eivLwc48ePx+WXX45oNAoAeOyxxxAKhbBp0ybtZ1asWIGBAwfijDPOQF9fn/b+hg0bcO6552LQoEGoqqrCcccdh1deecXw77NgwQIMGDAAU6dOxejRo/GNb3zD8P8BIiIiIpJLidcXQERERERUKC+//DImTJiA448/Pqufb25uxs0332z6/SuvvBLHHHOM7r2DDz7Y8Z/z1ltvYcOGDZg+fTqGDx+OFStW4OGHH8aKFSuwaNEihEKhtJ856aSTcNlllwEAVq1ahd///vcZ/5zly5fjpJNOQmlpKS677DKMGzcO69evx8svv4zf/e53GX++oqICjz76KO655x7tvccffxxlZWXo7u7O6u+0Y8cOfPGLX0RzczMuu+wyHHLIIdi+fTuef/55dHZ2oqysLO06tm7ditNPPx2HHHIInn32WZSUJKY1DQ0NOP7449HZ2Ykrr7wSgwcPxuOPP46zzjoLzz//PL71rW+Z/t3ee+89vPrqqxn/GxARERFR8WNQnIiIiIik1Nraiu3bt+Ob3/xm1r/j5ptvRmlpKaZMmWL4/ZNOOgnf+c53sv79qiuuuAI///nPde8dd9xx+O53v4sPPvgAJ510ku57fX19OOCAA/D9738fQCLz2U5Q/Kc//SkURcHSpUux3377ae/fcssttq7zW9/6Fp544gncdtttWrD6sccew7e//W08+eSTWf2dZs+ejfr6evznP//B0UcfrX32xhtvhFGlx7179+L0009HdXU1/t//+3+oqqrS/T0aGhrw/vvv48QTTwQAzJgxA5MmTcKsWbPwzW9+E+Gw8WbZX/7yl/ja176G1157zdZ/CyIiIiIqXiyfQkRERERSam1tBQDU1NRk9fPbt2/Hfffdh+uuuw79+vXL+jr27NmDpqYm7Z+Wlpa0z1RWVmqvu7u70dTUhOOOOw4AsHTp0rTPR6NRlJeXO7qOxsZGvPfee7jkkkt0AXEAhpnoRs4880yEQiH885//BAC8//772LZtG84///y0z9r5O8Xjcbz44os488wzdQFxs+vq7u7GWWedhcbGRrz++usYPHiw7vuvvvoqvvjFL2oBcQDo168fLrvsMmzatAkrV640/Hv94x//wEcffWR7cYCIiIiIihuD4kREREQkpf79+wMA2trasvr5OXPmYOTIkfjxj3+c03UcfPDBGDp0qPbPtGnT0j6zZ88e/OxnP0NdXR0qKysxdOhQjB8/HgAMg+gtLS2OA/UbNmwAABx22GFZ/C0SSktL8f3vfx/z5s0DAMybNw/nnHOO9t9aZOfv1NjYiNbWVtvXNH36dHzwwQdoa2vT1RFXbd682bB8zaGHHqp9P1UsFsOvf/1rXHjhhZg0aZKt6yAiIiKi4sbyKUREREQkpf79+2PkyJH47LPPHP/sqlWr8Nhjj+Fvf/sbSktLc7qOv//977qg8dq1a/GTn/xE95nzzjsPH374Ia655hpMnjwZ/fr1Qzwex+mnn454PK777J49exCNRjF8+PCcritbl1xyCY488kisWbMGzz33nJY1nsrJ38mupUuX4qWXXsLMmTNx2WWX4e23387lrwIAeOSRR7Bp0ya88cYbOf8uIiIiIioODIoTERERkbTOOOMMPPzww1i4cCGmTp1q++dmz56NyZMnG5YFcerkk0/GkCFDtK8HDBig+/7evXsxf/583HDDDbj++uu19z///HPD36eWAFGzn+2aMGECAGS1SCA6/PDDceSRR+K8887D0KFDceqpp+Ldd9/Vfcbu32no0KHo37+/7Wv685//jLPOOguRSARnnHEGHnnkEVx66aXa98eOHYs1a9ak/dzq1au174s6Oztxww034Iorrkj7HhERERHJi+VTiIiIiEhav/zlL1FdXY0f/ehHaGhoSPv++vXrcc899+jeW7hwIV566SXccssttmtt5yISiQBA2qGSd999t+Hnn376aZSVlenqZtsxdOhQnHzyyZg3bx62bNmi+57RgZZWLrnkEixfvhw//OEPDf8b2f07hcNhnH322Xj55Zfx8ccfp/2e1J9XD+f8xje+gQsuuADXXHONrl2//vWvY/HixVi4cKH2XkdHBx5++GGMGzcOEydO1P2+e+65Bx0dHfjNb35j429NRERERLJgpjgRERERSWv//ffHk08+ifPPPx+HHnooLrroIhx22GGIRqP48MMP8dxzz+GHP/yh7mfefPNNfOUrXzGs/V0I/fv3x8knn4xbb70Vvb29GDVqFN58801s3LhR97nPP/8cc+bMwVNPPYVf/epXhnW8M7n33ntx4okn4qijjsJll12G8ePHY9OmTXjllVewbNky279nxowZOPfcc1FbW5vT3wkAfv/73+PNN9/EKaecgssuuwyHHnoodu7cieeeew4ffPBBWma96p577sGhhx6Kn/70p3j22WcBAL/61a/w1FNP4Wtf+xquvPJKDBo0CI8//jg2btyIv//97wiH9TlBb775Jn73u9+lHdhJRERERHJjUJyIiIiIpHbWWWdh+fLluO222/DSSy/hgQceQHl5OSZNmoQ77rgDM2bM0H0+FArhlltucfUan3zySfz0pz/F/fffD0VR8NWvfhWvvfYaRo4cqX1myZIl+PTTT3HPPffgpz/9aVZ/zhFHHIFFixbhuuuuwwMPPIDu7m6MHTsW5513nqPfU1JSoisJk+3fCQBGjRqF//znP7juuuvwxBNPoLW1FaNGjcLXvvY1VFVVmf7+YcOG4a677sLFF1+Ml19+GWeeeSbq6urw4Ycf4tprr8V9992H7u5uTJo0CS+//DK+8Y1vpP2OESNG4KqrrnL0dyciIiKi4hdSnO6VJCIiIiIiIiIiIiIqUqwpTkRERERERERERESBwaA4EREREREREREREQUGg+JEREREREREREREFBgMihMRERERERERERFRYBRdUPz+++/HuHHjUFFRgWOPPRaLFy+2/HxzczN+8pOfYMSIESgvL8dBBx2EV1991aWrJSIiIiIiIiIiIiI/KfH6Apx45plnMGvWLDz44IM49thjcffdd+O0007DmjVrMGzYsLTPR6NRfOUrX8GwYcPw/PPPY9SoUdi8eTMGDBjg/sUTERERERERERERkedCiqIoXl+EXcceeyyOOeYY/PGPfwQAxONxjBkzBj/96U/xq1/9Ku3zDz74IG677TasXr0apaWlWf2Z8XgcO3bsQE1NDUKhUE7XT0RERERERERERESFoSgK2traMHLkSITD5kVSiiYoHo1GUVVVheeffx5nn3229v7FF1+M5uZmvPTSS2k/8/Wvfx2DBg1CVVUVXnrpJQwdOhTf+973cO211yISiRj+OT09Pejp6dG+3r59OyZOnJj3vw8RERERERERERER5d/WrVsxevRo0+8XTfmUpqYmxGIx1NXV6d6vq6vD6tWrDX9mw4YNePvtt3HhhRfi1Vdfxbp163DFFVegt7cXc+bMMfyZm2++GTfccEPa+1u3bkX//v1z/4uQuZtvtve52bNz/6Pet/lnOTT7pNyvzXvZ/Lcx+XvbbVMg53YtVJsCQW5XIK1tXWxTgH3VXC7/XXJoU8DX7QoEtW0N/s7sqz7F9hWxfVVs4+Lk9L+Zt+3MZ69dxdmP2b5GPGpLwLf35eJty0yKc65LhdPa2ooxY8agpqbG8nNFExTPRjwex7Bhw/Dwww8jEolgypQp2L59O2677TbToPjs2bMxa9Ys7Wv1P2T//v0ZFC+08nJ7n8tDO5RX2/yzHJLj/5Fs/tuY/L3ttimQc7sWqk2BILcrkNa2LrYpwL5qLpf/Ljm0KeDrdgWC2rYGf2f2VZ9i+4rYviq2cXFy+t/M23bms9eu4uzHbF8jHrUl4Nv7cvG2ZSbFOdelwstUBrtoguJDhgxBJBJBQ0OD7v2GhgYMHz7c8GdGjBiB0tJSXamUQw89FPX19YhGoygrK0v7mfLycpQ7veERERERERERERERUVEwrzbuM2VlZZgyZQrmz5+vvRePxzF//nxMnTrV8GdOOOEErFu3DvF4XHtv7dq1GDFihGFAnIiIiIiIiIiIiIjkVjRBcQCYNWsW5s6di8cffxyrVq3C5Zdfjo6ODkyfPh0AcNFFF2G2UNfn8ssvx549e/Czn/0Ma9euxSuvvILf//73+MlPfuLVX4GIiIiIiIiIiIiIPFQ05VMA4Pzzz0djYyOuv/561NfXY/LkyXj99de1wze3bNmCcDgZ5x8zZgzeeOMNXH311Zg0aRJGjRqFn/3sZ7j22mu9+isQERERERERERERkYeKKigOADNnzsTMmTMNv7dgwYK096ZOnYpFixYV+KqIiIiIiIiIiIiIqBgUVfkUIiIiIiIiIiIiIqJcMChORERERERERERERIHBoDgRERERERERERERBQaD4kREREREREREREQUGAyKExEREREREREREVFgMChORERERERERERERIHBoDgRERERERERERERBQaD4kRERERERERERBl09fais7fX68sgojxgUJyIiIiIiIiIiMjCjrY2jL7rLoy84w5sbm72+nKIKEcMihMREREREREREVmYPX8+9nR1oaWnBz959VWvL4eIcsSgOBERERERERERkYWdbW3a643MFCcqegyKExERERERERERWSiLRLTX0VjMwyshonxgUJyIiIiIiIiIiMhCqRAU72VQnKjoMShORERERERERERkoTScDKH1xuMeXgkR5QOD4kRERERERERERBZKhKB4H4PiREWPQXEiIiIiIiIiIiILcUXRXkdCIQ+vhIjygUFxIiIiIiIiIiIiC2J2eCTMcBpRsWMvJiIiIiIiIiIishBjpjiRVBgUJyIiIiIiIiIisqAIQfEQg+JERY9BcSIiIiIiIiIiIgtiIFwMkBNRcWJQnIiIiIiIiIiIyIKYG86QOFHxY1CciIiIiIiIiIjIAjPFieTCoDgREREREREREZEFMRAeZ1CcqOgxKE5ERERERERERGQhJgTCGRInKn4MihMREREREREREVmIxePaa5ZPISp+DIoTERERERERERFZYKY4kVwYFCciIiIiIiIiIrLATHEiuTAoTkREREREREREZIGZ4kRyYVCciIiIiIiIiIjIgpgpHmemOFHRY1CciIiIiIiIiIjIgi5TnEFxoqLHoDgREREREREREZEFXU1xD6+DiPKDQXEiIiIiIiIiIiILMWaHE0mFQXEiIiIiIiIiIiILrClOJBcGxYmIiIiIiIiIiCyImeJigJyIihOD4kREREREREREBfDR9u249d//RmNHh9eXQjlipjiRXEq8vgAiIiIiIiIiItn09PXhi3/+MwBgyc6deOY73/H4iigXukxxBsWJih4zxYmIiIiIiIiI8mx7W5v2+tkVKzy8EsoHZooTyYVBcSIiIiIiIiKiPOuIRr2+BMoj1hQnkguD4kREREREREREeba3u9vrS6A8YqY4kVwYFCciIiIiIiIiyrNmBsWlImaKKwAUBsaJihqD4kREREREREREeRaNxby+BMqj1OxwZosTFbeiC4rff//9GDduHCoqKnDsscdi8eLFpp997LHHEAqFdP9UVFS4eLVEREREREREFES9DIpLJTUIHmNQnKioFVVQ/JlnnsGsWbMwZ84cLF26FEcccQROO+007Nq1y/Rn+vfvj507d2r/bN682cUrJiIiIiIiIqIg6ks5jJHlNoobM8WDo6u3F529vV5fBhVYUQXF77zzTsyYMQPTp0/HxIkT8eCDD6Kqqgrz5s0z/ZlQKIThw4dr/9TV1bl4xUREcoorCl5YtQrvc6GRiIiIiMhQb0pQPDVITsWFQfFg2N7ainH33INRd96Jxdu3e305VEBFExSPRqNYsmQJpk2bpr0XDocxbdo0LFy40PTn2tvbMXbsWIwZMwbf/OY3sWLFCss/p6enB62trbp/iIhI77kVK/DtZ5/FyY89hjVNTV5fDhERERGR76QGwVljvLillU/hIoeU5m/ciF0dHWju7sZZTz3l9eVQARVNULypqQmxWCwt07uurg719fWGP3PwwQdj3rx5eOmll/C3v/0N8Xgcxx9/PLZt22b659x8882ora3V/hkzZkxe/x5ERDK46MUXtdd3LVrk3YUQEREREflUak3x1MxxKi6p5W+YKS6n+vZ27XVDR4eHV0KFVjRB8WxMnToVF110ESZPnoxTTjkF//jHPzB06FA89NBDpj8ze/ZstLS0aP9s3brVxSsmIioO4oAw5OF1EBERERH5VWqmOA/eLG48aDMYwiHOcIOixOsLsGvIkCGIRCJoaGjQvd/Q0IDhw4fb+h2lpaU48sgjsW7dOtPPlJeXo7y8PKdrJSIKkhAHDUREREREaVIzw5kpXtxYU5xILkWTKV5WVoYpU6Zg/vz52nvxeBzz58/H1KlTbf2OWCyGTz/9FCNGjCjUZRIRBYI4/GNInIiIiIgoHTPF5cKa4kRyKZqgOADMmjULc+fOxeOPP45Vq1bh8ssvR0dHB6ZPnw4AuOiiizB79mzt8zfeeCPefPNNbNiwAUuXLsX3v/99bN68GT/60Y+8+itQBm09PfjnmjVo7u72+lKIyII4IGSmOBERERFROtYUlwszxYOB7RocRVM+BQDOP/98NDY24vrrr0d9fT0mT56M119/XTt8c8uWLQiHk3H+vXv3YsaMGaivr8fAgQMxZcoUfPjhh5g4caJXfwXK4NznnsMb69fjjIMOwsvf/a7Xl0NEJlhTnIiIiIjIGjPF5cKa4sEQZT8NjKIKigPAzJkzMXPmTMPvLViwQPf1XXfdhbvuusuFq6J8eWP9egDA/1u7Fp29vagqLfX4iojISDgU0gaBHAoSEREREaVjTXG5MFM8GLh4FRxFVT6FgmVnW5vXl0B5oCgKLnv5ZRwzdy5WNTZ6fTmUJyXCrhzW0pPHOxs34qlPP03LaiIiIiIi55gpLhcGxYOBmeLBUXSZ4hQcXEWXw7ubN2Pu0qUAgHOefRYrf/ITj6+I8kGsI86hoBxW7NqFL//lL9rX3z38cA+vhvIpGouhNBxm/X8iIiKXsaa4XHjQZjCwnwYHM8XJt7g6J4f1e/Zor1c1NXl4JZRPYmiNGRJyuOXf/9Zez3ztNQ+vhPJp0bZtqLv9dkx95BHuACAiInJZas1pPouLGzPFg4GxqOBgUJx8Q0l5oHBrmRyYmSgntqt86tvbtdeDKys9vBLKpx+++CKau7vxn+3b8df//tfryyEiIgoUZhbLQ1GUtB2yPGhTToxFBQeD4uQbqavmXJ2TQ5jBUymJ7coMCTmI9+BKHnIsjTW7d2uvP9u1y8MrISIiCp60oDjHzUXLqOU4D5ITd3QEB4Pi5Bs8mVtODIrLSWxVDhrkwMNT5dS/vFx7vbury8MrISIiCh5misvDKADO9pQTFzuCg0Fx8o3ULSrMFJcDtx7JSVzsYMaLHCJsUylxYZKIyP/+vnIlxt19N2754AOvL4XyLDVoyjFW8TIKlDJ4Kif20+BgUJx8IzUIzmCqHDp7e72+BCoAsaY4M8XlEGGmuJRSz+sgIiL/+c5zz2FzSwtmz5/PZ7BkmCkuD8NMcY6zpMTFjuBgUJx8g+VT5NTDxQ3pcXAvB2aKy48H5BIR+d+ujg6vL4HyKHWUzDFW8WKmeHCwXYODQXHyDZZPkROziOUUZqa4dMRMce7UkQeH9ERExWVHW5vXl0B5xExxeTAoHhxs1+BgUJx8g+VT5MSBn5zEfFNmvMhBbFNmFBMREXmjPRr1+hIoj9KC4hw3Fy0etBkcqW3NILm8GBQn30jNNmWmuByYRSwn3UGbbGMpiIM9hsTlxHYlIvI/zoHkknbQJsfNRYuZ4sHBHR7BwaA4+UbqjYfBVDkwG0JOPGhTPmI7hpkpLiXej+W0qbmZmaVEEuG5SnJhprg8eNBmcLDfBgeD4uQbvPHIiQFTObF8inzEvsryKXJiWTL5vLh6Ncbfcw8Ouu8+dPX2en05VAB/X7kSB913H+5ZtMjrSyGX8F4tF2acykNhpnhgsN8GB4Pi5BupgTUGU+XAB4icmCkun15miktJbEtuyZfPt555BgCws70dL61Z4/HVUCF857nn8PmePbjqjTe8vhRyCTPF5cLEL3mwpnhwpPZT9lt5MShOvsHVODkxYConXaY421gKYmYaQ+LyiDAoHhhczJIfMxLllJp9ykxxuXCOKw/WFA8O9tvgYFCcfIOr6HJiO8opzExx6fSyfIqUSsLJoR6D4nLrV1bm9SVQgXX39Xl9CVQAqZnhzBSXCzNO5cGa4sHB2FRwMChOvsHVODkxYCo/DhLkIPZVZr3IQ1zgYF+VG8dN8utk3XgppS5YcgFTLpzjyoOZ4sHBfhscDIqTb6TeaDh5lwOD4nIS+ycHCXIQB3/st/IQc/7ZrnLrYSBNOqnBUQbF5ZQ6jmL5FLkw41QeDIoHB/ttcDAoTr7B1Tg5pbYjBw5yYABVPnEudEhJlynOdpVaD0trSKcjGrX8muSQOjZm+RS5pLYv50LFiwdtBgdjU8HBoDj5Blfj5NTHB4qUdAFU9lUpsE3lFGb5lMBgvWn5pC46dzBTXEqp92ZmisuFwTV5MFM8OBibCg4Gxck3Um88zD6VQ+rAj+0qB2aKy4dtKieF7RoYLJ8iHwZLg4GZ4nJjiVB58KDN4Ejrt7wvS4tBcfKNtJO5eeORQmoQhgMHObDUhnzYpnJiuwYHy6fIhwkjwcCa4nJjprg8mCkeHMwUDw4Gxck3eOORU2o7ckInB2YVy4dtKieWxQmO1EMZqfhxt10wcPFDbpzjyoM1xYODi1nBwaA4+QZvPHJKyxRnu0pBbEcO7uXANpUTFzuCg/1WPgyWBgODpnLjHFcezBQPDt6Xg4NBcfIN3njkxDp6cmJJBvkweCon9tXgYPvKh0HxYGAJSblxjisP1hQPDi5mBQeD4uQbPMxATqkTOE7o5MAAqnwYPJWTOFnjxE1uvBfLhyXogoFBU7lx0UMezBQPDt6Xg4NBcfIN3njkxFVWObFOsXy40CEntmtw8F4sH2aKB0Pq2JhBNrlwjisP1hQPDsYwgoNBcfINDvzlxHaVEwNt8hHbVAGgcNImBe4ACA62r3xYgi4YGHyRG9tXHswUD460HR5sZ2kxKE6+wQGDnJgdIScG2uTDvion7uoIDi5QyoeJBcHA56/c2L7yYFA8OBibCg4Gxck3uBonJ9bDlI+iKBBblW0qB/ZVOYmDeLap3Dhukg/vy8HAmtNyY3BNHjxoMzi4mBUcDIqTb/DGIycOBOXDvion9lU5cVdHcDBgKh9migcDx1VyYxkkeTBTPDg4LwoOBsXJN3jjkRMndPJhX5UT+6qcWD4lOHgvlk9qm/K+LCeOq+TG9pUHg+LBwcXK4GBQnHyDNx45sV3lY9SmPJSx+LGvyomH4gYH+6x8uFgZDMwklhvHV/IwajkGxeXExazgYFCcfIM3Hjkxy0k+zJKQE4Mv8kmt/8/nqlxSFyPZZ+XDmuLBwKCp3DjHlQfnQMHB+3JwMChOvsHgqZw4EJSP0aCA/bX4sa/KhwN6uaW2JttXPlysDAYetCm3tPblvbpoMSgeHGk7eHhflhaD4uQbnLzLiRM6+fDkdTlxYVI+vP/KjX1WfuzDwcA5kNzYvvJgUDw42G+Dg0Fx8g1mKcqJDxT5GA3+OFEvfuyr8uFzVW5sX/lx4SMY2JflxvaVB4PiwcF+GxwMipNvMCAjJ9bDlA8HhHLi4E8+qW2qGLxHxYtb8uXHTPFg4EGbcuMcVx6cAwUH+21wMChOvsF6enJioE0+huVT2K5Fj8EX+RgN4NlX5cE+Kz8mFgQDx8pyY/vKg0Hx4GC/DQ4Gxck3uBonJ07a5cMBoZx4D5YP6//LjYdAyY9jqGDgrg+5cSeAPDgHCg7Oi4KDQXHyDa7GyYkPFPkY9U0OCIsfgy/yYf1/ufH5Kj8ufAQD50ByY/vKg0Hx4GC/DY6iC4rff//9GDduHCoqKnDsscdi8eLFtn7u6aefRigUwtlnn13YC6SsMSAjJ7arfJh9Kh9FUZDaghz8FT+WOpIbS2vIj2OoYOACl9zYvvJgUDw4uIMnOIoqKP7MM89g1qxZmDNnDpYuXYojjjgCp512Gnbt2mX5c5s2bcIvfvELnHTSSS5dKWWDW8vkxCwn+XBAKB9mFMuJC1hyYxaT/LjwEQwcK8uN92p5cA4UHOy3wVFUQfE777wTM2bMwPTp0zFx4kQ8+OCDqKqqwrx580x/JhaL4cILL8QNN9yACRMmuHi15BRvPHJilpN8OCCUD4OncjJ6jvIeLI/U9mXbyodjqGBgJrHc2L7y4BwoONhvg6NoguLRaBRLlizBtGnTtPfC4TCmTZuGhQsXmv7cjTfeiGHDhuHSSy+19ef09PSgtbVV9w+5gzceOaW2KwcOxY8lGeTDTHE5sa/KjeMm+XHhIxiYGCS3tDIMbN+ixaB4cPC+HBxFExRvampCLBZDXV2d7v26ujrU19cb/swHH3yARx55BHPnzrX959x8882ora3V/hkzZkxO10328cYjJwbF5WMUeGG7FjcGT+XEHQByY6BFfswUDwbWrpUb50LyYFA8OJh4EBxFExR3qq2tDT/4wQ8wd+5cDBkyxPbPzZ49Gy0tLdo/W7duLeBVkogDQjmxXeXDAaF8mCkuJ7ar3BgwlV9aG/NZKyUmBsmNQXF5cA4UHLwvB0eJ1xdg15AhQxCJRNDQ0KB7v6GhAcOHD0/7/Pr167Fp0yaceeaZ2nvxff8jl5SUYM2aNdh///3Tfq68vBzl5eV5vnqyg5M7OXEgKB9mn8qH2f9yMmpXDurlwQPK5ceDNoOBfVluzDiVB4PiwcEYRnAUTaZ4WVkZpkyZgvnz52vvxeNxzJ8/H1OnTk37/CGHHIJPP/0Uy5Yt0/4566yzcOqpp2LZsmUsi+JDXI2TEx8o8uGAUD5sUzlxAUtuTCaQH9s4GDgHkhvnQvLgeDk42G+Do2gyxQFg1qxZuPjii3H00Ufji1/8Iu6++250dHRg+vTpAICLLroIo0aNws0334yKigocdthhup8fMGAAAKS9T/7AVXQ5caAvHw4I5cM2lRPLp8iNNcXlx4M2g4FzILml9mOOr4oXx8vBwX4bHEUVFD///PPR2NiI66+/HvX19Zg8eTJef/117fDNLVu2IBwumuR3SpG2dZADfylwlVU+PJRRPswolhP7qtwYSJMfM8WDIbXvcqwsFyYIyYNB8WBQFAWprcp2lldRBcUBYObMmZg5c6bh9xYsWGD5s4899lj+L4jyhpM7OXGVVT5Gg3m2a3HjIF9OXOyQGwOm8mNN8WBg0FReDK7JhePlYDBqUbazvJhWTb7BAaGcuNghHw4I5cM2lZPRc5RBNXlwh538uPARDBwry8uoJdm+xUvheDkQOC8KFgbFyTdYZkNObFf5MPtUPiyzISe2q9wYSJMfFz6Cge0sLwbX5ML2DAa2c7AwKE6+weCpnNiu8uFAQT4siSMnLmDJjaU15McxVDBwgUteHF/JhXOgYGA7BwuD4uQbPGRGTqntyuyX4seBgnzYpnJiu8qNZefklzaGYv+VEsfK8uKOLblwXBUMbOdgYVCcfINZEnJilpN8jPomB/jFjRnFcmJflVtqWzJTXD4cQwUD50DyYnBNLmzPYOAOj2BhUJx8gwN/ObFd5cMBoXzYpnJiu8qNgTT5cTdAMLCd5cXnsFzYnsHAdg4WBsXJNxg8lRMn7fLhQEE+bFM5sV3lxpIL8kttU/ZfOaUdtMl2lgZ34smF46pgYL8NFgbFyTc48JcTFzvkw4GCfFjzUk6cvMkttS1ZPkU+TCwIBmaKy8uoz/I5XLw4rgoGtnOwMChOvsHgqXz4QJET21U+nLTJiQtYcmN2qfy4GyAYeKCqvDhmlgvbMxjYzsHCoDj5BoPi8mH2qZw4UJAP21ROPChIbhw3yY9tHAzMFJcX50Jy4Xg5GNjOwcKgOPkGB4Ty4QNFTkZ9k/21uDGjWE68B8uNWcTy426AYGCZHHnxOSwXtmcwsJ2DhUFx8o3UASBvPMWPgTY5caAgH7apnNiucmMWsfzYxsGQtvjBBS5p8DksF7ZnMLCsZLAwKE6+wYG/fLh1X05c7JAPB/ly4rZtuaW2pQJAYb+VCncDBAMzxeVluLuS7Vu0OF4OBrZzsDAoTr6ReqPh5K748YEiJ7arfBg8lRP7qtzYvvJjwkgwGLUz50By4H1aLmzPYGA7BwuD4uQbRjca3nqKGwNtcuJAQT7c1SEnbv+UG9tXfqwpHgxG7cqWlgPHzHJhewYD2zlYGBQn3zAaEDKAWtz4QJETFzvkw74qJ7ar3FjKSn7MFA8GjqvkxbaVC8dVwcB2DhYGxck3ePORD9tUTsxOlA/7qpwYNJUbd3jIL63WNINpUmJflhfHV3JhewYD2zlYGBQn3+DNRz6G2f9s06LHviofBk/lxL4qN2Ygyi/1Psz+Kyc+g+XFuZBcOK4KBt6Tg4VBcfINPmTkwzaVEwcK8mFflROzD+XGXTvyS8sUZ/tKic9gebFt5cL2DAaOn4OFQXHyDT5k5MM2lRPbVT5sUzkxk1hu7LfySztok/1XSjxXSV68T8uF7RkMbOdgYVCcfIMrcvJhQEZOHCjIhxNyObGvys2ojzKTWC48aDMYuANPXpwLycWoV/K+LB+On4OFQXHyDQ4I5WO40OHBdVB+GQZiOMAvahz8yYntKje2r/xSx8EcF8uJiUHyMmpHBYDC9i1KfO4GA9s5WBgUJ9/gzUc+bFM5sV3lwzaVE9tVbqwpLj9migcDs4nlZdaO7MnFieOqYGA7B0uJkw+vWrUKTz/9NN5//31s3rwZnZ2dGDp0KI488kicdtppOOecc1BeXl6oayXJ8eYjHw7y5cS+Kh/u1JGTYVkctqs0+IyVX1qmONtXShxXycusHWPxOMKRiMtXQ7liXw0GtnOw2MoUX7p0KaZNm4YjjzwSH3zwAY499lhcddVVuOmmm/D9738fiqLgN7/5DUaOHIk//OEP6OnpKfR1k4SY8SQfPlDkxACqfNhX5cR2lRtLLsiPmeLBwAVMeZn1Wfbl4sRxVTCwnYPFVqb4Oeecg2uuuQbPP/88BgwYYPq5hQsX4p577sEdd9yBX//61/m6RgoI3nzkw4UOObGvyodtKie2q9y4QCm/1IUPtq+ceK+WF4PicmFfDQa2c7DYCoqvXbsWpaWlGT83depUTJ06Fb29vTlfGAUPtwHLhxN2OXGgIB8enion9lW5ceFZfswUDwbOgeRlWj6FfbkocVwVDBxfBYut8il2AuK5fJ4I4ENGRmxTORlu8+Xkraixr8qJix1yY7+VX2p7sv/KiQEYeZkFv9m+xYnP3WBgOweLraC4qq2tDUuWLEF7ezuARK3xiy66COeeey6eeOKJglwgBQdrY8qHDxQ5sV3lwzaVE9tVbswulV/aQZvsv1Lizkp5sXyKXDiuCga2c7DYKp8CAO+99x7OOOMMtLe3Y+DAgXjqqafwne98B6NGjUIkEsE//vEPdHZ2YsaMGYW8XpIYbz7y4YRdTuyr8uGEXE7sq3JjMoH8jNpTURSEQiEProYKhbt65GVaPoXtW5Q4rgoGxjCCxXam+P/+7//i3HPPxdatW3HVVVfh/PPPx8yZM7Fq1Sp89tlnuOGGG3D//fcX8lpJcnzIyIcTdjkxgCof3n/lxL4qN7av/AyDpWxj6fAZLC9misuFfTUY2M7BYjsovnz5clxzzTUYNWoUrr32WrS2tuL888/Xvn/BBRdg/fr1BblICgbefOTDNpUT21U+bFM5sV3lxjrE8mMfDgYucMmLQXG58J4cDGznYLEdFG9tbcWgQYMAAGVlZaiqqkJNTY32/ZqaGnR2dub/CikwDA/v482nqHGQLyfuAJAPtwnKiUFTuXHSJj8ebB0MvFfLy6y/cj5UnPjcDQa2c7DYDoqHQiFd/brUr4lyxZuPfNimcmIAVT6ckMuJ92C5sQ6x/NiHg4HjKnkxU1wuvCcHAxPAgsX2QZuKouB//ud/UFKS+JHOzk6ceeaZKCsrAwD09fUV5gopMPiQkQ8DbXJiX5WPYZt6cB2UXwy0yI33YvmxpngwMAAjLx60KRc+d4OB7RwstoPic+bM0X39zW9+M+0z55xzTu5XRIHFm498GJCRE8viyId9VU58rsqNZefkxz4cDBxXyYuZ4nLhPTkY2M7BknVQnCjfmCUhHz5Q5MR2lQ/bVE58rsqN/VZ+rCkeDFyYlheD4nLhczcY2M7BYrumOFGhcUAoHz5Q5MR2lQ/bVE5sV7lx0UN+zCAOBpYblJdZf2U/Lk4cVwUD2zlYbGeKqyZMmGD5/Q0bNmR9MRRsvPnIh5M5OTFzTT7sq3Jiu8qNyQTy49g4GHivlhczxeVi1GpsS/nw2RssjoPimzZtwujRo/GDH/wAw4YNK8Q1UUDx5iMfZrHJiX1VPuyrcmJflRuzS+VneNAmFz6kw3u1vBgUl4vYbiXhMPricbalhHhPDhbHQfFly5bhoYcewsMPP4wvfelLuOyyy/CVr3ylENdGAcObj3zYpnJiu8qHbSontqvcmF0qP/bhYODih7zM+ivbtzgxKB4MPMg8WBzXFJ80aRLuv/9+bNmyBV//+tdx3XXX4YADDsBbb71ViOtLc//992PcuHGoqKjAsccei8WLF5t+9h//+AeOPvpoDBgwANXV1Zg8eTL++te/unKd5BwznuTDrd1yYiBGPuyrcuJzVW7c4SE/TsyDgYsf8mKmuFxSg+Kp75EceE8OlqwP2qysrMQpp5yCU089FU1NTdi2bVs+r8vQM888g1mzZmHOnDlYunQpjjjiCJx22mnYtWuX4ecHDRqE3/zmN1i4cCGWL1+O6dOnY/r06XjjjTcKfq3kHG8+8mGbyontKh+2qZy42CE39lv5sY2DgYsf8mJQXC4MigcDn73B4jgo3tfXh2effRbTpk3DySefjEgkgmXLlmH69OmFuD6dO++8EzNmzMD06dMxceJEPPjgg6iqqsK8efMMP/+lL30J3/rWt3DooYdi//33x89+9jNMmjQJH3zwQcGvlZxj9ql8OMiXE7MT5cPBn5zYrnLjocfyY1mNYOACpryMgqgA50PFikHxYOD4OVgc1xQfNWoUysvLcckll+DWW29FSUkJWltbsXz5cgCJ8iqFEI1GsWTJEsyePVt7LxwOY9q0aVi4cGHGn1cUBW+//TbWrFmDP/zhD6af6+npQU9Pj/Z1a2trbhdOtvHmIx+2qZw4eZMP+6qc2K5yY/vKj20cDGxneYnj49J9NagBtm+xYlA8GHhPDhbHQfHGxkYAwI033oibbroJQCLgDAChUAixWCyPl5fU1NSEWCyGuro63ft1dXVYvXq16c+1tLRg1KhR6OnpQSQSwZ/+9CfLg0Fvvvlm3HDDDXm7brKP2afy4QNFTmxX+XBXh5wMs0zZrtJgv5Uf2zgYeK+Wl1mmOMfNxYlB8WDgXDdYHAfFN27cWIjrKJiamhosW7YM7e3tmD9/PmbNmoUJEybgS1/6kuHnZ8+ejVmzZmlft7a2YsyYMS5dbbDx5iMfZhTLybCvenAdlD+8/8qJ7So3tq/82MbBwHaWl9iOpZGI9przoeIktmckFEp7j+TAe3KwOA6Kjx07thDXkdGQIUMQiUTQ0NCge7+hoQHDhw83/blwOIwDDjgAADB58mSsWrUKN998s2lQvLy8HOXl5Xm7brKPNx/5sE3lxMUO+bCvyontKjfusJMfa4oHA8dV8tIFxZkpXvQUod2YKS4vjq+CxdZBm4sWLbL9Czs7O7FixYqsL8hMWVkZpkyZgvnz52vvxeNxzJ8/H1OnTrX9e+LxuK5mOPkHJ+/y4QNFTuyr8uGEXE7sq3Jjv5UfD6EPBqM25b1aDiyfIheWTwkGjp+DxVZQ/Ac/+AFOO+00PPfcc+jo6DD8zMqVK/HrX/8a+++/P5YsWZLXi1TNmjULc+fOxeOPP45Vq1bh8ssvR0dHB6ZPnw4AuOiii3QHcd5888146623sGHDBqxatQp33HEH/vrXv+L73/9+Qa6PcmNYN5GTu6LGyZycOHmTDwd/cuI9WG68F8uP9+Zg4L1aXmZBcbZvcWJQPBj47A0WW+VTVq5ciQceeAD/+7//i+9973s46KCDMHLkSFRUVGDv3r1YvXo12tvb8a1vfQtvvvkmDj/88IJc7Pnnn4/GxkZcf/31qK+vx+TJk/H6669rh29u2bIFYeFh09HRgSuuuALbtm1DZWUlDjnkEPztb3/D+eefX5Dro9zw5iMftqmcOHmTD/uqnBg0lRvvxfJjwkgwsEyOvMxqivNZXJwYFA8GzouCxVZQvLS0FFdeeSWuvPJKfPzxx/jggw+wefNmdHV14YgjjsDVV1+NU089FYMGDSr09WLmzJmYOXOm4fcWLFig+/r//u//8H//938FvybKD9585MM2lRPbVT6GE3K2adFjX5UbS5TJj304GNjO8jLNFOeiR1FiUDwYWJ4uWBwftHn00Ufj6KOPLsS1UMBxQCgfZjjJiX1VPmxTObFd5cb2lR8XLIOBuz7kJbYjD9osfkZBcQWJAzhDoZBHV0X5xvFVsNiqKU7kBmY8yYcPFDlx9Vw+7KtyYl+VGxee5cd7czCw1JW8WD5FLmK7RYRFDramXPjsDRYGxckXFEUxfJgwS6K48YEiJ7arfBg8lRMDLXLjvVh+XPgIBj6D5cWDNuWitmc4FEJYyAzns1cuHD8HC4Pi5AuKyU2GN5/ixu2gcuJAQT4MrsmJ7So3ltaQH/twMHC3rLx0meIsn1L01HYLAQyKS4zP3mBhUJx8IW6SDcGbT3HjIF9OXOyQDwd/cmJflRv7rfy48BEMvFfLyyxTnPfq4qS2GjPF5cbxVbAwKE6+EIvFDN/nzae48YEiJ7arfDghlxP7qty4a0d+LKsRDGxneZmWT2H7FiWWTwkGjp+DpSSbH+ro6MC7776LLVu2IBqN6r535ZVX5uXCKFiYKS4nDvLlxIGCfNimcmK7yo3PWPlx4SMY2M7y4kGbcmFQPBg4fg4Wx0HxTz75BF//+tfR2dmJjo4ODBo0CE1NTaiqqsKwYcMYFKesMCguJz5Q5MRAjHw4IZcTS1jJjc9Y+XEXTzCwneUlPodZPqX4MSgeDBxfBYvj8ilXX301zjzzTOzduxeVlZVYtGgRNm/ejClTpuD2228vxDVSAJgFxRloK258oMiJgTb5cKFDTmxXubHetPw4jgoGtrO8zA7a5L26ODEoHgy8JweL46D4smXL8POf/xzhcBiRSAQ9PT0YM2YMbr31Vvz6178uxDVSADBTXE5GAz4OAosfM5rkw8GfnNiucmP7ys9w4YMLW9JhO8uL5VPkwqB4MHB8FSyOg+KlpaUI71vlHDZsGLZs2QIAqK2txdatW/N7dRQYPGhTTnygyIntKh+2qZzYrnJj2SP5sQ8HA9tZXmYHbbJ9ixOD4sHAnXjB4rim+JFHHomPPvoIBx54IE455RRcf/31aGpqwl//+lccdthhhbhGCgBmisvJrP0URUFIGEhQceHkTT7M/pcTg6ZyY3kcuSmKAqPeynuzfLizUl5mQXHeq4sTg+LBwBhGsDjOFP/973+PESNGAAB+97vfYeDAgbj88svR2NiIhx56KO8XSMHAoLiczNqPA/3ixkCMfLjQIScudsiN5zvIzawt2cby4TNYXmY1xdm+xUlttxCD4lIT2zNk8j7Jw3Gm+NFHH629HjZsGF5//fW8XhAFk+lBm7zxFDWzQCkfKMWNkzf5sE3lxHaVG9tXbmZjYC5Cy4fJBvJi+RS5MFM8GFL7be+++3FcURAx+yEqWo6D4mZ6enrwzDPPAAAqKytx7rnn5utXUwCwpricmOUkJ5ZkkA8n5HJi0FRuLLkgN+62CwZFUbirR2JiO4qZ4mzf4qQwKB4IVkFxko/joPi9995r+H5bWxuuv/56XHnllaitrWVQnBwRM8VLwmH08cYjBdMJHYNtRS11K2hvPM7BfZFLHfz1xeO8/0qAQXG5sX3lxt12wWDWmmxnOejGzJGI4ftUPJgpHgzc4REsjoPiV111FUaPHo1IRL9xQM30veuuu/JzZRQoDIrLySjQlvo+FR+j1XO2aXFLzWRiUFwOYlAthETwhYuS8jBqS7avPJhYEAxG9+nU96l48aBNuTAoHgwMigdLVuVTPv74YwwbNkz3Xn19PUaNGpWXi6LgSQ2Ka+/zxlPUGBSXk3bIDIDIvv7KNi1uRoM/tmnxS81Qi8ZibFeJMFNcbmY7sNjGcjG6T6e+T8WLwTW5MCgeDDH220AJZ/6IXigUQigUMnyfKFtiTXHeeOTBOnpyMhoQsq8WN6PtveynxY+LHXLj+Q5yY03xYEgtSadiO8vBrH15ry5ODIoHA8seBYvjTHFFUXDdddehtrYW/fv3x/jx43HyySejtLS0ENdHASFmipdya5k0+ECRk9ovxQEh+2pxM5q0sZ8WP7ENI2pfZbtKg4fzyY2HlQdDLHWs3NsLgO0sC9PyKWzfosSgeDBwh0ewOA6Kn3zyyVizZg16enqwe/dubN26FT09PTjhhBMKcX0UELqgOIOn0uADRU7igDDCTHEpMKNYTjGxr7JdpWO0GMn2lYfZYjMXoeViminOdpYCE4TkwqB4MBgllaS+T/JwHBRfsGCB7utYLIZFixbhuuuuAwC8//77KC0txXHHHZeXC6RgYE1xOXGgLye1XSPhMMunSMIoKM5+WvxY6khuhpni7LfSYKZ4MJgFTZlJLAfWJpaLblxl8D7JgYtZweK4pniqSCSCE044AU899RROPvlkXH/99bj99tvzcW0UIKwpLqcYFzukxECbfIwGf2zT4qctYLGvSok1xeVmFhRlsFQuMZMSkuzLcmCCkFzU9gwBzBSXGMseBYvjTHEzdXV1eOedd/L16yhgmCkuJ66yyskoKM5BQnFj+RQ5GfZVTsSlYdRH2W/lkRpM693Xd9nGcmGmuNw4F5KL2mosnyI3HpAbLI4zxceNG4cbb7wRW7ZsKcT1UECZHrTJG09RM82OYLsWNV1NcQZQpWAUFFeQOFybihfr/8vNaIGDz1d5xEzO2+HCllxiDL5IjecryYU1xYOBZY+CxXFQ/KqrrsI//vEPTJgwAV/5ylfw9NNPo6enpxDXRgHCgzblxIGgnGIGA0K2aXHj9m05qe3KvionZorLjYkFwWCaKc7FDymwDINcGBQPBu7wCJasguLLli3D4sWLceihh+KnP/0pRowYgZkzZ2Lp0qWFuEYKANYUl5PpQJAD/aJmVKeYbVrcOGmTEw/FlZtR/2SflUeMk/JA4DZ9ubF95cKgeDAwsS9Ysj5o86ijjsK9996LHTt2YM6cOfjzn/+MY445BpMnT8a8efO45ZocYU1xOXFCJyeWZJAPMyLkxPr/clPbl+MmOTGYFgymZXLYzlJgcE0uDIoHA/ttsGR90GZvby9eeOEFPProo3jrrbdw3HHH4dJLL8W2bdvw61//Gv/617/w5JNP5vNaSWJmNcV54ylunNDJyWhAyDYtbuyrcmL9f7mpwbTScBh9PIRROjGThBHuzJKLaZkctrMU2I/lwqB4MDAoHiyOg+JLly7Fo48+iqeeegrhcBgXXXQR7rrrLhxyyCHaZ771rW/hmGOOyeuFktyYKS4nlmSQE4Pi8uHgT06s/y83tS1LIxF09fUBYKBFJtzBEwx8/srNr/041hdDd3s3qgdUe3odxYZB8WDgfTlYHAfFjznmGHzlK1/BAw88gLPPPhulpaVpnxk/fjwuuOCCvFwgBYNZUJyTu+Lm14Eg5cbo8D4udBQ3sU9GeA+WBhew5Kbed7m7Q048aDMYxPYsY/kU6fhxJ148FscTv3wCGz/ZiP+Z8T848XsnenYtxYZB8WAw2+HBdpaT46D4hg0bMHbsWMvPVFdX49FHH836oih4xIM2GTyVR4yrrFJiSQb5GNWJF9+n4sRDceUmZoqrGEiTB89lCQYmkMjNj7tmNy3bhI2fbAQAzJ87H8d95ziUlGVdVTcwxDPzQgyKS42Z4sHi+KDNU089Fbt37y7EtVCAsaa4nFgnUU5aoC0cZvapJJj5IiceiisvRVGSQXGOm6TkxwxTyr+YyRyIY2U5+HHRo359ve7rhg0NHl1JcRFbjONlufH5GyyOg+KbNm3SZfUS5QNrisvJjwNByh1LMsjHLCjOrNPixr4qL7EVOW6Sky5YKu4GYLBUKhwry800U9zDfrx3x17Lr8mY2JYMisvNj/2WCsdxUBxIbBchyifToLgXF0N5w61HcjLKPuUgobiJBzJG2Felwfr/8mLAVH7MVAsGP5bXoPzx41yofXe77uuWXS0eXUlxYVA8OLhYGSxZFY86+uijERH+5xBt2LAhpwuiYDKrKc7JXXHjQF9OzD6VD8unyEksdcT6/3JhwFR+ZjXFOYaSS8ykL3MOJAez9vXyXt22u033deuuVo+upLgwKB4cuhgGd9BKL6ug+M9//nPU1tbm+1oowFhTXE5mdRLZrsUtZhBAVZCoccudRMXJ6EBGgJPyYme02ME2lYNZFhMnbPLgwkcwsJ3l5sd7dfseZopng0Hx4DBL7FPYzlJyHBQPhUK44IILMGzYsEJcDwUUa4rLiQN9OZkFUBUADIkXJ6OSOOL7VJyMguJcwJIDs0vlF+PYOBBMSyGxnaXgt7mQoihpmeKp5VTImFVQnM9eucRMguJ8/srJcU1xro5QITAoLiceUiEnXQCV7SoFlk+Rk9GuDkB/SCMVJ7PsQ7atPEwzTPmslYrfgqaUX36rKd6+ux3xPv09pKu9y5NrKTbMFA8O1hQPFsdB8UcffZSlUyjvxJrifhgwUH7wgSInBlDlY9amzFQrbtwBIC+zLGIGTOXhx1rElH9MIJGb385XatralPZeVyuD4nYwKB4cfuu3VFiOy6dcfPHFhbgOCjjWFJcTtx7JiUFx+Zhl/7NNi5tVrXjxnkzFh9ml8vNjLWLKP7E9I+EwwqEQ4orCviwJtR1DgC/GV7u37k57r7u9m2XVbBDbLARwDiQxXb9lO0vP8Yxo0KBBlv8U2v33349x48ahoqICxx57LBYvXmz62blz5+Kkk07CwIEDMXDgQEybNs3y8+Qds/IpHPgXN7NJO9u1uDGrWD6mbcpMtaLGxQ55xUwCpmxbeXDhIxjE9hQXMDmmkoPfEknETPFQeN9ZI3EF0c6oJ9dTTMQywn5pTyoMv/VbKizHmeKKoiAej+Pqq6/G+PHjC3FNpp555hnMmjULDz74II499ljcfffdOO2007BmzRrDgz8XLFiA7373uzj++ONRUVGBP/zhD/jqV7+KFStWYNSoUa5eO1mLmxwywxtPcWP5FPkoQvYSSzLIQzf4M3ifihMH9fJiwFR+MZNdlAyWyiW1JEMkFEIfuCgtC7Ud/ZJ0sHtLMlN8zBfGYMunWwAAXW1dKK8u9+SaigXLpwQHx8/B4jhTfP369bj44otxxx134LPPPsPZZ5+Niy++WPunkO68807MmDED06dPx8SJE/Hggw+iqqoK8+bNM/z8E088gSuuuAKTJ0/GIYccgj//+c+Ix+OYP39+Qa+TnGNNcTn57XAZyp3Ycuo2XxXbtXiJkzZmFMvDdDLOdi16pjXF2bbSYGJBMIh9WbxXs53l4LdEkuaGZgBAaUUphowdor3f3d7tyfUUEwbFg8Nvi1lUWFmVT7n33nuxZMkSrFu3DgcccADuu+8+XVCzEKLRKJYsWYJp06Zp74XDYUybNg0LFy609Ts6OzvR29trWealp6cHra2tun+o8MzKp/ABU9x4EJh8OCCUE0viyEdRFG0RKxIO+2IyTvmTuugcMnifihvPZQkGXfmUcFhbmObzVw7a2R4+SSTp2NsBAOg3qB8qayq193nYZmacAwUHyw8GS9anLB100EF44YUX8Pe//x1/+ctfMHHiRLz44ot5vDS9pqYmxGIx1NXV6d6vq6tDfX29rd9x7bXXYuTIkbrAeqqbb74ZtbW12j9jxozJ6brJHh60KSdmissnbZsvFzuk4LdJG+VObDlO3uQTM5mcs23lYXouC5+1UkntyxH2Zan4Kekg1hfTgt/VA6pRXpUslxLtYk3xTPwaFFcURVfvnHLHeVGwOK4p/u1vfzvtvVGjRmH16tU455xzCp4xnq1bbrkFTz/9NBYsWICKigrTz82ePRuzZs3Svm5tbWVg3AWmB21y4F/U/LZlkHLn1wEh5YZ9VT5WfZXP1uKXml0aDoUQUxS2rURiPG8nEEwP2vS4L/d292LJ/1uCAcMH4JATD/H0WoqZnzJOO5s7tdfVA6tRWlGqfR3tZlA8Ez/OgfqifXj6f5/Glk+34JzrzsHBxx/syXXIhjXFg8VxULy2ttbw/e985zs5X4yVIUOGIBKJoKGhQfd+Q0MDhg8fbvmzt99+O2655Rb861//wqRJkyw/W15ejvJyHjLhNnExhQN/efgpO4Lyw6z2JcD+WsxM+6pHk/JYbwzbV2/H8AOGo6yyzJNrKHZWuzrYV4tf6r04Eg6jNx5n20rENFOcbSwVs3u113351XtfxbLXlgEApt87Hfsdvp+n11Os/DS+6mju0F5XD6jWja+YKZ6ZH4Piqz9YjfUfrQcAzJ87n0HxPGEMI1gcB8UfffTRQlxHRmVlZZgyZQrmz5+Ps88+GwC0QzNnzpxp+nO33norfve73+GNN97A0Ucf7dLVklOsKS4nP2VHUH74cUAY7Ypi5bsrMeYLYzB4zGBPrqHY+a2vvvnAm1j8wmIMGDEAVzx6BUrLSzP/EOlwAUtuZtmlbFt5iJNvJozIy+xe7WXwpbenVwuIA8Dqf69mUDxLfso4bd/Trr2uHqQPivd297p+PcXGj8kGO9bs0F43bmpEb08vx8x5wB20wZJ1TXEvzJo1C3PnzsXjjz+OVatW4fLLL0dHRwemT58OALjoooswe/Zs7fN/+MMfcN1112HevHkYN24c6uvrUV9fj/b2drM/gjzCmuJyivloIEj5kRqIifhg9fyN+9/AS394CfN+Og/d7d2eXEOx89OkLR6L46OXPgIANO9sxoaPN7h+DTIwC5oCHgdbunvx2duf6Sbn5JxZTXFmMcmDNcWDIe2gTR+UT9m5dqfu66ZNTR5dSfHzU3CNmeK5Edss5IPxMgDs3blX9/Xurbs9uQ7Z+GleRIXnOFN80KBBlt/fs2dP1heTyfnnn4/GxkZcf/31qK+vx+TJk/H6669rh29u2bIFYWHQ+MADDyAajaaVdpkzZw5++9vfFuw6yTlmistJO6TCB1sGKT/8limuKAqWvrIUANDZ0okNSzZg4ikTXb+OYuenbYKtja1Q4sk/t2FjAw4+gdtBnUrLaPLBoF5RFDxx7RPYvHwzaobU4CeP/QTl1SxZlw2zBUqOm+QR49g4EPx4aO62Vdt0X7fsavHoSoqfWYKQF+Or1KA4a4o747c5EAC0Nbbpvm7c1IjhB1iXFqbMmNgXLI6D4s3Nzbj77rtNa4sX2syZM03LpSxYsED39aZNmwp/QZQXDIrLyU/ZEZQffhsQpmaG79leuIVZmfmpr6a24a4Nu1y/Bhn4ra8CwN4de7F5+WYAQFtTG9Z8uAaTvmJ91gsZMyu5wOerPHSZ4iyfIi2zkgxe7vpIzTZt291m8knKxCxByJNM8T3JoHi/Qf30QXFmimcktphfxlXte/W77jgPyg8/9VsqPMdBcQC44IILMGzYsHxfCwWYeNBmCQ8Tkoafsk8pP/xWT6+1sVX3NQeD2fFTRkRqWY3d27gVNBtm2YeAd7t1tny6Rff1tlXbGBTPUmrJBQbF5cODNoPBj7s+UsdWXa1diPXGECmNmPwEmfHTmS2pmeKi3i7WFM/Ej8kGqclBqeVUKDt+OiCXCs9xTfFQKIS2tjZ0dXUV4noooFIzxdVbDyd3xU19cPhhIEj54bdAW8feDt3Xe7YxKJ4NPw3+UrNeWhq4bTsbaXVqfXAP3r56u+5r7gLInmlNcU7YpMGDNoPB9KBND/uy0XOX50Bkx0/jK3HMXD2QNcWd0gXFAc+D4vFYHD0dPbr39u5gUDwf/LSYRYXnOCiuKAoOOugg9OvXD6WlpRg9ejTOPPNMvPDCC4W4PgqIOLcBS8lPA0HKD7PsxNTvuSWtfMoOBsWzIW4T9HrwJ27vBRIZapysOefHjKbdW/RZ/7s27oLC53xW0rJL9/VbjpvkwYM2g8FsAdNPmeIAg+LZ8tOBfWpQPBQOobKmUlc+pbebmeKZ+G1c1dPZk/YeM8Xzw0/9lgrPcfmUd955B4qioLe3F62trdixYwc++ugjnHfeeXj44Ycxffr0QlwnSc4oKB5TFN54ipwWaAuHPa9TTPmRNiA0+Z5bUoPibU1tiHZFddkvlJmfBn+p2f8A0FzfjGHjWbbNCavJm1flF5q2Num+7mrtQvvudtQMqfHkeooZa4rLT2xjZorLy+xe7dV9uru9Oy37FNCX3iD7xPGV+u+4R3NcdSde9YBqhMIhZoo75LuguEE/bWtqQ29PL0rLSw1+guzy07xIpCgKQsL1UH44Doqfcsophu8fddRRuPPOOxkUp6yINcU5uZMHa4rLx6qmuBft2tWWXsprz/Y9PHndIT/1VaOJd0tDC4PiDqX1VY8H9dGuKNqa0g9r27VpF4PiWTDbtcPnqzzMMsU5NpZLaikkr2uKG2WJA8bjLcrMLCju9r1aURRtfFU9MFFPPFIaQSgcghJXEO1mUDwTvwXFUxODVM07mzF03FCXr0YuYglYr+dFqt/97ne49dZbccUVV+Dmm2/27Dpk5Lh8ipkZM2bgpptuytevo4ARM8V1kztuES1qrMcln2IYEDZubnT9OoqZ4rPgaWpNcQBobmh2/TqKnVkmMeBNu+7eanxgKs8ByI7fAmmUf7GUhQ+j991Wv64eaz5cg1hvLPOHyZbUUkhez4FadiXriQ8cOVB73dXKoHg2xOAaAM/u1T0dPYj3Ja5FDYqHQslscWaKZ1YMcyCAJVTyQRfD8EGm+M6dO3H99dejtbUVt9xyCzZu3OjJdcgqb0Hx6upqnH322fn6dRQwqeVT/FBPDwB2b9ttuJWf7ImZPFC42FG8/BZo625LHxBuX7Xd4JNkxm+DfKN7rjhJJ3vSak57fA8W6/0f8MUDtNepJVXIHrNAmtfjJsofsz7sVRtvXr4ZD//4YTz9m6fx+h9f9+QaZJQ6rlLnQF4tfrTuSmaK102o016bBeDImlhKEoBn92qxJny/gf2012pQnDXFM/PbeFnsk4PHDNZec1yVO7Hfet3OAPDJJ5/o4mXPPvssGhuZBJYvjoPiRx11lOU/RNnw40GbH730Ef74gz/inu/dg10bd3l2HcVMPLzPL1uPKDd+HhCqtq3c5vp1FDPL2tMuB0+VuKIFxcMlySFK+24e8OWU3/qqOCEfd+Q47TUzxbNjtkDJRWd5+K2Nl/xzCZR44t7x8T8/Rl+0z5PrkE3aQZsez4FaGpOL0HX7J4PizBTPjlH5FMD9fiyWpqsaUKW9Zqa4fWKfDPlgXCXOgcZOGqu93rF6h+vXIhu/1RT/73//q/v6V7/6Ferq6vDggw+ivr5eF0sj5xzXFF+2bBl+/vOfo1+/fpk/TGSTH2uKv/eX9wAkVs6XvroUp//kdM+upVixfIp8/JZ9Kg4Iq2qr0NnSifp19eiL9qGkzPEjLpCs6sS7vr23swfxWOL/o7oJddi5dicAoG13ei1qsua7oLiwsDH8gOGIlEYQ642xbbNk1m/5fJVHWrA0HEZvPO5ZG29frd+F1bC+AaMOHeXJtcjE9KBNj4IcrQ1Cpvj+zBTPVWpQ3Kt7tbgLT8wUL61IHMjImuKZpZYb9HpcJfbJ/Sbth+X/Wo6+nj7umM0D07OWPLovr127Nu09RVFw+eWX4/LLL8ekSZPwwAMP4KCDDsKQIUM8uMLillXE4JprrsGwYTzwivJHV1PcB0HxaFdUl9XWsL7Bk+sodn57oFDu/BZoEweE4yaPw8p3VyLWG0PLrhYMHj3Y4idJ5ac2FTOVautqsWvjrkTg1OCARrKWVnPa45rE4jO1ZnANqmqr0NbUZniwKmWWWm/a63ET5V9qH/byMFUlrqSVsdq2ahuD4nlgdq9WkAh6hIRnsht0meJC+RQetJkds0xxL4Piak1xIJkpHu+LI9YbQ6Q04up1FRM/jZcBoLtDnxg0fP/h2LZyG5rrm9Hb04vS8lLXr0kWfkvsq6+vt/z+8uXLccIJJwAALrjgApx77rk4/vjjMXz4cDcur+jlraY4US78Vj6laYu+FpfZAWFkTTxcxg+HVACJCUbLrhbE+nhIVDb8NiBUJ2llVWUYMGKA9n5LA2tQ22UWeEn9nhvEmpZlFWWoGVIDQB9QJXtSs0y97qviAar9BvXTJuWdzZ1aSQayz+xezKC4PPzUxu172tMO19y5Zqfr1yEjs/MBUr/nFvV5W1pRitq6Wu19BsWzY1o+xe2a4sIzuHqAEBSvKNNeM1vcmt/mQGJiUEW/CgwaNUj7eu8OHraZC7+VTxGD4ldddRWuuuoqTJo0yfCzTz/9NM455xyMHTsWF154IR588EEsXrxYV5mB9LLKFHd7xZrkZxYU96r2dGpQvK2pDdGuqLaaTvaYHVLhVbt2tXXhiV8+ge2rt6NuQh0uvf9Sbdsg2eOnUhtAckBYWVOJ/kP7a++zJIN9ZvVMU7/nBjFTvLSyFDWDa9C8sxldrV0sieOQrq8Cng/q1UBLOBJGZU2lNimPx+Lobu9GZf9K16+pmMVMdtjxzA55+Omgzeb65rT3tq/hFv18SDtoM+Ve7XbebmdLJ4BE5mmkJIKyqjJEO6OGB5tTZmnlUzzqx53NndprMVNcnAf1dveisobPYjN+C4r3tPdoryv6VWiJJMC+nQHjXb8kacR8GhQfPXo07rrrLgBAX18ftmzZgvLycvz+97/HypUrsXjxYnR2Jvp6NBrFk08+iSeffBIlJSVoa2tDJMKdIEayml1ed911qKqqMvzenXfemdMFUTCl1hT3+pAZo4Danu17MPwAbkFxwm9bj979y7taTcyGDQ347J3PcOTXjvTkWoqVn7KKFUXRguIV1RWo6p98LvFAKPv8NMgXs5TKKst0dS87mjtQO6zW6MfIQNoClsclrNQJedWAKoTCIV2mWkdzB4PiDpm1r9eZ4l1tXSgpLeGCcx746aDN1sbWtPeatjShp7MH5VXlrl+PTCwPu1YUuNmTlLiijZ+qahNjqsqaSkQ7o8wUz1IsJSjuVT8W208MfOsyxXnYpiU/jZeBlEzx6grdOKqztdPoR8gmLbHP47kukIiT7dq1CwB05VBKSkowYcIEAMD9998PAGhsbMTLL7+MTz75BH/729/Q3NwMAPjCF76AiooKdy+8iDgOip988slYs2aN4feYQU7Z8lv5FKOAWnN9M4PiDvmppng8Fsey15bp3tv0ySYGxR3y0zbfvmiftp27okY/GGRQ3D7LCbnLfVWckJVVlKFqYHKho2Mvg+JO+G3ypmUf7lu8qhqgb9sh+/FgICf8WFP8o5c+wqt3v4pBowZh+r3T0W9Qv8w/RKaMDtpMfd8tYkBNPSQXCrBx6UYccuIhrl+PTMzaGXD/Gdzd0a2Vs1KD4hX9KtDS0IKuti5PapwXOzG4BnhXU1zM9K+oSQbHxAVMBsWt+W1clVo+Re2zAOdBufJT+ZSmpiYtVlZXV2f52aFDh+KSSy4BANx2221YsmQJli5daprQTAmOg+ILFiwowGVQ0OkO2vTB5E6dvItYo9g5Xaa4xw+UXRt3oaejR/dewwYeoOqUnwaEqYNBZkhkx08lcXQ1xSvLUK3os4nJPrMsU8Cbdu2L9gEQsg+F/ir2ZbLH7F7s1UHW8Vgc8+fOB5DYWffJq5/gpO+f5Mm1yMJPB22K46dJX5mET179BACw4NEFOPj4gxEKM1CaLasdeK6X2BDmP2KmOJA4iLG3u5elJB1QUtoWgGeLW13t+4KkoURWsUpsT3EMRun8NAcCkgdthkvCKCkv0e2YNYplkD2p/dbrGMbevcn68EOG2E8gqaiowAknnKAdwEnmeNAm+YJpTXGPJndmmeLkjFk9Li8mdFtXbE17r3FzIw/cdMiqJIOXWS+VNZUsn5IlPw3ydTXFK0r1JTb2MijuhGX2oQ8CLWLJhZ7OnrSfIWtp9aY9zCIGEmMkMXC65bMtnlyHTPxUU1xcuJp4ykRtZ0fDhgbD8RXZZ9bOgLf3anXhUrxXM5PYmdT5rfhvt9tWHTNX9KvQLWKVVgqZ4jxo05KfxstA8r5c0a8CoVCIyUF54rd2VkugAMCAAQNc//ODwHGm+Je//GXL77/99ttZXwwFV1pNcY8nd8wUzw91UUOcsAPetOvurbu11/0G90P77nbE++LYvXU3ho0f5vr1FCs/ldoQJ+nl/cpZPiVLmeqZuklXPqWyTHewJjPFnfHToD5ToCV1Fw9lZrYTQAE8KXGQmjggPnMpO2Zt7GVGIpBY2Dr2nGPxyl2vAAB2rt2J/Q7fz/VrkoWfdmsZLWCKmcQMijtjFRR3PVN8Xwmk1IM0xZrizBS3JrZZCN4fYC4GxQHoy6e0cB6ULT+NnwEGxd2QVfmU0aNH46yzzkJpKQ/RofwwzRT3Kii+b3U1UhpBPBaHEleYKZ4FrY6eUBIH8GYHwN4dya1Hh5xwCD7+58cAgMZNjQyKO+CnkgziJL2iXwXKq8sRCoegxBVmSDjgp+z/1IM2xckbg+LO+GlQL/ZHLVO8mpniuUjdCZDavhGPg+LN9c2I9cYQKY24eh0yMWtjL8ZQ4sJVeXW57gyAll1MGsmF1bjK7bY2DIpXJYOmvFc7YxQU92LHhxJX0gKoKtYUt09sMa/HVUpc0e7LRkFxzoOyZ1XSypMYhlA+hUHxwnAcFH/hhRfw8MMP4/nnn8cPfvADzJgxAwcddFAhro0CRFdT3OMtokAyy1Q9JKqloQV7d+7lATMOKIqiDR68DrQBwJ4dewAkFjomHD1BC4rv2rgLXzj1C65fT7HyU0aTbpJeVZ7YOlhTic6WTl1pFbLmp+Bpb5dQU7yiDNUDk+VTOvdygO9E6qA+4rNACzPFc2PVvnFFgduh6NSguBJXsHfnXh6gmoO0NvZwF6XuDI/qCu0wRgDobOa9ORdppa48fAaLu+yMguLRTgZNnbAsn+Lic7ins0frs8wUz56fxsvRrqjWpmpQnKWO8sOq/CAzxeXkuKb4N7/5Tbzyyiv46KOPUFVVhWnTpuHUU0/F4sWLC3F9FBB+qimuKIq2xayiXwUGjxkMIDEh4KEV9oklcSIel2RQFAXNO5sBAANHDETdhOTJzfXr6l29lmJnlZ3odruKGUvqQLCiJjEw5MF99vkpSy21fIqupjgzxR1JrVPru/IpzBTPiZ/aFwDa97Snvbd3516DT5JdZm3s9UGb5dXluoxE3ptzY5mV6GX5lP4sn5Kr1PKggDcHbaYeTC9iprh9fgqKpy5UAonEr3BJ4v8vtmX2/NTOAIPibsj6oM0xY8bgmmuuwbXXXoulS5di4cKF+bwuCpjUoLiX2TC93b2I9yWup7KmUguKA6yR6YQuKO7xKmu0K4q+aB+ARD3xgSMHaoGZbau26U6ZJmt+GiikTtKB5GC/u6Nbl8lG5swO7Ev9nhvE8imlFaWorKlEOJK4Hh606Yyf+qpR9qE6iQOYKZ4Ny8UsLzKJDXbntO5qdf06ZJLaxn44aLOkrAQlZSWorKnUDuvjvTk3Vs9gX+zqqeQCZrZ0O6H3tasXNcXVZC8AuvN3gJRFDx60aclX4yqhTcWFDrU9GRTPnp/aGWBQ3A1ZBcUXL16MH/3oRxg/fjwWLlyIl19+GT/72c/yfW0UIKkr6V5mw+hWXmsqMGRMcutv05Ym16+nWJll/wMeDPKFrb3VtdUIhUIYdcgo7XusF2+fVUaT1+VTAKCy377BvsLJm11+OmhTVz6lsgyhcAhVAxITc2YjOmNV6sjT7EPWFM+LTDXF3Wa0O4e1pnNjdm/2YheleoaHGnwJhUPaTp6OFt6bc+GnAEymmuIMtDljWT7FzUzxNv3cViQGxVk+xZqf+qqYbFBZm1zoYFA8d36aFwEMirvBcU3xyZMnY8+ePbjkkkuwePFiDB6cyKJtbU1kg/Tv3z+/V0iBkLqS7odsGCCRycZM8eyklk/xskaiGExTA2yjDh2FdYvXAQB2rN6BgSMGunpNxSoto8nLoHineaY4kMiiSN0mSun8NMhPLZ8CANUDqtG+ux0dzR0818EBP7Wr0ZZ8XU1xBsUdM6s3DXgzdupq70p7j5niuYmZLHx4OTYWF7OqBlShfU87Ovby3pwLsx0BgPsBGF2gTS11xXt11vxy0KYuU7yfPlNcVz6FmeKW/DSu0rVpDYPi+ZSWVMJMcek5zhRfvnw5tm3bhhtvvBEHHHAABg4ciIEDB2LAgAEYOJBBJcqOn2qKp2aKDx6dDIrv3cH6mHZZlU/xNEtxX1B86Lih2nvMFLfPT/WnjTLFxQwY1hW3x0+DP3FCpgXF9x22GeuNscyGA1aBFj+UTykpL9HKL7BdnfNbTXH1fhspTR7x2dLITPFcxFIXoT0qLRiPxbUDFsWFZnWBK9Yb00rUkXN+OtRNHS+XVZahpKxEe61ioM0Zq0xxN9tWlxwknAcApBy02cVMcSt+CoobJRsA+qA4y4Nmx0/tDDAo7gbHmeLvvPNOIa6DAs5PNcVTV177Deqnfc3t+/bpsv89fqCI7VZdmwiw9R+a3NXS2shsNrv8tGVfzFhSJ+rihJ1BcXsstwl6eNBmaXkie0l32ObeDmb/22R5KK5HdWrDJWFtK34oFEJ5dTm627qZfZgFPy1QAsnt+bV1tWhpaEGsN6YrXUbOxVJ2UXpVWlC8L4tnAegyiDt6tHs2OWN50KZH92oxcKoLincyKO6E0UGbXiR+iXX/1UQDlZgpzvIp1vwULDWrE6/1VwXo6+nTtS/ZYzW+8jIoHgqFWJWjQBwHxU855RTT73322Wc5XQwFl1lNcQVwfUtm6gndJWUlKKsqQ7QzyqC4A6lt6uV2UHFirmaK64LiTQyK2+WrmuKdBpniYlDc4OA3SuenQb46ISutKNWyiHVB8eYOXUkrMuendtUCLf2rdM/z8qp9QXFmijuWll3qYfsqcUWrOV3ZrxJ9PX1obWzlmClHZuXK3G7f1HGxKvVcADGJhOyLpSSReNWX47G4FmgTg+K6xY8u3qudSC0lCcCTxK/2Pe3a69R+yoM27RPbLOR1UNyg1BGgb8+ezh4GxbNgtRPPi6QDNSheU1ODcDirIyEpg5z/q7a1teHhhx/GF7/4RRxxxBH5uCYKoNSsYi8nd7rDSPYN/rXDhDjBsy21fIqXAwdxQqfWXes3qJ8WdGOmuH1pkzcPt/mKgTR1EMhMceesDmT0qqa4OKgXs5rEbCey5qd2Nco+BJJBNQbFnfPdAuW+P7KiX4W2+NzZ0gklzu3b2TJrY7cn5eKzVAyEiwcwsg9nz3JXj5uHMbZ3a/2VmeL5kToXApCW+OUGceyUGhTX1RRneRxLfko20AXFxZriFSx3lCs/jZ8BYO/eRPlelqounKyD4u+99x4uvvhijBgxArfffju+/OUvY9GiRfm8NgoQs5rigAeHzAiHRaUGxbvbuhHrixn+HOmlLXSINcXdntB1pE/oIiURLdjW1tTm6vUUM79M3oDkJLysqkxb4GBQ3Dk/nbKuZimJk7TUTHGyx3JLvovt2tvdq9UbFrOZgGQGYl+0D7FePludsMxk8jKTuKZCK1OmxBXeh3OQWj7Fq9KCuqB4v2RQPDVTnLKTdmiuR1mJRmc/APrFDwbZnDHKFPcikNq+N5kpLo6pgMR8KFySuLewfIo1xSoo7vK16NpUSB7hGQC589Pih6IoDIq7wFH5lPr6ejz22GN45JFH0NraivPOOw89PT148cUXMXHixEJdIwWAGEANebwiZ5RVrGY9AYlBI7eIZmZWEgfwNqNYrIdZVVuF9t3tuokAWfNddiL0W3vFbAlxgYvMWU3ImSlevPxyEKNZ3UtA33ej3VFUluq/T+bSDlL1cNwktnFFvwqEI8lr6WjuSGt3sif1oE2vSgvqxlBi+ZTKcsPPkDNm7Qy425fFg/vEPqu7TzNT3BGjTPHUMVYk7afyTx07VdRU6A5DVpVVlqG7rZvlUzLwU7C0rTGR0BUpjZjv7GBQPCt+aueOjg709SUSSxgULxzbmeJnnnkmDj74YCxfvhx33303duzYgfvuu6+Q10YBkrqS7mXtJl35lJrE4F982DBT0Z7UgaCXNcXNJnSV/RKD/r5oH3p7mB1hh19qXwLJdhWz1Zgp7pxfgqfxWBx9PYmBn7j9k5ni2Unb/ulRu4qTMjG4AnDylgs/HXqcmikuJhKIgTZyxuygTcDdNta1b7V5TXHKjtmOAMDd8bLYV8V5T2l5KbDvfz3WFHcmU6a4W+2r1hQ3S+pSx1zMFLfmp2Cpeh5WzeAa3QIpx1W589MOWjVLHGBQvJBsZ4q/9tpruPLKK3H55ZfjwAMPLOQ1UQBZBVBdr30qHMqoZp2KkwBmw9hjtdDh+oTdoHwKoM+E6W7rTgz8yZJfBoTxWFwb7ImBNnUhC+BBm3ZZDv5cXJQUF6aYKZ47v7SrGCwT2zX1a07enLEsj+NhzemKfhW6UjhcnMxepoUtNzJMAf0YSpcpXsVM8XxIzRT3ag5kFhQPhUMoqyhDtCvKTHGHrGqKA+60b7QrqgW7+w00DoqrJev4HLbmlzlQX7RP2+VcM6RG9z2WO8qdn3ZFMyjuDtuZ4h988AHa2towZcoUHHvssfjjH/+IpqamQl4bBUhq/WkvV+SaG5oBACVlJVowhtkwzqXWifeypnhPe6LNIqURlJQl1wLFyZ24/ZvMxSyyE91sV132KTPFc+KXA2XEDCVdUJyZ4lnxy+RN7KviZA0ASit5wFe2/LLDA0gvUcb7cH5YldVw+wBGlfi8FV+z/2bP8qwWF8dVZkFxIHnv5hzIGbXsAQCU7GtXt8dYapY4oE8yEDFT3B6/jKvadifPwqoZnBIUZ7JBzlLvyV4mazIo7g7bQfHjjjsOc+fOxc6dO/HjH/8YTz/9NEaOHIl4PI633noLbW08qI6yl1p/2qugjKIoaK5vBgDU1tVq25GYDeNcanaEHzLFxYk6oM8UZ1DcHr8EYsSJmbiTg8EY5/wyyBcH7+JBm6UVpdogX5zckTWrmtNuBtR0QfGUTHGxJjEzEJ1Ja18fnO8AJNqY9+H8sCqr4erz1qymOMfGeeGX8wE6W41rigPJtmaQzZlMmeJuLHqIO+zMguLqAnU8Fueh1xb8Ml4WF7CqB+nblEHx3PmlnQEGxd1iOyiuqq6uxiWXXIIPPvgAn376KX7+85/jlltuwbBhw3DWWWcV4hopAOIWdRPdPnldXSWvravV3udWJOdSy6d4WVNcnZSLWU1AyqGMPGzTFr9M3sQJuNg/IyURLaDK8in2+KV2nlXwVJ3IsXyKfVa7Olxd7BCC3WKteICTt1z4qaa42MblVeX6oHgH78PZsswUd3FsrCufwprieeeXHQGWmeL77t3RrigUl+8vxSxTTXFXMsX3JpMJMtUUB8DDNi2I7RWC+22pEues4lwW4LgqH3TzInjXzgCD4m5xHBQXHXzwwbj11luxbds2PPXUU/m6JgqgtExxj24+LQ0t2usBdQO018yGcc6qJI6r2f9xRZusiZM5IKX+NLPZbPFLoE3sh6mLHWpAhsEYe/x4IKOYKQ4kJ3Ld7d3oi/aBMks9FNcPOwB40Gb+WNYUdztTvIuZ4oXgl4UPtQQdoH/eiv2XY+Pspe0I8CoxqCUZaDMrn6LEFe1AbMrMKFPc7TGWuMMuU01xgM9iK365J4u7m9OC4lzgyJlfkoUAoLGxUXs9dOhQV//sIMkpKK6KRCI4++yz8c9//jMfv44CyOpQRjdvPmrpFACoHZ7MFGc2jHNWJXFcrz29738hZornzqp8ipt9VeyHqYE2tV0ZjLHHL9sEzWqKA/qJHLPF7UldwPIq0GK1A4BB8eyl3ou9LJ+SWjeeQfH88EuJHNODNjk2zgurTHHPDtrsrw+Ks62zkylT3I1xs53yKWIglXXFzfnlAEZmiheWX85aAqA7w3HIkCGu/tlBkpegOFGurA5ldDVTfFcyU7x2mBAUr+Jg0CmrmuKuHhBlsu0XSAmKs6a4LX6ZpNvJFO/t7mVtRBssMyK8Cp6mlNkQayayrrg9flnsSM0iFnHylr3Ue7Ffy6eIWcbkjF/KamgLGyH9eJhj4/xIO9TNo/Mf1JriZVVliJRGdN/Tnf/Ae7Vthpnibh+0aaN8Cg+9tscvO/B0meL9zYPivV1c4MiGX8bPADPF3cKgOPmCZQDVxaCMOHAQT3PmwN85q5rifgme8qBN53xTPsUiU1wsi8N2zcwvdeKtMorFTHHxPk3m/DJ5S80iFjEonj2rbdxujpuAlLrxLJ+SN347aLO8qhyhcPL/s9KKUu1rlk/Jnl+SDdRM8dTSKQBQVs1SOdnwQ01xq7I4KmaK2+OXOZBV+RSWwsmdn5IOGBR3B4Pi5AtpmeIe3Xw69hhvMRODqdEOPmDsSG1Tzw6IEibk5f2MM4oBHspol1+yinWLHSblUwAGxe3wS41EsfZhak1xcSLHUkf2pJVP8Sj7kOVTCiN1G7eX23vF3QDlVeUoqyzTgqUMimfPsm68B+MoccwEAKFQSOvD7L/Z88OBqvFYXBsvGQVOxUxxJgfZZ5Qp7nb7ivfg1ACqSpcpzjrUpqxKSLpa0qpVaFOLTHG2ZXb8lHQgBsUHDRrk6p8dJAyKky+og4awwSq6m5N3se6amJmoyxTv4mDQjtSBoNcZTkD6hE4XFOehjLb4JftUlymesgNAnNCJNTLJmF8OlLEKnnJXh3N+6aupWcQiMXOcz1Zn/DI5B9LbOBQKJQ88ZlA8a2o7qm3rWU1xNSieUoIOAIPieeCHHQHd7d3a+Tup9cQB1hTPllGmuNv9WE0kCIVDabu1VMwUt8cvGcSWB22yfErO0mqKezi+UmuKDxo0CCUlJa7+2UHCoDj5gppVrA0YPAqgqtvyQ+GQLgijm7hz26AtVuVT/FJTnFu8nbOqfemXQ2YYFHfGL4M/q4M2mf3vnNVBm16VT0nd1cHJW/asJuduPmOBZJBMLKfBoHjuYiljYy8CMH3RPu1sjtTddkCyDzNQmj0/1I63CrIBKdmnnVwAsStTprgrQfH2RNtW9KtASPizRSy5YY9vyqcIcyCxZCQAlJazLXPlx5riLJ1SWAyKky9YZoq7uE1FzRSvqq1COJLsHpGSCErKEqtzHPjbE0/JfAl59ECxqikejoS1gSAn7vb45eR1MdidutVXFxRvZlA8E78M/mxnirN8ii1WmeKeHaDK8il545d+CyTbTmxPdRG6u70bisvXIwv1eWtYdsHNDOJ9UnfbAcmFrmhXlO2cpbRMcQ/6slhCMDXIBjBTPFuZaoq70Y/Vtk0tsyESM8X5LDbnlx146iJWWVUZIiX6Q3FD4ZA2t2X5lOz4ZXzV09ODtrY2AMCQIUNc+3ODqOiC4vfffz/GjRuHiooKHHvssVi8eLHpZ1esWIFzzjkH48aNQygUwt133+3ehZIj6qBBO5nbg5uPoijoaE4ExcXSKSp1QMgMCXvEgWDq1l9Xa2FaZIoDyUkedwDYYxlo8ypTvD8zxXMh3mND8K58lZiplnYorpC5xvr/9vhlUC8+M8UMJoBB8Vz4ZScAkAySiTsB1GdrPBbndvwspWaKe7EzS1eCzqh8irqTUmHZhWz54awW8flrGBSvYlA8G0aZ4m7243gsri1sVfYzD4qLmeLsx+b8cgaP2l/NasSzrFVu/FJWkodsuqeoguLPPPMMZs2ahTlz5mDp0qU44ogjcNppp2HXrl2Gn+/s7MSECRNwyy23YPjw4S5fLTmRWj7Fq2wYdYto9aDqtO+rA0LWnrbHKjvCL5niALd4O+WXAWFzQzMAoKSsJG2izqC4M1YHMnqV/V89QH8PZqa4c35pVzGLWC2toeI23+z5ZdFDURRt4UMsNcfyZLlT29GrA/qAlMPKDcZQXNjKndWhuV7sCDAKnjIonp2+vj7tdYkH5VN0i1oGix0qHs5ojx92yyqKkgyKm2T/MyieGz+0M8CguJuKKih+5513YsaMGZg+fTomTpyIBx98EFVVVZg3b57h54855hjcdtttuOCCC1Benj6QI/9ILZ8S8WDgb3bIpkqd7PEBY09q+RTx326usuoOZKwyCIrvC6j2dvci1hdL+z7ppU3ePBgo9Hb3Ys/2PQCAoWOHpgXaGBR3xi/bQcV7cGpJnPKqcq2dO1vZpnb4ZVeHeoBmaukUQF/Cis9WZyzrELu4GyvWG0M8lvjzyiuTz1ix/jSD4tlR29jLgzZ1u+2MyqdUMliaq7QdAV60c4YyOeKCF3fM2meYICR+v8D36ky14lW68z2YKW7KD+Pl3u5exPsS12GaKb6vHA7bMjupB5l7lVSiHrIJsHxKoRVNUDwajWLJkiWYNm2a9l44HMa0adOwcOHCvP05PT09aG1t1f1Dhadlint0CAmQUo6h1vyQmXhfHH3RvrTvk55R+RQvMsWjHcIhbxaZ4gBLqNjhhwFh4+ZGKPHEn1W3f13a93VBcQZQM7I6OMjN4Jq6gFHZv1J3pgOQqJHIXR3O+OVAKC1TvCo9KA4woylbaXWIPd4JADBTPN+sDtr0IoPYMFO8ipniubKsHe/H8ikcK9vmdfmUTO2q0h20yUxxU34YV+niFSZB8dLKRHv2Rfu0RWuyzy878Zgp7p6iCYo3NTUhFouhrk4fAKmrq0N9fX3e/pybb74ZtbW12j9jxozJ2+8mc2mZ4h5vHcyUDcOBf2ZG2RFe1BRXsxQB40xxcZLHiXtmfqh92bC+QXs9bPywtO9X9KtIZhUzUzyj1IUOr2oTq5niqaVTVGpf5YTcHr+0q9EhjCIGxbNjlSnuaokyk91YDIrnzipY6klNcWYQF4QfaseLZ3UYBdrEvs17tX1eH7Spa1ebB232djG72IwfgqV2FjqY+Z8bP7QzAOzevVt7PXjwYNf+3CAqmqC4W2bPno2Wlhbtn61bt3p9SYGgHbRpMGDwZIuo0WFCrJvoiFF2hJ9rigOcuNvhhzrFTVuT28mMguLhSFib1DEonpkfMl96e3q1+6pZUFy9L3e3d0Nx+SDBYuSHHQB90T5tm2+moDhLLziTminuVXkcMRAqtjGfrbnzRVkNB2Nj9uHsqG2ZuqsS8FFiUDUzxbNhNRcC3M0U50GbuUtNNhCLN3qSKW5WU7yCMYtc+CEBDAD27NmjvWZQvLBKvL4Au4YMGYJIJIKGhgbd+w0NDXk9RLO8vJz1xz2glk/xsqa4o3p6fMBkFE8ZOAAe1xQP6Qd9Kk7cnUmts+ZFAFUMdPcbnF7/H0iUUOls6WRQ3AY/1J7ubE62U9WAKsPPqH01Houjr6fPsD9Tkh8yXcRnpbjbSqQG1WK9McT6YoiURFy5tmKXminu1U4AMRDK8in55beDNrmLsjBSdwR4XVPcKFNct/jRxaC4XVa7ZgH/lE9h4pc9qckGoX2BcQXeZIqb1hRne+Ykdfzs1fhKDIoPGjTItT83iIomU7ysrAxTpkzB/Pnztffi8Tjmz5+PqVOnenhllA9apniRbBFlNkxmfqkprrZreVU5QqFQ2vfFw8CY/ZKZOBFPWz33yTZfIFlXPNoZ5RkAGfgh+7+jWThk0yQozlJHzqSVT/GgXXUB0wyZ4gAz1JywyhT3rKa4WaZ4B/trNtIO2vSiD7db77ZjwkjuLGvH+6SmuHgoMsfK9mXKFPfLQZusKW5P6rgKcH9u66SmOMD2zIYfkkoABsXdVDRBcQCYNWsW5s6di8cffxyrVq3C5Zdfjo6ODkyfPh0AcNFFF2H27Nna56PRKJYtW4Zly5YhGo1i+/btWLZsGdatW+fVX4FMxC3q6fnmMCGuujpieLiMBzXF1bYyqicO6LcDM9CWWWoAtUTsqy61q3h4pniopkh32CazxS354fBUsY1My6cwyOaIZfkUDxaw7NS+5LPVPqua4q6e22FWU5zP1pz57aBNw4QRlk/JWVqmuBdzoH336lA4xPMf8ihTTfFCj7HsJJEAQKQkgkhpYpcW29dcarBU/LcnmeIsn1IQqQlgIY+C4nv37tVeMyheWEVTPgUAzj//fDQ2NuL6669HfX09Jk+ejNdff107fHPLli0ICwOJHTt24Mgjj9S+vv3223H77bfjlFNOwYIFC9y+fLKQdtCmx1sHM24R5WFCGRmVT/E6U9wIt3g7k1o+RQyK97mV0bQvS6K0ohQlZcaPscra5ECxs6UT/Yf2d+XaipEfak+rh2wCmQ/aBNhX7fDDYofTA6E4ebPPN5nirCleML4oq9GRYWzMAxhzZrX44dq9uj1xr67oV2G4qxJIPIM79nZw8cMBwwQhF3d82C2fAiTu3129XezHFlLHy4A/M8W5Ay83cZN2jiuKqyVgxUzxgQMHuvbnBlFRBcUBYObMmZg5c6bh91ID3ePGjeNhXEVCyxT3sG5ixvIpnLg7YlQ+xe2a4vFYPJkpbpD9DzD71KnU1XNxkt7n8oDQKuuFmeL2pZXZ8GBC3tGSOSgu9lVu384srSyO13VqTQ754rM1O2k1xT0orQFYZIqL/bWd/TUbfgiWOskUZ8JIdlIP2vTiXCV1XGW2+w5IJgf1dPRAURTT4DklZcoUL/R8yG6mOJCYJ3W1dnHRw4IvyqfYyRTnuConRjsCIvuC4l6UT+nfvz9KSooubFtUiqp8CskrLVPcg8mdbuBfbTDwZ01xR6zq6HlyyBszxfPCqnyKG5niiqJo5VPMBoMAg+JO+KHMhpgpbnrQJssxOOKHA1Q5eSscv9S81NUU50GbeZUaLPXyoM2SshLDnVni2IoHMGbHqnyKG3051hfTFpqtxlVqcokSV3hWi01WpSQBdzPFMwbFq5KLHmTMLIM49XuFZKdNdTXiOa5yzA9lcoBkUJylUwqPQXHyBe2gTS/rJgpZwkZZxdwi6ozVieuuZf93Wh8Qlfo+B4KZpQ4U3K4p3tvdi3hf4s+p6m+e0VRdm8w2ZlDcmh/KbHQ2O6wpziBbRn4ImupqihtkmQJccM6WVfkUN7f3mi0+l1WWIRROXBP7a3ZSg6UlHp63Y9p/xW36Xdymnw2va8eL92mrcZXuXs3xsi1+qSkeKY2gpNw601SdD8V6Y1z0MBHzQbBUVz6FyQYF4YeguKIoWlCcpVMKj0Fx8oXU8ilebvMuqyxDOJLeNfiAcSaeUmZD/LdrmeImtU5FDLQ5kxpAdTtTXAxw284Ub2VQ3EpamQ0Pdup0NDusKc5SRxn5oV3VOrWARe1LHgiVlbTyKR5liosLGeJzNhQOaX2Wz9bspAZLvTjDI2NQnItaOfO6drw4RrLMFGdykGN9fcngcokHJULVrOLKmsqM5W50Z2exfQ2lPncB7zLFS8pKUFpeavgZ3biqm23plFVQ3K3Evra2Nm1RjZnihcegOPlCavkUL2uK28mG4cA/M6vDZdzKcLKTKc6SDM6IvdGL8il2MiQAlk9xwrLMhkv3Xy1TPGTerqxR7Iwf2lXsrzxoM7/8ftAmkOyzfLZmxypT3I3nbTwW19rXbGysC5SypnhWLDPFfTSuYqa4c345aDPTIZtAys5ZznMNpT53Ae8yxa3alDt4cmO0I0Btb7faWTxkk0HxwmNQnHwhnjIg9LKmuJ2gOCfumVmVT/Ei+9Rs8FBSXoJwSeL/Nw7yM0s7aNPtoLiNGsWAPije1dJl+jlKzygOmXyvkNS+WtW/ynCnDsBdHU5Z1Yr3onyKaaY4n61ZSc1Y82LRA7A+u0MMivPge+fUfupVprgYGDMbG4uZiqwpnp20gzZdLpNjdweern48g6a2eFk+JdYbQ293IiCaqZ44wEUPO+I+yBRXx79WbcpxVW780M4MiruLQXHyBctMcZcOmVEHDqa1p5kN40jcYjXdrQl7+5527XXNoBrDz4RCIWazOZAaiCmG8ini4gilS80oDgnt6lZf1YLiJodsAimZ4pywZeSH8hq6A6y54JxXVguUnpVPqTLOFI/H4ujrYY1aJxRFSQuWuv28tdN/Q+GQ1ofZf7OTuiPA7QVMMVPcqqY4g+LOGWWKuzXHdXLIJsBMcTu8rineF+1LLnRYzIF40GZu/FBTnEFxdzEoTr6gHbTpUT09McBip24i63NlJg4Evdp61LKrRXvdb1A/08+pJVRYpziz1JPX3T74SxzkZzoQSt0BwPIp1lIzioFk8KXXpcNT1UG+WT1xIKWmOBewMvLDQYxqfxXrS6diUDw7MSFgGvLoIFUgpXxKhXFQHGCfdcooscDLoHh5P+P+CyTHx0wYyU5q+RRxDuTGwrTtmuI8mN4xq12zQGHv1WL/tRUUr2TyVyZel0+xu9ChK5/SzfIpTqUmHYj/dmv8zKC4uxgUJ88pFqtxgDsDQl02TLWNbDYOFjKy2jLo1gNl22fbtNd1+9eZfk6duPd09HCLdwapAwW/1hQPhUJatjiD4tZSM8WBZPDFjTa1c8gmkFL/nwtYGaVmunhdlszskC8GxbNjWYfYzUzxfSUzSitKEQrr25hndmTPaAzlx0xxIJlBzOzS7KQdtOnyvdpusgH7s3OZMsUL2b52zvQQMVM8M68P2tTNgVg+pWCMkoWYKS43BsXJc4ar6C4PCO1kw0RKIoiURgDwAWOHUZaTmzXFlbiCbasSQfH+w/pjwPABpp9VB4JKXGHbZuB5+RQxoylD5osYFOdihzmjwV+pR0Fxq/IpkdIISspLADBLzQ6rmtOuHQi1L9hie/LGBWfbvC65oFLrxhsFTZkpnj2jYJpfg+LqDoFoV5TP2ix4vcAlnrtilWyg689cmLYlU03xQiZ+iYsdtoLiVdwJkEnqblnAw0xxq0NxK7m7PRdGyUJun4u2d+9e7TWD4oXHoDh5zqr2NODOgND2wH/fQ4Yr6JkZlU9xs6Z42+42bcvY8AOGW36WE3f70rJPhb7qyiS9Ndk+Yt1wI+r3xcOGKJ3XmeKdzcmFDqtMcQCs/++AZfkUF9pViSvJTHGLCbnuvA5O3mxLO5zPg6C4Ele0Ra1+A9NLlIlJBuJknjKLG2zf9jQobrKLEkiWT1HiCvqirB3vlNd92W6gjWNl54wWt9xK/HJcPoWZ4hlZldXwU6a4eAAyk72cY6Z48DAoTp4zrD3tZU1xi4G/OnnnAyYzqx0AClDwbKK9O5IrrANHDLT8LAf69lkF2lzPFLeYvAH6bcAsoWLOsqa40I8LRWybTAsdrP9vn9cHbXZ3dCdu9gAq+3Gbb75ZZZe6NWnrbO2EEk/8WUbndojjKWYeOlOM5VMA7vZwSlEU9TZpnBjkRju32Que6oKm7ezPdmTMFHcpKG41t1WJz2IGxY15Xj7F5gJWKBzSDtvkuMo5o2QhBsXlxqA4eS5uceMBPKgpbpUpvi8bhpO7zLysowcAe3cmg+JWpVMAHh7kRDxlQBgSSqi40VftZkkA+gArg+LmjAZ/pZFEqShX6sTbPDgISN6fo51RxGOFv7ZiZrWA5UpQXAi0WGWKqxM3gJM3J6zKp7hxLwaAlobkYdY1Q2rSvs9yC9krqvIpXNjKWqYSkm4eYB4uCevux6mYQOKcl3MhMbBtdtC1iIeZZ+b1QZviXCbTeFm9L3OnrHNWmeJuja8YFHcXg+LkOcNMcS9rilsMHNQBYV+0j1tEMzBa7Ii4lB0BAM0NzdprZornTyylfArgbqmN9j3tABIZEuGI9SNMrE/NoLg5q0xx14PiGbL/ub3XPqua4m4GWgDryVs4EtZqxTOgZl9qprgXB6nqdmSNSn/O8tmavUzBUr8GxXlfdsbrBBJAf/aD2YHIABe5smHYj70IildlDoqLiSRinXlKSi0hKf7bjb7avrtde220O0uk3pc5rnLOsKb4vvuzF5niAwdaxzEodwyKk+cyDQhdmby325u8i9/jBM+aVU1xoPAPFbFOcaaBg7itkO1qzShLwq0AqqIoaNvdBgDoP6R/xs+LA3zxMEfSs6op3utyUNwq8JL6ffZVa2n1/z1cbM50yBcnb8754aDN1qZW7XXtsNq073MXVvZ8kSne5mwXJcA+7FSmoKkrO/BsHIgM7Aus7rs0lk+xp68vmUDl9q4esZSR2EfNiOdCcMxszOvyKWpiEGC8O0uklU/hWS2O+ammeGVlJSorM58JQLlhUJw8l+kwIVcGhDZPXhcHjGIZB0qX6XCZQrerrsxGhuxTBtrsSy2fIv670JP0zpZOxHoT/19lGgwCKYtYbWxXM15niuvqmTrJFGeQzVLqApbbh+I6KYvDoLhzVjXF3UgmAICOvcnAidFBm3y2Zs8PB23a3cUjZqEyU9yZuEGigZsLmLG+mBY8zbR4GQqHtLZmprg9YlC81O3yKR3OMsXLqsoQKU2UzhPv7TKLRmN4++2N2LPH3pze6/IpamIQkDnhq7wy0eZ9PX2I9RX+fCCZ+KmmOEunuINBcfJcpsOE3M5UtHvyuvgzlC5TrfiCZ4q3Oji8j1tCbbMqn1LoQExbU3IwaCcorquPyHY1ZVhT3KvyKZlqinNXh22pGU2uLza32t8BoAXFeUifbamZ4m4fpAros9Z40GZ++eGgTbv3ZtYUz16mXZWFHleJz9FMz18geS/n89ee3t5kPWf1rBa3Fj3EvmgnKB4KhVA9sBoA0L63PcOni188rmDatL/gf/7nL5gy5WHs2pV5IcAqU9zNEpJlVWW6+64RcdzF568zljXFGRSXEoPi5DmjLAm/DvzFLAoOCK0Z1op3caCv1pAOhUMZD5jRZZ9yS6glL8untDYmt+rbCYozIGOPnzLFWT4lf6wO2nRlsVkIimdamFQnd33RPh6gapNVprhbQXExm1ANpojYX7Pnh/Ipah8ury63PMNDFxTnwpYjXtacBlJ2atkJilcHOyje1taDn/zkFdx007vo68vcBzNlihdyLqTLFLdx0CYAVA9I3Mc7WzqhxN15jnjltdc+x/vvbwEAbNrUjMcfX5bxZ8T+qNbfVxc73Eg2UJODagbbmAPVMJEvW4Y1xV3MFO/q6kJ3d+Iey3ri7mBQnDxnFDwtdXvgv698SqYAqq58Ch8wlrw+PEidzFXVVlkeHARw4u6E0SEzbgVQxUxxOzXFg5wpvmLFLhx++AM49dTH0dpqvSBglPkitqlS6L7aZi/won5Gxb5qLbVdQ6GQqzsAxN06GcviVCbblZmm9ljVFHdjcg4ks9bCJWHDgFqQ78G5ypQp7uZuj4z9l+VTspbxXKVClxoUz/TIUD4FSI6XY70x9EX7MnxaPtdd9w7+9KePcf31C/DAAx9l/LyYKV7i8q6enq59fTGUrC+dibq4qcQV6ee5//znGt3X7723JePPpC5GA+6dwRPtimrjI1tBcc5ts+Z1TXHxkE1miruDQXHynFGZDV35lFjh62Bph8z0tz55nTXF7TPMfnFxQqdmimeazAHcYuZEn9HquVuZ4k0OM8XFdg3YDoCf//xNfPbZLixYsAl//vNSy88aZf+rmS9A4Xd1qPffTFniqZ9hX7UmtqvbC1hASqZ4f3uZ4gCD4nalTs51AVOXy6f0G9gPoXD62CkcCWtty0m5M17vohSDYnbPBAB4qJtTYiaxFjR1sS/bLR+pCnqg7dVXP9deP/30ioyfNyqf4nZN8fKq8ozJQSrdYZuS1xXfsqVV9/W//70lYxJI6mI0oC83WMgkEif1xAHubs+FYaa4i+PnpqYm7TWD4u5gUJw8Z5Qp7vYWUTWjLdPEnQ8Y+4wOiXJrINgX7UNvd2IgmqlNAQ7ynegTAjEhlwNtulPXbWRJBPVQxt7eGN54Y7329ZIlOy0/b5UpDhS2XRVF0bZvc0KeX+o9NmzQV11ZbHZw2DGD4s6J7Qu4P26Kx+LoaE4ETYxKp6jU+3CQ7sH54PXYuKezRyufkHFRq4rlU7KlC5p6uKsSACr7ZX4GB3m3lqIo2LEjGZj89NMGxDOUGDFa9HBrJ4D6LM1Ue1pUNSDZ12WvK759uz4ovndvN7ZvbzP5dILaH40yxYHCLmK17xbO8BhsIygujpfbgtVXc2VVVtKNXVo7dybnbSNGjCj4n0cMipMPGG0dFLMUCz3wF09ez5QNw/Ip9hm1q1s1xZ0EY4B9W3/3XVrQBvmq3bs70dyc+e+u9kexj7o1UFCz/wHrIIxK3NIdpK37q1c36b5ev36PyScTrOrEA4UNoEa7oloNaTsTch6Ka18sJWgKJPutK4vNLfbLp5RWJrd2MyhuT2rGmhf1ptWgqVXWGg/my47XB206GUdxsTJ7hgcxunj+DjPF7du1qwMdHcn2amuLYuPGvZY/Y7To4dZBm1qmuM164oA+U1wMwspo27bWtPc+/bTB8mfU8bLRuAoo7HhZzBS3kxgkjqmD1ldzZZQprs11FaXgZSXFoPjIkSML+mdRAoPiVBBdXV34xz/+gQULFmT8bKbyKb4d+HPV1VKm8imFHAiKwZhMB7wB+2rJ7wugBjHQ9t//1mPkyDsxevSd+Pzz3ZafVfuj2EfdyhTvbHbWruFIWMtgC1KW4rJl9bqv6+utJzZeZorrDvmyMSEX272t0TqjJ+isal+6uQOrvLockZKI5WeZKe6cVfkUN9pXzCK0WqRUD+br7e5FrK/wOxRk4XVQXDwTIFOtaZYWTNq+vRWXXvoSfvvbBY4PYjQqn+LmQZtOS5gFLdC2YUN6APyzz3ZZ/oxX5VOUuKI9S8UzOzKpravVXjc3NOf7snyjq6sXe/em//+bqT2Nyqe4dV8Wd8vaKp8i9NWu9mDfl52yyhRP/X4h7NixQ3vNTHF3MChOBXHBBRfgnHPOwamnnoq5c+dafjbTFtFCH1zhJEtC/D4zxa0Z1cN0a8ugkwPeVEHLZnv33U04/PAHcMIJ8zB58kOIRmPo6OjFH/7wb8uf8zIorm7VL6sqQ0lZia2fUQMyQVrsSA2KNzV1mnwywbCmuEuDfN0hXzYm5ANHDkSkNDGxbNhondETdFaTt0I/VxVF0Q7GtbOrg0Fx51LbN+J2UNzmBJ3nAGTHaLedXxNGODZO+sEPXsC8ectwww3v4sEHP874+UzlU9w8aNPWzsp+wSxLBxgHxdevt84Uz1g+pUDBNfE56iRTfMDwAdrr5vrmPF6Rv4hlUg4+eLD2+tNPMwTFDZINSl2KWahzIIA1xQvNKlMcKPzzl5ni7mNQnPLu888/xz//+U/t6z/96U+WnzfKFHcrIAOkDPwzlE9hprh9Rosdbg0cnBzwpgpS3dNoNIYLLvg7PvtsFz78cKvue1u3pm8nFBkFxdV+61ZQvHpA5iCbKkjtqkod1Hd09KKrq9fk05kzxQvaVx1OyCMlEQwdOxQA0LSlKfBZiVa8zBTvbOnUznUYOHxgxs8z09Q5zzPFbQbFg1yDOBdG57J4FRS3c1BuOJK4tiAHxdeu3Y133tmkfT1v3icZf8YwU9yrmuIZ5kBAMtEACF5/NgqAr1tnXZ7OsHyKC+3b05kc84o1/zMRg+It9S35vCRfEUunTJs2QXudqT3jHmaKO90FzZhF9jJlirsZFB8+fHhB/yxKYFCc8u5f//qX7uvPPvtMN+hL5fVhQuLp2pky2iIlES2jjVuRrBlt/XWr7pqTWrYqdfDQF+1DX9T8/1cZLF683bSkRmOj9WnzXmWKx/pi2qDOzmBQFcSt+xs3Nqe919honi2eqaZ4QTPFhQl5pi36qtFfGJ14oQDv/e29QlyWFIwyxUtdCoq3NiYnnP3r+mf8vHifFnf6kDmrmuJuHAQljp3EOrSpglxuIRdel08RsxIzPXNDoZDWh4O8qLVgwSbd1598Uo8VKxyU13Axk1jFmuL25ZIpLh5O70b5FDEo7qR8SmX/Sm2eK3P5FPGQzf33H4i6usT8f/Nm64UAq7NaAPfmtnbmQeIiV9D6aq68zhRvbGzUXg8bNqygfxYlMChOebdw4ULd1319fbraSKkybREt5AMG0A/87WSgqoGbIA/87TBsV2EQ4VqmuM0AapAG+mvWJA9iPPHE/fDjH0/Rvt61K/uguILCDfDFNrVTjkEVtK2+8biCLVvSB/VWJVSMMsXdOuxY7Gt2stQA4MTvnqiVz1n22jLtoE7SMzoQSiufUuDnqnhAl50DocT7tDjxI2Nen8UCOMgU78dM8WxkLJ9S4GCpbmFrqP2FrSBnii9evD3tvb/9bbnlzxgetOniApfjTPEAjZVTiQHwcDhx37WbKS72XTfK44jjXSflU0KhkJYt3lzfrB2mLBuxfMro0f2x336JWuo7d7YhGjUfH2Uqn8JMcf+KxxW88cY6/Pe/9Rk/63WmuBoUr66uRmWlvbkR5YZBccq7jRs3pr23adMm089nzBQv8MBfFxS3EWxTB41dbV0FP33Yb+Jx+ycuG2399etqOqDfEip78PTzz5OD+P/935Pw4INn4AtfSJSkMDp4RmQVFAcKN8B3krUmClK7AolDNY0G9FY7APySKW43KF5bV4uDph4EIDEpb9zUmOEngkltt1KXd3UAQNvu5ITTVlBcKM/ABefMvA6YAvqguOVBm6wpnhWvM8UdB8X33b+jndHA7MpK9d//pp9z8cQTn1qOmzPVnC50+RTxQGS1BI4VXaAtQGe1AMlM8WHDqjFpUh0AYPPmZvT2mv//rgbFxfmPGwepigsW4sKkHWpQPNYb0x2oLBOxfMqoUf0xduwAAICi6L+XKtNBm4VM+FLntmWV9s5VKq8qR7gkcW3iHCqorrzyNZx++hOYMuVhzJ+/wfKzmcpKFvr529SUSF4bOnRoQf8cSmJQnPLOKCi+efNm08+LA0J18u5WliLgPNimTv7iffFAZUm8+urnqK29BYcccj927GjL+HnD8ileBNpslk8JUjabGBQ/8MDEATMDByb+O3V29lpmSWQKiheqXTubkwsd2dQUB4Ixgdu0qdnw/d27zQONhoM/cVdHARewxDJUdg7aVA0/IFljr3Ezg+JG1MmZ+DxVXxf6uWo3i1ilO6iPQfGMvA6YAinlU6wO2qwObhAtF0aHlbvZxupBuQBQMyTzwpbYh4Oalag+f8eM6Y+vfnV/AIlzWqyyiTPVnC54+ZR999tsdlX2tAdnkaurq1eb+0yYMBAHHDAIABCLKabjLiA5xzXNFHehfIp4D7ajdnit9lrWwzbFTPFRo2owZkxy4c8qKK7VFDcpn1LQTPF98yC7fTUUDmlJCa1N1udFyW737k7cf/9HABJ99q67Fll+3stkoVgsht27dwNgUNxNDIpTXvX09BiWStm2bZvpz4iTuxKDG0+ht3l37hWCbTYyxcXameKkUHa/+MWbaG+PYu3a3bjzzoUZP2+UyabLFC/kwEGoSWv3oM0gTdzXrk08bEtLw9qWwQEDkn//5mbzv7/hQZsuDBR0i1cD7GeKi0HxIGQpipOzww9P1qGzatNiyxQHgKHjkgPFoATFW1t7sHGjdf1SkdUCViHvv4A+U9xOUJzlU5zJmCnuYvmUkrISy+35QS63kAuvz9tRM8Ur+1eitLw04+d1h+UGsIRKR0dUK1M2btwAnHTSftr3jMqqqAwP2nQhkxgAlLii9UnbCSQBPThXXNg48MBBOPDAQdrXYqJJKi1T3CQoXrCa4mL5lKrsMsUBYO8O+2OOYqLWFA+FgBEjarSa4oB1GUnDsnQuJJHEY3Htvupkt2z/IYlgf2dzp/TnZVlJPe/h44/Ny/oC+uerUeJBIWNTe/bs0XYXDRkypGB/DukxKE55tXnzZq0jjxw5UntfXfEyYjQgdHWLypZkfWWrw6JUYuBczIaT2e7dnVi1Kvnf6e2303cDpDKqeVrq0gMlm0zxoEzc43FFG9xPmDAQJfu21g0cmPz7791rPqH1KlNcV+ao1n6muG6xQ+J2VW3e3Ky9njw5mU1t1aae1hQXMgrt9lUAGLJfcqC4Z5t1TU8ZbN3aggMOuBcTJtyL//s/e4eLqvdYo/IpcUUpaLClY0+yv9opn1JaUYpIaeL/OR60mZlReTIxc82VoPi+bfXVA6u1A+SMBOXZmm9e7gZQ4oqWWagGVTLRBcUDuNtDPKBv7NgBOOaY5Bxo6dKdpj9nVFPcjZrTQKI/qjWj7S5KBymBRKQmkwDAQQcN1gXF7ewE0JVPceFeLbaNk5riADB41GDt9e6t5vP3YqaevTNsWDXKyiIYNiw5r7AqN2i1Aw8oYHsKfdVJYpC4y0dMVgiaDz/cqvu6oaED7e1R0897WVNcPGSTmeLuYVCc8kqsHX7MMcdor8UOnsooKO5WmY31H69Hw4ZEDcBh44ehtCJzNoyY9RaUoHjq6eorVzYiluFwO6MsJ9cyxfdlGlbUVNiqkQgEp+7p9u2t6O5O9Dm1dAqgzxS3qivui/IpTg7aFDPFO+VtV5Va8xIAjjwyGRS3kykeArTglls1EsWMQidBcbHGbRAG+o888gkaGxN9YM6cBZY1TFV9RpM3lw5wa9vjLFM8FApp2U9BDKg55XX5lFhfTHvOZmrfoO3WyRcvdwN0NHcg3pf4/XbqiQP6+3cQd3uIC9Jjx9bi0EOTwYzUMbQoU/mUQi5eZrOrMlIa0eZKQSqTkx4UT46fP/88c+KX2HfLXDhfSbzXOilNBwCDx8gdFO/q6sXOnYn5+4QJAwEAQ4fayxS3OqsFKNx4WXdWls2+Cujv3y0NLRaflJvRbg51t4ARcXzsdsKmWk8cYFDcTQyKU16J9cSPPvpo7bXYwVN5lSmuKAr+9fC/tK+PO/c4Wz8nBuSCUj4ltYZ4T0/MsuYaYFI+xaVMcXXw4OhARmHQKHOmor6eeDLTRcwUtwqg9hoExcUBfrRA7drRkt1Bm0ELyIiT7ylTkplqVgsdmQ4OKmj5lH1B8XAkjLLKMts/V1ZZprWtWPtWVuJWz3hcwSef1Gf8GaO+6tZiR/vuxISzsn+llgGeiTrR62zpDNwh1k5lCpgWcsED2LdIua+JMu2wY6Z4drxc+BAP2awZmnmnBxDMhBGRmCk+btwAjBpVg7KyxL3PKiie6aDNQtYUz2ZXJZDs00Eqk7NmjT4ortYUB5yXT3EjQUhXPsVhpvjAkQO1hKKmrebz92IllhkcPz4RFNdnipvPAdW5q3gvdiORTxcUdzAHGjQq+f+puDM+aIzuwWJd+VSZzlpiprh8GBSnvNqwIXma79FHH61lHeYSFC/UgKF+XT3qP08EFoYfOByTT5ts6+fECaCsp3KnMjpYs77e+u9uWD7FhYFgrC+mTbydDByCMqETM1oOOiiZDaIetAmYl9qIx+Na1pLYRytKkqegd/cVpmZdV0vymhwtdgRsq6+aKT5wYAXGjx+gvW8ZFN/XF3UHB7lcU7yyf6VlCQYj6rbQ1qZW6YOoy5bpg+D//veWjD+TKaOpkAvOava+nSxxVWVt4h4U642ht7s3w6eDzetMcXHsUz3IeueOeA8OwsJkvhgdtOlWiRxxodFuprhYJimIh7qJ5z2MHVuLSCSMceMGAEg8l82eUUblU9yqKa4LitfaD4qrY7DO1uAsYIpB8QMOGIS6umr071+e9r1URuVT3M4Ud1pTPFISwcCRiWDx7m27tbIdsti4sVl7PWHCAAD6oLhVprhR+RQ3ak1nGxQfNj55ttCujbvyek3FIh5XdLtoVVbJfUZnLblVVpJBcW8wKE55JQbFDzroIAwcmHioOg2Ku3HjWfPvNdrrKWdMQShsLyAjTvKDmikOJOpxWTEsn+LCwEEc5GcdFN8tb1Bc3AIqZorbOWjT6FBcAKgQ+muhguK6bb7MFDfU1taDrVsTg7wJEwbqFjosy6f4IFPcySGbKrXWbV9Pn9Rt29TUmZbR8umn1pMbRVEMSx25Vfsytq+8i5164ipxS3AQyy844fVBm+LCcaaFD2aKZyfTQZuF3G3X3NCsvbYdFA947VoxMKqW1lBLM3R29mqHcKYyPGjTpcUPcVzl5Bms3qvjfXFEu8zr8sqiry+O//43sTA9YcJA9OtXhlAohEMPTZxtsmlTMzo6jP87GJVPEedChdpdme0h5qohYxJ/t76ePjTXN+frsnxBDJCqmeJDhybHH2aZ4maJQW4kfOmC4g5qiuuC4huCGRTfubNNKxsqsgyKG2WKe1A+hQdtuodBccorNSgeiUQwZswYrTM7rSnuxo2nfl0y827ClAm2fy6IB20aBcWtVtIBk/Ipbg8cHNRdC0pQXF8+JZkpXlubDB63tBgHGMW+WupyprjarmI9SzuCFBR///0tiO/L6Dn22FGori5FJJIYzFkdtGl1IKP4/XyL9cUQ7UxMJCtqnNW8BPR9VuYSKkaHtIkHHxsR779uZzQ5CZiKxExFBsWteZ0pLiYEZCqfUlJegvC+A52DsFvHSmNjh2HGmhGjNi4XnrU9BQyKN21O3l8Gjx5s8ckkMSje3iTvGMrM6tWJ/2YVFSXYb79aAMCIEcm+Yba70qimeCgU0vpzT4HGVIB+8cLRvTpg9eNXrNiFrq5EO4gHqIp1482yxY3Kp5S5MBdSd2uEwiFH5/Co6g6o017v/Nz8oNhiJO7qUBeuqqvLUFWVmFuYzW/N5kBuPHvFZ66TxKDK/pXavblhY0NgdnaIxNIpRx+d7L9WB6oaZYrzoE25MShOeaUGxffbbz+UlpZqmeJtbW26h4koY/mUAg381QM2SytKMXDEQNs/V1VbpWWVBztT3HrSk+kAVb9tMSurLENZVaKmsXhInGzUoHhFRQlGj05mgNXWZs4UN2pTwN2geFVtlaMyG0Hauv/228kzHb785fEIhUJatridOvFi8NSN4It4SFc2mUxi2YaOZnnvxR99tD3tvVWrGi0nN2Z91Y1Bvbio2G+w/UCLuIjJwzateZVMoHKy8BEKhbT7cJAzxbdta8Vhhz2A/fe/F7fc8kHGzxslFoRDIS2gVqhnLaCvPTt0rL1JeVX/Km3xI2jlU7q6erFuXWJsdfDBgxHeN0cYPtxhUFx8Bu97XcjFj9ZdyXaqHVZr++fEsXUQ7tWLFm3TXotB8YkTk1mcK1caJ38ZZoq7cA6Pei5A9cBqrT64EyMPTv49d6zZYfHJ4rNhQ7P2WiwzqGaLmwVLzcZVbsxtxXuqkx14AFC3f2KBo7utG3t32FuUlYm4EC323z17Mu+gBdxPPGBQ3BsMilPe7NmzB83NzQCACRMSmddqUBwAWlqMTz02O2RGDXsV4sbT09mD5p2Ja62bUGe7dAqQOBBOHRAGpaa40WEUmTLFjVbUXT+h20FQHEgONGTNFO/ri2uDg/33H6hN3AB9+ZSWFn8FxRVFyerwVECfKS57luKHH27VXn/pS+MAJNvVqqa4UaZ4pdCmXb2Fqe8sHtKVTVBcd76DxLt2/v73VdprNauppaUHe/ZYZP8bZB+mvi7UoF7MPnRUPkXo2zIfdpwPhiUXPAqK28lCVEuoBDko/sgjS7Vx03XXvZPx80aZ4kDy3lyo+zIANG5OTMqrB1bbPoAxFA5p/T1o5VOuvfZfiMUSQZSjjhqhvW8nKJ5pXFXITHHxQFW7ZXKA4O3q+fDDZFD8+OPHaK8nTkwGrIyC4rFYTFu8Nq0pXqA5rpq05STpSzTyIHmD4mqmeElJWJccNHRo4lnW1NSp7boUmS1guREsbWt0fs6DavTE0drrrZ9ttfiknMyC4rt3m9+7vMwU37UrWeZm2LBhFp+kfGJQnPLms88+014feOCBAIABAwZo76kB81SmK6/7HjiFuPE0bkoOXsR6W3apwZj2Pe3SHUCSSlEUbN2avqCxa5f1QFhs17DRQZs+yxQHkhlv0a6olHUS163bg2g08d9dHMwDzsunuBkUj3ZFEe9L3AdyCYrLnimubhEcObIGgwcn/jsNHJgIRrW0dBsO8gHjTHFXDk8Va17aDLyIxGCcrJniK1bswiefJEp9HXPMSEybNl773qZNzaY/52mmeLblUwK2JT8XRpPzQicTiHTlU2y0sXof7unoCeT2bQB49tmV2uu+vrhlSStAf9BmWAiKq/fmgt2X27q09h2yn7N6pmpQvLO5E33RwgVz/eTjj3fgvvsWAwDC4RBmzDhK+1625VOA5G4tNzLFQ+GQo3t10Hb1qAkH5eUR3aKHWD7FqKSZncXpQmSK79meLJNot/xRqpohNdpOr51rd0pz3+7ri2ulbiZMGIiIkEU/eHBiDKIoxslBZuVT3CgNqi5gOe2rALDfYftpr7d8lvmQdtmIB6tOmSIGxc3vXV5mitfXJ8b8lZWVqKlxtiuAssegOOXNxx9/rL2eMmUKAH2muNOguPq6EA8Y8dCQQaMHmX/QRP9hiVXaeF9c+mzxHTvatCDpF784Sns/04RO3DIYMjpo02eHkQD6rEYZM50++yy5+nzYYfrFIDsHbXoVFM9loSNSEkFJ+b7JpcRB8fb2qJaFqGYTA8l2VRSgtdX472+UKe5KUDzHTPHqAUJQXNJSVn/963Lt9Q9+MAljxw7QvrYKitvJaCrUPTjboHjQAi250N2LhYCp2r6xAgcwnLaxmimuxBUpF5wzWbt2d1omqThRN2JUPgUAKksTdW+7CnRfFuuJDxnrMCgu1hWXePeOSlEU/PKXb2lf33rrNEydmswkziVTXCufUqB2VhQFe3cmFtJrhtQ4KrGh29Uj+QJmQ0O7Vhrn6KNHorw8OTYaN24AyssT7fT55+k1xTMlfQGFSRDavTV5LYPHZBcUB5LZ4t3t3bpAezFbu3a3dujiEUfU6b4nHk5vtLtSHFe5nWyglk+pGeysrwLAqENHaTvit34a7EzxAw4YpM2L/JoprgbFhw8f7qhcKOWGQXHKmzfeeEN7rQbFxUzxvXuN61hlCooX4sYj1uZyug0JAAaMGKC9VsuwyOqZZ1Zor089dRzU+7PV1n0gcx09N7bui0EzO2qGJid0MrbrJ58kD8tJDYr37+/fTHFx0pVNRrFWz1bi8iniwUH7758MiouDfNPFjn19scQg8AIULviSa6a47nBcCRcn43EFTz75KYDENt8LLjgM48YN0L6fTaa4G+VTxPJT2ZZPkTXzP5N4XMG7727CmjXWB6nqMtYMFj0KXj5lX38rrShFWWVZxs+rQXFA7sVJMy++uDrtvUwHbpplmRY6U1wtnQIAQ/dzVs9U9sSCVC+//DLeeWcTgESAdObML+q+rw+KG9/TTGuKFzhTvGlLk1bOqG5CXYZP6+l29Uhe6mrhwmTplBNOGKP7XjgcwogR+w4xbEhvX7O2LXT5lF2bkgkwOQXFD0lm1W5flX62STESDy5PDYoPGpR8ThnNcc3as9A1xaNdUS3xQ03Kc6Ksskxb4Gjc3Bi48ZU6Pxo+vB+qqkq1HQF+zBSPRqPYvTuxqDV8+PCC/BlkjEFxyovly5fjzTffBACMGzcOkyZNApBbpnhpASd3utpcQ7IIig8foL0Ws85loygKHnpoifb19OmTtQMZrWoUA8nBg9uHkbQ0JEu91NbZPzgI0E8AxYmhLN5+e5P2+rjjRuu+V1oaQXV1IhAqU6Y4kNwx0LG3A/FYYYNFXhFPVxczxdXyKYD57g6vyqeIB9raqUucSlz06twr38T8ww+3YuvWxALuV7+6P4YOrbYdFDcLqLlS+1JoVycHbYpZpuIzOkjmzHkHX/rS45g48U94773Npp/LlLHmVk1xuzsBdGc7BLCu+AsvOA+Kmz1vC11TXBcUH+cwKC70YfEQR1n98Y9/1F7fdddpuixiIIuDNl3MFF/+ZnIX0rgjxzn62SDt6hHPahHriavq6pJ1qHt79fMaN8qnrF+/HldffTUeeOABrcRJ/ef12vdHHDjC7EczGn1ocp6wbdU2i08Wj/nzkwfSp86DBg1KLvYYBcW9KksnZv4PGeNs945qvyOEEiqfBqeESldXL3buTNx71UNV1Xbeu7cLMZM5oZopHgK0bG03xs9iPXEGxd1VdEHx+++/H+PGjUNFRQWOPfZYLF682PLzzz33HA455BBUVFTg8MMPx6uvvurSlQbLHXfcob2eNWsWIvsGc/nIFC9E8LStSTgIbIjzek0D6gZor2UOir/zziasXZt4GH/pS+Nw8MFDdA8TK2q7ul13TW2PSGlEdxCfHeIEUMy0kMHKlY34z38Sg9pDDx2CkSPT/79XFzz8dtCm7lA3h9n/QPKgoVhvDC27jA/8LXZigMWofApgvpCVqXxKoYIv2WYUq8TySDJmij/11Kfa6+9+9zAASAmKm/+/bGfyVqiFSbVdSytKUV5VnuHTSf0G9dO2Bbc0ytlPrbS19eAPf/g3gETG+MMPLzH9rFltUzeC4n3RPnS3Je4ldp+xYqZ40ILiO3e2YdGi9IDSjh3WCz9muwHUe3NvPK7b4p0vuvIpDmuKDxyZfPbs3p5eTkIm3d3dePfddwEAY8fW4qyzDk77TL9+ZaiqSiQb7Nxp3N6m5VOETPF813OOx+L475v/BZCoUTxp2iRHPx+k8in//rd1UFxc+Ghs1P+3MFu8zFf5lIaGBkydOhV33303rrjiCrz00ktQFEU7GLOipsJxcpBo1KHJkpkyZIpHozG8+urnAIDKyhKccMJ+uu/ry6dkyBR3cW7btDV5T84283/spLHa660rglNCRUweUedG6plLimKeBKZmikdcTipRS6cADIq7raiC4s888wxmzZqFOXPmYOnSpTjiiCNw2mmn6VZVRB9++CG++93v4tJLL8Unn3yCs88+G2effbbuQEjK3bZt2/Dkk08CSGSGT58+XftePmqKFyRTfHeOQfGAZIr/+c9LtdeXX340gGTm6d695gf3ASblUwockFEURWuPAcMHaDXU7BKD4uJhrIUWj8fxi1/8AqNHj9YtMOXTTTe9B3Ve9cMfTjb8jHrYpt/Kp4h9TOx7dolbgzd9sin3C/Kh9euT9R6dZIorimKYKV7pRqZ4jouTkZKIto1btu2gfX1xPPdc4mC+iooSfPObiYDL8OH9UFaWaKfNm5tNf95OTfFCl7ByehhUOBLW/j8IQpZpqiee+BS9vck2+eijHaaf9TJTXOxrdttYLWEFBC8orgZhAOCCCw7TXqtnQJgxa2OxtFUh7s0NGxoSf07/Ssf3ZfFQvz3b5KhBbGbJkiWIRhP18b/0pXEIG4w3Q6GQlkls1t6m5VMKGGjbsGSD9vw98LgDHd+rxfIpMmeKd3f34eOPE/fhAw8chKFD05My1PYFEvXHRV1dyf82VUK/DYdCWkmGXDLFb775ZjQ2JucqL730Enau3amV2hjzhTE51SSu6FehLYzVr6tHd3dx37tffHG11g+/8Y2DUFGh39nhJFPczR14ukxxhwuVKnHHgLjwKTtxF62aKa6WTwHMS6ioC84RgzNbAAbFZVRUQfE777wTM2bMwPTp0zFx4kQ8+OCDqKqqwrx58ww/f8899+D000/HNddcg0MPPRQ33XQTjjrqKN12N8rdvffeqz0orrjiCvTrlxxciZnijsun7BsQFrKmeEVNBUrLSzN8Op2aeQpAO6hGNt3dfXj55bUAEgOFs88+BEByJT0eV9DWZl4bNFNN8UKsprc0tKC3OzHBENvIrvKqci2ronFTo2unrb/44ou44447sH37dlxzzTXYvNl823w21q1bh2efTdSGHzKkCj/5yTGGn1Ozitvbo+jrS28fr4Li9euSgwQxE82uA754gPZ69b/Tt7HLQBz4iTXF1ex/AGhrSz/gTjzMze2DNsUdANlkigPJsiuyHbT55pvrtayzM888CDU1iQWrcDiEsWMT96hNm5pN71FmBzEW+lyH3p5erWZ0Nm2qnvHR2dKJ3p7C7FDwI0VR8MADH+veW7duj3YgWCqzLOKIC0Fx3c6dQfZ27gQ5U/z119drry+5ZLL2OlNQ3CwAo9vFk+d7c2dLpxYsrZtQ5zigNmhU8uD63dvkzhT/4IMPtNcnnrif6eeGDUv0kd27u9LKawCZM8WB/JdQWfb6Mu315NMnO/758upybVePzDXF3313E6LRRJuddJJxG9fVmZfIEYPiYqIBkKwrnu1caOXKlXjwwQd173300UdYu2it9vVBUw/K6neL1GzxeF8cn3zySc6/z0tiOVA10UuUKShumvlf4ISvfBycWjOkRjv/o2lLcILiK1YkE2cPOijx304fFDe+f2XKFC/UbncGxb1TNEHxaDSKJUuWYNq0adp74XAY06ZNw8KFCw1/ZuHChbrPA8Bpp51m+nkA6OnpQWtrq+4fMtfa2oqHHnoIAFBWVoaZM2fqvi9mijstn6IOGPJ9yIyiKNqgP5t64kAimF5Rk5jkyfpwefPN9WhvTwTRvvnNg7XsRHHQYFVX3ItM8RULkoeCjpo4yuKT5tRV+J6OHt3kv5Aef/xx7bWiKHjrrbfy+vtvuukmLav/6quPQ3W18cFoYgC1tTV9wcNsQFjIAGrH3g6s+886AIkAaDb19EYdOkrLePt80eeutaub1KB4v35l2iQc0B+gmm2bFuqgTbWUTUW/CpSUlWT4tDG1fENvdy+iXelB/2L1xz8mS8N9//v6re1jxw4AkFjkMC2JY+NAqFxrmRoR+5bT7ENAv5gpe6ap6MMPt2L58gbde/G4opUvS+VlpriujW2WTxFrigfpoM2+vjjeeisRFB84sAJf/vJ4LTsx60zxAj5vG9Yn/x8cNmGYxSeNlVWWaQtbYiBHRnaD4mLQNLW8BpC5pjiQ33lQV2sXVn+QSA6oqq3CQcc5D5yGQiEtW1zmTHHxgNyvf/1Aw8+ImeKp7dvZKRwSX6pPwFKfy9k8h7u6unDmmWeip0d/L125ciVWvJOcB+UzKA4A//nPf3L+fV6JRmN4//1EwtH48QNw6qnj0j6j31mZPrbKdCguUJiDcXd+njgcNFIawaCRgzJ82lgoFNLmt3t37tUt2Mhs+fJkUPyIIxJBZjtxDK8yxTduTNa8HzUquzgGZadoguJNTU2IxWKoq9OfFFxXV6dbVRHV19c7+jyQ2IpUW1ur/TNmTHr9MEr685//rC0cXHTRRWmrWnYyxcVMRTcOE9q9ezdi+7I1stmyDyQeLkPHJkpttDW1STnJ+/vfV2mvzznnUO21nYP7APczxeOxOD7+ZzLT7vAvH57V7xkyNhl0dWOL2Z49e/Daa6/p3nvnnXfy9vv/9a9/4S9/+QuARID0iiuMs8QBff1pozprXmSKr3x3pXY45uTTJzsuiQMkyjIc8dUjAABKXMGq91Zl+Ini0tcX1+rm7b//QF12X01NcgHEKChulnFa6C367XvatUNxnR7mJhJrzMuSLf7557vx2muJhaCxY2vxjW/oJ+PjxiVrhJodtunVro7WxmQiQTbPV5nPdbCi1hIHktlMQCJb3EimsnOFqDWtEvuZ7fIpAc0UX7Rom1aO7Ktf3R+RSFhbtHSUKW5yCHK+x8firiyx7JgTg0YngjZdrV3S1puOx+P4978TfXbw4EocfLB59qYYNDVqc7PFj0Jlin/y2ifaHOjwrxyOSGkkw08YUw/blLWNu7p68dRTiXKrVVWl+OpX9zf83JAhyfrqTU36/xZm5VMAIVM8iyDqL37xC2zYsAEAcNRRR+H73/8+gERSjTpvGTZ+mLZAlYvRE5OHUWY6x83PPv98t1ae7LjjRhvugsn2oE2xbTsLELNQFxhHHDgi6/4KCKVXFODzzz+3/rAkPvooUQu/pCSMQw5J/P3Fua7ZGVpe1RRftSo5Pz3kkEMK8meQsaIJirtl9uzZaGlp0f7ZujU4hxGIduzYgQsvvBDTpk3DjTfeaPiZ3t5e3H333drXs2bNSvtMLpni6kOmJxbL6wRv+/bkYSHZBsWBlOCpZNni0WgML72UyJDo378c06ZN0L4nBsWNBg0qdaBvlqWY70zxdYvXoXlnMwBg/2P2z3qL2dD9hLrimwtfV/y5557TTYoA4L///W9efndvby9+8YtfaF/fdttXdIOBVGpNccB4oOBFoO2zd5JnQBz25cMsPmntkBOTg4ttK9MPPStmW7e2aOVu9t9fn0XiJFPczfIpWz9LPlv3O9w8yy4TtXwKIM9hm/fdl5x4XnHFMYhE9EM1/WGbzYa/w6xdxcWOQuwAUBc6AGR1wJcYFFdrG8vu008btFJlo0bV4Oqrj9O+Z3Y4n1n7up0pLvY/K0ENir/++jrt9emnJ8p4qUHxxsZOxGLm7eRFpvj21cnx8ciDR2b1O9SEEcDds1nctGrVKm1Oc+KJ+1mWmbGqOQ1Al+0rPncLkSne19eHxS8kny/HnGWeJJFJZW0igNjb3Yu+aGF2k3npuedWagta5533Ba2EWSqroLguUzylfIp633aaIPTggw/iT3/6U+J3lJbir3/9K7785S+nfW7C0RPS3svGsPHDtEDs0qVLM3zanq6uLixatAjt7e6N2cSx0gEHGGdbiwdtZiqfUupSUPzll1/WXosLFNkQ65GLwVdZffjhVnz+eSKx4LjjRms73sVd0WZnaHmVKa62S3l5OcaNG1eQP4OMZbdf2QNDhgxBJBJBQ4N+ktTQ0GBac2f48OGOPg8k/icsLzd+8AWNenhmdbXxpOf111/XFg3OOOMMHHrooWmfqa1NToqd1hRPzVSsLjMu+eCUGBTPtnwKkB48FbeYFbu3396oPSjOOOMglJcnbxX607kdlk8pYKb40leSg7Vjzs5+oO/2YscTTzyR9t7q1avR09OT873orrvu0gLsRx45HD/60VGWn9evnltnFZv11Y48DgjXrl2LLcu3AEi0S93+2WWuAUDd/nUIl4QR74vrJv4yUAd9gL6eOKAPihudAWC2HbSywOVTtny6RXs95rDsd2SJQTkZMsU7Ojrw6KPLACSy04z6rJ2guFeZ4rqg+DDnQXHxMKitnwYjKeHhh5N1Tn/5yxN0B+Xu3GkcNPDigHKVuPhkN1O8qjYZOJI1s9SIGBQ/7bREpunQoYn/FvG4gubmbgweXGX4s3b6cL7vzdtXJZ6NpRWlGDbeefkUALqf27VxF8YeMTYv1+Yn77//vvbaqnQKAF05s4aG9GeUru60MJYqL8C9+sUXX9Tu0Qcce0DWySNAMlMcSPTpfGQlOxGPx9Hd3Y2qKuP+kyvxjIcZM8zHznYzxVPLp5RlUT6lvr4ev/zlL7Wv586di4kTJxqeLSKepZOLSEkEdRPqsGPNDqxduxbt7e26s8OcamxsxIknnoi1a9di/Pjx+PDDD12pnbx5c3Jsop7LkipT+RS3M8UVRcG9996rff2FU7+Q0+8T+/vatWstPimHRx5JxgUuvfRI7bWYAGa0KxrwJlO8t7cX69YlxgwHH3wwIpHsdwWQc0WTKV5WVoYpU6Zg/vz52nvxeBzz58/H1KlTDX9m6tSpus8DwFtvvWX6eUoaOlTI1mowztZSg+YA8P/9f/+f4WcikQj6908MlLLNFAfy+5BhpnhmL7+8Rnv97W/rt+/oa3E5K59SqEMqGhsb8fmixFawmiE1OPBY49p/dohZToUun7J582ZtcnXooYdqWyBjsVjOq/hdXV244447ACTOX3jooTMQzlB6JNNAwezgr37CglU+g+J//vOftddHfv1Ix4d+iUrKSjBsXGKyvmf7Ht3fpdh98slO7fUXvqAvRaLPFE+vue1VpviWz4Sg+BcYFFd98MEH2lkOF1zwBd39ViUGxTdvbjb8PbYWO/Kc0QQk68QD2WWK9x/aXyu/sG3lNqnqxBuJxeJ4/nk1MyiCH/5wMkaMSAYcduwwzhQ3K63hRlC8Y4/z8ini52Q808HIrl0dWLIkcW+ePHk4RoxIjDetgmgiW7s98tiHGxoa0FzfDAAYcdAI7SBFp1KD4jISg+JmBzCqxJriRpniZocx6jLF8/QMvuuuu7TXx33nOItPZqZmigPuL3S1tLRg0qRJGDJkCP75z3/m/PviKffLTz75BIsWJXYUHnFEHaZONc/QzbZ8SmkW5VOuuuoqtLUlngk/+tGPcPHFFwNIlFkQk9DKq8sx7ohxtn9vJsMPTAStFUXJeSfr7bffrgVkN27ciCuuuCLn67NDHCup57KkqqwsRWVlog9mzBQX+mdVgXbgvf7669rhpiMPHplz8p2YKb5mzRqLTxa/jo4onntuJYBEGcnzzksuKOgzxe3XFC8tcFB8/fr12tiOpVPcVzRBcSBRnmPu3Ll4/PHHsWrVKlx++eXo6OjA9OnTASRqWs+ePVv7/M9+9jO8/vrruOOOO7B69Wr89re/xccff5x2GCSlKy0txZAhiZunUVC8ra0NL730EgBg8ODB+OpXv2r6u9S64o4zxYXBYT6D4jt27NBe55LZoNsi6kKZDbcoiqLVsy0tDafV0cu0kq4yCooXKtD2zDPPaHWnD592eNaTOSCR0aZmtTVuKWy7igtLF154ISZNSh6ot3z58rTPx+Nx3Hffffj2t7+Nt99+2/J3P/TQQ9i1KzEhPffcc3HMMZkHU5kGCmJfjZgExduj+QliNTc3Y+7cuQCAcEmyJnguBgwfACBRV1xcHCt2H32UvKeltrO45TfrgzbzHDzt6OhA/eeJ2rVDxw7VZZE6JR70J0P5lHfffVd7bVbDVJzQbdrUYvgZzzLFd+WWKQ4AE45KbPuOx+LY+MnGDJ8ubv/+91bU1yf+vz399APQv385Ro5MLtabBcV9c9CmzaB4ZU2l9lwOSlD8zTfXa69PPz3Zl+0Gxc36cHWBdma9+OKL2utcFirdOBdgz5492LPHm4N4FUXBe++9BwCoqqrCUUeNsPx8pprippnieS6fsmzZMnz44YcAEgsXE6bkVl5DzBR3+7DNe+65BytWrEBXVxeuvvrqrH9PLBbDpZdeipKSEkyfPl3LuP7jH/+ofebyy4+2TMjItnyK00zxd955B8888wyARGnS3/3ud9r3IpGILrZx1BlH5VR7OpW4gyvXEiqLFi3Sff3CCy9o/18Wkp1McSC5G9oo6cvN8imKouCmm27Svj7xeyfmlBgEAINGDQL2/QrZg+IvvLAabW2J+ej5538BVVXJNsp0fhaQHEOZJfYVYowlJsMZVV+gwiqqoPj555+P22+/Hddffz0mT56MZcuW4fXXX9cO09yyZQt27kxmzB1//PF48skn8fDDD+OII47A888/jxdffBGHHZZ9XdogUf+71tfXp23Nev7557WB3HnnnYfSlBVwUbZB8UKtvOYrU7x2WC1KKxLX6MaBjG75/PM92LixGUBiW2hqHb1MNddURkFx3WQuT8FTQF+CJB/B08GjE1vM2ne3F6xWoqIouuv+3ve+p7s3rVy5Mu1nrrvuOlx55ZV44YUXcMYZZ+jud6Jdu3bh+uuv176+9tprbV1TpoGCWPuyTJiw1RQgKH7bbbdp94xJ0ybpDlTMlpi5unnz5px/nx+8//5mvPBCov5/TU1Z2oFfmWqKm2WcRsJhrY3zXSPxvffe0xaxxhye22HWukzx5uLPFFeDLQBwyinjDD8zYkQ/lJYm7qt+rSkeKY3Yrjedav9jkgHE1R+szst1+dU//pGcBJ177kQAid1Yau1LW5niQvuqWU1ulE8pry5HSZm9KoyhcEj7/0GGxSs7jOqJA1lmiovPW6GsWluPcT3UbDz++OPa61y26VfWVGpj610bdxmWdshWNBrFJZdcgiFDhmDIkCHawrmbNm/ejG3bElnEU6dORWmG4KOj8ilipnieD9r861//qr0++pvWgV47KvsLmeKt7mWKt7a26s6z2rBhQ9YLJA888ADmzZsHRVHw2GOPYfXq1Vi4cCHmzZsHIDGmuvDCSZa/o7y8RDvQvLHRfvkUpzXF1WsCgDvvvBPDhunLG91444145plncP5N5+MrP/6Krd9plxgUVzOXs6EoCj799NO097/zne/go48+0r7+y1/+gmnTpuHCCy/E1VdfjR/96Ee44IIL8Ktf/QotLfpEgFgshhtvvBGnnnoq3nnnHdM/W53XhkLAfvuZB8XV3XlODtosRBLfhx9+iIULFwJILDSK5yJlq6SsBAPqBgBIBMXzeW9WPffcc7jpppu0HQ1eefzx5I6Giy+erPue/vws42eo2i9156IJr52UPbKLQXFvFU1NcdXMmTNNM70XLFiQ9t65556Lc889t8BXJae6ujqsWLEC3d3daGtr08qgdHR04P/+7/+0z/3gBz+w/D3qYZs9PT3o6upCZaV+O7jbmeK6oPjg7IPioXAIg8cMRv3n9di7c680B8289lryROqvfS29Jp0+U9w4KB6Px7WHrS4oXoAyG+vXr9cyD+om1GVdB1PUf1h/YEXidWtja86/z8jy5cuxYkXiDzn++OMxfvx43SQltXzK1q1bceutt2pfd3V14ZVXXsGPfvSjtN99/fXXawOSSy+9FEceeSSAlzJeU6aBghgUF7OYyiIRlITD6IvH8xIU37VrF+655x4AiSzxUy4+JeffCeiD4lu2bLH4ZHHYubMN5577HOLxRF+79NIj0w5lLC+PoLQ0jN7eeOaa4mH9z/YrK8Oerq68LXSoXnvtNe31AcfkVvdSzFRta/J2EJ4rcWvy+PEDMHy4cRZuJBLGfvvVYv36vdi0qRmKoiA1vuFFpriiKFr5hdq62qyDLvsfsz9KK0rR292LNf9eg2g0irI8nSniN+qurEgkhG984yAAQCgUwsiRNdi0qdlxprg6aYspCuKKgnCOgS8jaqa33SxxVb9B/dDW1IaOvR1Q4gpCGcp5FbN4XMEbbyQyxWtqyjB1anLxL9dM8f5CULw1T0FxNRgIAMMmDMPwA3Kr8Vs3oQ5tTW3obutG++78LYL86le/wqOPPqp9PWfOHMyYMcP08319fdizZw9qampQUVGx714ZyikgLO7SO/nkkwFYBzX15VPMg+Ih6JMN8pkpHovFtJ2J4ZIwDjs19+QwcYeXm5nijzzySFo5zg8//BBnnHGGo9/T1taGG2+8Uffe+++/j7feekv7es6cU9CvX+Znz5AhVWhri2ZVPsVucE0tB9u/f39897vfTft+OBzGeeedh5UL0hNqciXu/lBrHmdjx44dWtv9z//8D3bs2IFVq1Zh586dOO2007BmzRosWrRIKwtjpLu7W7cocvvtt2POnDkAgP/85z/YunUrBg9Or5W/cWPizx05skZ3TlYqNSje1dWH7u5uVFQk57x2yqfkK17xl7/8RXt9/PnH5+15OXjMYDTXN6OtrS3jOXtOPfvsszj//PMBAJ999pm2s8FtW7e2YP78DQAS5yydcII++cbOQZtqWSM3y0oyKO6tosoUJ3epmeKAvoTKDTfcgA0bEjebU089NWONdjVTHDDOFreVKV6AoHi4JJxz9ql62KYSV7B72+6cr80PXn9d3PKbHrDS1xQ32XZkksVWVYBMcbEEyWHT8rMLRCyrU6iguJglfuGFFwIA9ttvP23RKDUofvvtt6fVwRazSlVz587FQw89BCCxtVfcfpeJ/qDN9LaNCm0mZjGFQiGthEo+Aqh/+MMf0NGRmDxOOXOKVvYkV2I5h2LPFJ8/fwOOPnquNsn+/9u777Cmzi8O4N+ELRtFhqKACG5Fxb1FcEtVrHVUcQ9UtGpVWkfd1f5qcVtXba0TqdvWvariwm3BiQu3oCgIJL8/4n25N7kJISQE5Hyex+cJSQgvhtz73vOe95zAQG/MnauaHSSRSFi2eE7lU5SD4twOgLcGCopLTaR53sJt52zHtgkburfDkydPkGWA7BDO48eP8e6dIoBUsaKzxudydcVTUtJFd3UYo6Z4yrMUZKQpXrOER4kcnq2emYUZ/Br4AVAEW4x1YWVod+68Rny8Yt7QoIGH4PjLlVB5+fID0tNVL77U7fCw1HN2qbKMtAx8fK84HvBLF2mDe75cJs/XzFJjuHDhCQuQtWzpzTL/Ad2C4vxjM39nlr6Ozfws8Rqta+Q5i9jZi1dCRQ91xR88eICRI0cKamIDimPyixfix/3o6Gi4urrCxcUFxYoVg1QqhYmJCaRSKTp16qQyn5LJZBg7diw8PT3x/fffq82i3LZtG7utqXQkx9HRku3s0VQ+xcrMTPD/LkgiyeP7fOjQISQlKUqW+dbzFWR560q50WZ+kMvlgl4znBMnTuT6tUaOHInnz4UlEk+dOoVdu3YBUGT4jxhRV6vX4j7Tr159EMwRtCmfIvu0gKns5cuXLAP++fPnbGdorVq1YGFhofJ8QzK3Mmc7fbjrf13ws8Rr1qyJHTt2oHJlxa6U169fY8SIETmWuN25cye7nZ6eLjgmfPjwAf/884/K96SmfmRZ/F5ejiqP8wkTv4SLL2qT+PQcFH///j02b94MALC2tkalppXy/JocfrNNfZZQkcvlmDVrFvs6OjraoPNlTX7//TK4j1SfPtVVzmfaNNoUyxQ3dFD85k3FzkiJRILy5XXvjUZ0Q0FxopZYUDwjI4Nt4bKwsMCyZctyfB0uUxwQb7aZXycZDhcUty1um+eVV0Gzzc+ghEpaWhqOHLkHAChVyhZVqqhmXfPLp6gLiqvLYpNKJGxiqI9MceUSJFVbVM3zawLCoDi/Rq6+yGQybNiwAQBgamqKbt26AVBkevj5KYJBt2/fZpnZly9fxpIlS9jzOWfOnBG87tOnTzFmzBj29U8//QQ3N831Lvn4q+c5lU+xUOqKra+g+KNHj9jvamlpicY9G+fp9fj4QXFu+3Nh9Pz5c3TqtJFlkZYqZYs//+wsCLzwcSWQcgyKK72n3DZ9fW7Rv3XrFss08qjiAQvrvF3cSU2krNzRq0evkJVpmEl4ZGQk3N3d0ahRI8HikD7xL1CUy+Ao4zfbFCuhok2muL7Lp/B7a/DPjboICAlgt+fNm2eQbb7Gpq68BiCsQ6y8JR/QrheAPuoQK+OXPsltpri1U/bv9LnXFd+/Pzu5IDhY2BuAHxQXe2856t5jfZdPycrKYlmJUhMpqgVqLhehDa6pNZD3oPjFixdRsWJFLFy4UPRxrmkf37Vr19C9e3e8fCmerLJjxw7WF4mzcuVK/PTTT7h//z5mzJiBzZs349atW5g/fz5OnDiBI0eOYMmSJdi9ezcAoFSpUqhTp06O45dIJKyEilijTW4h1Fopk1ifix/85JGqgfqZJxujfMrZs2dZaUEfn+xjZm6D4sePH8fatWtV7l+7di3S0hRz3/bty6udUynjPtMymVyQ/KWpfAp/Dq0cYDt48CBKly6NsmXLIjY2VtDcsnr1vJeI1IWjm+Ja/tGjR+z/KLf4QfGqVavCx8cHBw4cQLFiiv+/TZs2sV2cjRs3xvnz53Hy5ElcvnwZHh6KbN87d+6w/+Ply5er9D0T67fEnyN5eTloHCM/8Uu5LI+6JBKpRMLOvfqIV/z+++/sd+zatSvMrfS3U46fsKDPoPjx48cFf6dZWVm4ffu2hu8wDEUppDj29ddfq35ezMxMWI1xdY02xTLFDZlUIpfLWVDcy8tLpaoCMTwKihO1+FtquAyD/fv3s0lmSEgIfH19c3wdvWSK6+niPS0tjWWV5KWeOIffydnQTRnzw7///ou0NMX/dVBQOdFsIVtbc5iYKO5XV1Nc3XsKZL+v+sgUv3jxIjupl61WVlAeIy8EmeLP9J8pfuzYMRaUbd26NWtqC2RvmZLJZLh16xbev3+Pvn37sv/TyMhI1KhRA4AicM4P0E2ZMoVdYA0YMABDhgzJ1biKF88+Cb94ofreCoLiSlkv+gqKjxw5kk24w8PD81TiSJldyez39cGDB3p73fy2evVqpKYqJmTlyjli796ecHZWv+slr5niHzIz9VajWFA6pW7eSqdwuOOwLFOGN0/e6OU1+Z4+fcoyYE6fPs0yyfRN16A4v4EUR139f/6Fub4zXZ7ezr445Tei1oVHFQ+UqqhoGnvlyhW2dfxzwg+KK5cq4wfFxQJpxmqkyg9m57ZmPD+Irs+SGgXRoUP32O3AQOFuGJ0yxXmfYX2XTzl48CBrQF++bnmdewHw8cvY5TUo/s0337CdY4AiU5bfZFD5XJ6VlYVBgwax/79KlSqhadOmKgFs5aSCFStWCL7u2bMn/P39MW7cODRu3BjNmzfH8OHD2eOhoaGQSrW7jOaC4s+epUKmdC7laiTb88o0APpb/EhLS2PZ7XZ2dvCtn/N1mzYE5VOS86d8yvz589ntiRMnssD42bNncfDgQa2yU1++fCl4H5cvX45y5VSbWqtrdC1G+JnOTpDiZ4orl0+x0rAbetq0aUhLS8O7d+/wv//9D3Fxcewxbv6f37igOADcu3dPp9e4fPkyu121qmJxxtXVVfB5BgAzMzOsWLECNWvWRIMGDVC1alVBeZzLly9j586diIiIUPkZYnXFuXrigHDuJIafKa68qKbumAxkv795DZampqYKMq5HjhyZp9dTZqhM8aioKJX7jHGddfr0QyQkKBYzmjf3FDSm5+OyxcXKp8jl8nzPFH/48CFvpyiVTjEGCooTtcQyxflbLMVqmonhZ4rnJihuiJriCQnZ9bL5J3hd8eusvbhX+DPF+SvsLVt6iT5HIpFo7M4NaA6Kc1tC9fGectnWgP6yXwCloPgL7YPix48fR82aNdGmTRuNjX/ESqdw+CfDGzduIDQ0lDW2qVSpEiZOnMiek5WVxf6mr127xppO2djYCOr+a4s/sRfb5qttpriuWZ1nzpxhF28lS5bEhAkTdHoddWwcbSA1Vfw96mOydvnyZYwZM0YQ6M0L5e3c6hw9epTd3rOnJ6pWddHw7OygeHp6Fj5+FF4wqstGBLLfUyDvix0ymQxnzpzBtGnT2H3l6+hne6BgcfK+/hcno6OjBV/Hxsbq/WcAykFxzZnWZctmLwCKZYqra95myEzx+5ezSxJxAW1dSSQS1O+WXZqNX19TH7Zv346qVauiV69eBsv81yQ9PROHDt0FoAiAV68urOvJb84ndixWt5ilKftQH1JfZ48lt5ni/J06rx7r1hivMEhLy8SJE4psRw8PO5QrJ5xrOjvnvtGmqQHLp/A/W9WD9ZOF6lzWWVEkG8DTO0/VPu/9+/eCwKGyq1evsiCXlZUVli1bhsOHDwuCmPxzeXp6Olq2bIl///0XAFC2bFmcO3cOR44cwZkzZwS9RLisPEAx1zp//rzgZ2dlZbEghbJixYoJduXlhKsrnpUlFwTa5HI5C4o7KAfF9fQ+79mzBykpinls586dtW6OmxN+UDw/MsWvXLmCLVu2AFDMD7/88ks0b94cgKK0X2BgILp27YqpU6eqfQ2ZTIY2bdqwjOWqVauif//+qF27tuB5EokELVtqX9pNXVCcv5ijHBRXl/j1+PFjHD9+nH199uzZApEp7uDuwG7rWkKF+383MTERXOtERERg586daNOmDby8vLBy5UpUqCBsLMlfDDh58iQGDx7MrjVGjhyJpk0VvYdu376tUh7x9u3s801OmeJc6TJA9TpB03yZez/zem0bFRXFjlPBwcGoWbNmnl5PGX++rK+g+MOHDxETE6NyP7fYmp/Wrcv+rPTtW0Pt87hydWK7ovkLa2priut5Jx63AwagoLixUFCcqKUcFI+Li2MTkuLFi6N169ZavQ4/Uzyn8ikmajLF9RUU59dpzuv2bgBwKuUE6afGdp9Dpjg/G69FC/GgOJC9kq5NTXGVoDiXKZ7H91Qmk7Fas6ampqjYRH8nEX5Q/O1z7Zr37dq1C61atcLFixexb98+QSMYvvT0dGzduhWAInjdsWNHweP8k+HKlSuxZ88eAICtrS02btwICwsLwXOuX78OmUyG0aNHswykSZMmCT6/2jIzM2HZ4srZicpNU9Rlisvkcp2DbRMnTmS3f/jhB9FmOXkhkUpgV0Lx3ua1fMrjx4/RoEED/Pzzz2jbtq3oVtzcmD17NhwcHNCgQQNWO1IdbpHE0dES5cs75fjatra8i2ulZpuaMl/4mWp5CYo/e/YMzZo1Q7169VhAwLmsM0p6570pLiBcnNQUgNGVck1r5Xr/+qLP8inqtm1bGSjT5caNG7h7QRHkLeZQTHDhpSu/Bn6svM7u3bv1VkLlyZMn6N69O65evYr169fn+bOrixMnEtluj+BgH0iVSrnl1JyvMGaKC7KH7+S9znRBdfr0Q7bjrmVLb5Udd46OVqwxri41xfmZ4nkNir99+5YtRDs5OaF8Pf0sVJpZmrFjwNPbT1WCyxkZGRg8eDBsbW1hbW2Nbt26CRbdAUXAmGugByh6jXDfw5VSAIRNs5csWcIWjSUSCRYvXizYhl6qVCmYfToe8rNd//jjD3a7Q4cOKhng/v7+aNmyJSIiIhAWFob9+/cLxpCTMmWy55T8n/vu3Ts2b7NXqhOtr0xxfukUbZOZtGFpY8kWPvIjU5y/oD5hwgRYW1uL/j6aFlD37t2Ls2fPAlBcx/7+++8wMTFBp06dBM+rW7euINCdE2FCSfaxjZ8I5qi06KEu8YtLbuHcv3+fLdiYmpoaLWDGTyTTJSiekZHB5k6+vr4qddHbt2+PPXv24M6dO/j6669Vvp8fFJ80aRKbJ7dv3x4LFixAixYt2OPK2eKXL2fPCytX1jzv5NccV86IN3RQXCaTsZr5EokEv/zyi86vpY5tcVuYWSrGKlZ6Shdr1qxhx7EqVbJ7e3HlavNLZmYmtm5V/I1ZWZmic2f1nxWuXOi7dx+RmSncvcNPlDBTs9NS3+VTrl27xm5zdfZJ/qKgOFFLOSj+7bffsovSyMhIrRt96JopboigOP+gwzXJzAsTUxM4lVIEpV4+eGm0phL6kJKSwiaLFSuWgJub+rIVXKZ4cnIasrJUyypoCrRxmeKpecgoBhRlDLhV/KCgIEHWSl7ZONmwevPaNNq8fv06unfvLrio4+pOKtuzZw/7HHzxxReslh6Hnx3x999/s9sLFixg2w0rVcpuunLjxg307t0b+/fvBwB4eHiIbinUFn+bL+f69evw9/fHqVOn2H3qMsUB3QKox48fZxNZHx8f9OvXL9evoQ1uwePVq1csQy0rK0tjtpqYLVu2CLKApk+frvPf84kTJzBp0iSkpqbi1KlTgos/ZUlJSayclb+/m1YN0bhMcUC1hIo25VMA3S/KZTIZunXrJsh8AoCGXzXMczM3jlv57Lr5T+I1Lyho8urVK5UaiMpZW0B2UPzp06fYsGGDSk1LXXEXKLa25nB11ZyFm1NQnF/zU22muJ7Oq+np6ejQoQMyPyqO+5WbVdbLe2tqbooyVcoAULw3+tqK+7///U/w/yPWmMvQhPXEVbfp55QpbqxGm/ygeG4zxfmLV+d2nMPD64W3r4Mme/dm70gU23FnaiplcyidMsX1WD5l27ZtbAHtyy+/1FsWMQCUrV4WACDLkrHMbc7s2bOxYsUKFkjZsmWLIDANKHZz8AP2ffr0YY+VKVOG3eYHxfm7WTdv3ox27doJXlMqlaJsWcW47t27B7lcDplMxn62VCrFihUrsGfPHgQHB6Nz5864f/8+Lly4gAMHDuDnn3/G6tWr0aBBg1z9X3h7Z18H3b17l93mJwoZIlM8OTmZ1ziypCBwmFdSEymsbBV/x6nJqscofbp//z77W3B1dWWlAZs1a6byOyUmJgrmZhy5XC4ov7Jy5UqWdd2xY0dB/53evXvnanweHuKLHpre32IiAbbE5GRB6QxAMT/l5hyVKlXK9yabnLwGxa9fv86CjdWq5b5vQfXq1VXqLEulUsybNw8SiUTwd7Bx40bMmTMHa9euxcqVK7F6ddyn50tEe2Xx8edWd+/eFczr+dd4lkqJQdz7mZcEkuPHj7P/28DAQNZjSp8kUgnrw3Pnzp0875STyWSs15xEIsF3333HHsvvTPHDhw+zc2r79r6wsVFfi53fbPPdO+H/gbrrIkMmHVy9epXdpqC4cVBQnKjFrym+c+dOduHo6emJYcOGaf06uckUz2szIblcjqVLl2L+/PmCTDlAkTnHL1vh5qt9A0JNuGyYrIwslS1bhcnhw4dZUF9d6RQOlykul4vX49ImU1yOvJ1UuF0LAFijSn2RmkhZLeucyqc8ffoUbdu2VZmEX7x4UfTvnX/hp1w6BVBkUChP/EqUKIEePXqwr/mZIkuXLmWZQFKpFFFRUXlq0MEFY1JTM5CaqpgorFq1SqW0h7pMcUC3SSG/puD333/Psrn0jb8LwNraGnZ2drCwsECJEiXw119/af06yiVT7ty5o3Lhr42MjAwMHTpUcN+6detUjl8cfm1Jf39X0eco0zoorpwpnoeL8rdv32LRokWoX78+y9xzdnbG2LFjsW3bNr1t0wcUO3bMiynGqmtQPCYmBh4eHvDx8RHs8oiOjlZZ7Lh9+zYSEhJQpUoV9OjRA3Xq1FHJcuR7/Pix2oZvnPT0dHYx7etbPMegsru7LUw/lQJSDorv3r0bs2fPZl/zJ/KGqCm+dOlStpjg4u2CFv31F3hxdM++ENfHBdarV6+wdOlSwX38Mgr5Zd8+xf+XRCJeu5YfFBerKa5No02DZIrnodGmla2VoNb8X3P++iwbqO7erQiKSySqTTY5XGaptpniasun5DEozp+PiGVn5oVndU92m1u0v3TpEiZMmCDIAOconz+5QAsALF68GHZ22eduNzc3mHw6X3FB8YMHD7IyE3Xr1kXXrl3Fx+WpGNfbt2/x+vVr7Nixg71GUFAQXF1dERwcjH379iE6OloQgNcVP/uUH1DkL6iWtBbuvLDVw46Abdu2sXNTt27dBI3a9YEriZT8NNlgTa4BxRyUO1aEh4ezOa5EIkF0dDRmzJghuNYUy4Bdv349jhw5AkAxz+bv0rS2tsaRI0cwfvx4rFixQmVOlhMfn+wde/wyndw1gIWJiUqjTbFM8agzZzQGKY1VOgUQnot1CYqfPHmS3a5Xr16uv9/CwgLNmjUT3BcaGsoSierUqcOSjP7++29MnDgRYWFhGDhwIHt+xYolWINFdfjlVVatWgUnJyccOHAAgDDZQDkozu3gyZDJdF6Q5h/zwsLCdHoNbXB1xbOysnQuhcOJiYlhc9fg4GDUr59d9i6/M8U3b97Mbn/5pebAMv+6SLnZprrrIkPOr/hJm/zEN5J/KChO1HJxcWETKP52/gkTJuRqpTqnTHF1DcH4W0STtZz4L1++HMOGDcO4ceNUGndERUWxC3ePKh5wcHXQ6jVzwt8mruu2+kOHDqFWrVoICwvTuq6wvvGbx7VurbkBHr87t1hdcU1bzKx5F3S6llCRyWSsBImZmZlKCRJ94IKnqa9T1U5SMzIyEBISwhZDatasySZgcrlcUPsZUNSn27lzJwBF1k7Lli1VXtPc3JzVSeQMHToUlrwsEx8fH3ZByGUNA4ps8pCQkNz8mir42/YfP36LrKwsbNy4UeV5VspBcd6EnwuKf/z4EZMnT8a3336rMRP74sWLLCve09NTr1t8lTm4OQi+fvtW8Tt++PABkyZN0uo13r9/zy6u+HQpw7BgwQJBhgCgWMBTF2DnSqcAQI0auQ+Kv32rXUYEoPv2bZlMhuDgYIwYMUJQf/uPP/7AvHnz8MUXX2j9WtqQSCUsWzzleYpg+7I2UlNT0b9/f/Y3OnfuXACKz/CaNWvY87jtuzKZDCNGjGC1QxMTE3Hu3DnR1167di08PDzg5uamcjzgu3XrFsuazKmeOACYmEhZdhq/0eb69evRvn17QbkC/sW4ZR57dZw7dw47d+5k56kjR47g22+/ZY93mtBJsa1eT6yd+MHhvGfkR0VFqSxg3r59W6X5nSElJb3D1auKv9Hatd1RvLjqLid+o81nz1SPnepKaxg6KJ76Svea4gDQekR22b2XD15qtROrMPnvv/9w7ZqilF7duqXVNkDmguLJyekqfR446i7MLUxN2Vw5L5nijx8/ZiXzypUrh7p16+r8WmK8/L1YecE1a9Zg//79CAgIYMdXAILsb/78+cWLF2zhuVSpUiqJDyYmJihVStG3IDExEadPn0aHDh3Y45p2mnFBcUDxfo0aNYp9zQ+g6RM/U1xdUNzVRvh50sfih6b+NfrA7ZSVy+S4sOsCli1bhpUrVyIyMhKrV68WTQzJrczMTKxatQqA4n1XDhY6ODggMjJScB5SrpW8Z88eDBo0iH09Z84clRI5vr6+mDt3LgYOHJjrnU7ly2eXO7t1K3sXEHfN6yiSqCJWU/wUr6yf2HzUmEFx2+K2MP/0N6lLIJWfyNSwYUOdxqCcwc9vQmlubi56TcU3eHCtHH+Gg4OloGfLmzdv2DFCXa8WIO87O96+fcuua+3t7fN8LaeJvpptyuVyQf+qUaNGCRIqcyoFqU8ZGRlsN4m1tRnatNFcCkyXHbSG6skjk8lYTXEvLy9YW4vPG4hhUVCcqGViYiKYPHKUtyPmJKdMcXXN++xzuUU0KytL0GCFX3oCADtYAkC70bn7HTTh1yZfuHBhrrciZWRkoHfv3rhw4QLWrl0rmDgAiiy2AQMGoH379ujatSs6dOiAsWPH6mWyycnMzGTlPiwtTdG8uXaZ4oB4XXFtMsUBRQkVXfz222+sJnRgYKBg4UVfbEtkl49Rl6E4c+ZMnD59GgBQunRp7Ny5UxCg79y5M5o2bYqGDRuiefPmKFOmDDvZDhw4UG3Wzty5c1l2Utu2bTF+/HjB4+bm5ihfXnjCd3R01MsFHb9G9ZUrz3Do0CHR399eaSuoWKb47NmzMX36dPz4448aS4Lwt7SOHz/eYFnigLDUhrIbN25o9bk6fPgwO2599dVXbAKzevVqlWZdmiQmJrJjlkQiwTfffMMe4zJTlOmSKc6vKa48+VO3KAnoPsmPiYkRlNoBgF69eiEoKEjr18gt/s6f3LwHgCJgw3/fk5KS8Pr1a+zfv58tQtSqVUuQeah8flFe2AAUiydjx46FTCZDRkYGwsPD1QZfc1NPnFO2rAMARaOg5ORkvHr1CqNHj1Z5Hv/izdzEhJ1nc3vhdvjwYdStWxcdO3ZEp06d8PTpU4SEhGRviW5VTePnSxfWDvzgsPaLHTKZDNu3b8eKFSvY+J48ecJ2AZiYmLByVGlpafm6zffgweyAQqtW4s3cctNok3+ONXSjTX6mOP+90ZZ3LW8EhASwr18+0LyDorDh70Lo2lV9PVM3N+HisxhN8yju2JyXmuIbN25k2bc9e/bUWzkrjrWjNSo3V2TrvXz5EkFBQYK/WwcHB/z4448siMIvO7F582b2+/fo0UMlgAkokgO41w4NDWUBq2rVqqFXr15qx8W/rpk+fTrLEm/VqpXeF2w52gTFXfScKf748WMcOnQIgGEWPYDsoDgA7PllD4YOHYqBAwdi1qxZ6N+/PypVqqSx6bw29u7dy47P7dq1g7u7u+jz+KUm+OfTTZs2oV27duzvo3fv3np/n4sXt2LXRefPn2e7brl5hXI9cUC4WM0tUMd/2lFWqlQp1KlTR+V7lBuC5iepiZR9du7cuZOrXT4nTpxgiSTly5fXuXlkaGgoK5MyePBglTJG06dPh61t9rVbhw4dMGrUKKxbF4KjR/siPFz1/1SZRCJRCZ5fv34dr1+/1ipTHNBtsTIqKoolZnz11Vd52vGbkxIe+mm2efjwYXZNUrt2bQQHB8Pc3Jz1g8rPoPjhw4fZsaZ9e98cdwTwy6dou4NWKpGw6yR9zq8SExNZIguVTjEeCooTjfgd3gHFpKN06dK5eo3cZIrzSzLwg27aZIor13blZ9A+e/aM1cuuVq0aXLxz34RQHddy2YGpv//+G6Ghobn6/t27dwsuyPnBsFu3bqFevXpYtWoVdu/ejejoaOzatQs//fST6PZTbSQlJWHkyJFo27YtRo4ciaFDh6JFixbs5NWqlXeOJxOuHiYAvHqlmikuuJhTutDKa5mNgwcPYvjw4ezrMWPG5Po1tMEvsyFWFicmJgbTp08HoAiwxMTEwN3dHUFBQXB2VmwRl8vlOHbsGP79919BZnHx4sVFg1ecKlWq4N69e3j37h12794NGxvVjDx+0xlAcVFrKTLxzq2aNbODWv36bce8efNEn2enoSnUu48fkSmTCQIEO3bsEH2dxMRE1siwRIkSgswxQygXUA6Wtor/JwsLC0yaNIll3QPiwU1l/NIpoaGhiIyMBKAIxIWHh2t1sZCZmYkhQ4awSTC3w4XDb3rLxwVpLS1NtcooBjRnRPAzX4opLUbY6JCpJpfLBbt0Bg0ahB07dgi2hRqCu1/2hbK6rG0xmZmZok1x4+Pj8b///Y99PXHiRI11ZMWOEevWrROUTbl69SrLBFJ25coVdrtiRe3eV37ty/v37yMyMhLPn6s2fFbets19dnNz4SaXyzFmzBgW1N+zRxEASU5WZKk3btwYbUe11fr1tGXjyG84qX2m+IwZMxASEoLBgwdj4sSJkMvl6N69Oxtv3759ERgYyJ7Pz+4ztAMHsmsKBwaKB8UdHCxhZqaYoouVT9GmprghG21a2VnBxMwkh2eL4zfcfPnw8wmKp6amst1ClpamCAvzV/vcMmWyMxETE5NFn6NpFw/3Gc5L+RT+VnN+eTZ9ati9IWvGyLG0tMSgQYOwd+9elCxZkgXanjx5ws5H/LIu6gLc/DkQlyRRpUoVnDp1SqVXCx8/KM4/l//www96XxjgODpasiAMv7QH/zrFRWmep8v5l2/Tpk1sLtKjRw+D/G45NVROSkoS/J3pYvny5ey2psQPsaB4UlKSoBRKo0aNsHjx4jyNR4xEIkGjRtn9L0qUKIHFixezQFdOmeLvMzLw6sMHvPg0H/T19VVJSpNKpahVK+dMZ0Py9lacr1JTU3H//n28ePFCq/kuf8eC8pw7N0xNTXHgwAG8e/cOy5YtU3m8evXquHz5Mnbv3o2UlBTs2LEDCxYsQO/e1dGkSVmtPwMTJjTCjh3dBc104+Pjhb1alOZVednZcfPmTVbyzsTEBCNGjMjV9+cWP1Ocy1DWBf+zOW7cOPb/y9Xnf/LkSb6VSPv999/Z7dDQnMuPCMunaN9riZtj6bPRJn8HML9RKclfFBQnGnGZGJymTZvm+jWcnLIzCcRWDbmguJlUCinvhCUon5Kmmo2sTDmw8eTJE7Zav3fvXnZgzm2me05KepcUBGR27NghmOjmRDlIwmUeA8DYsWPZRbwydZmkmrx+/RqNGzfGwoULsXfvXixcuBDLli0TNJIbMSLnlXRhprjmoLhyneK8rKYfO3YM7du3ZxdOvXr1EgQ29Ik/2b98+bLgsWfPniEsLIwFiL7//nuWwWFubs6CpMocHBxQpUoVbN26la2kqyORSDRuoeIvDJiYmLDGQ3lVu3b233JycjqrBapMOSiuvNhx9tEjQRDr5s2bohlDCxYsYJ/T4cOHa7yY1QeLYhbo878+mDFjBs6fP4+ZM2di4cKF7PGcguJyuZxdSJuZmaFly5YYO3YsqwF3+vRprWqTDx06lL2Oi4sLZsyYARcXFzYhOn/+vMoi4tu3b1nwrlo1F1ZTOifC8inZn7m0tDTB37bKJF9poUMba9euFWRXL1u2DB06dDBo9j8AuPtm/92qyxS/d+8eFi9eLMhIXL58uUpzTUBR/5Jf0ickJAT16tVT+3vwm70Bihq6YnVJletZc/g7ALQti8Pf4nv48GHBBQpfcaULcm7BWZvzKufff/8VjBFQLAwCimPVb7/9Bgtr/TcAs3bMffmUpKQkQYmGNWvW4N9//8WxY8cAAO7u7pgxYwa8vLJ3RPGb3xmSXC7H/v2KvzcrK1PUr+8h+jyJRCLa9JijTU3xdD03/pbL5Swozl+syC3+BfnnFBRfv349m6/16FFFUGZOmTZBcY2Z4josbPHdv38fZ86cAaAIJBmioRsAuJRzQfVW2SUfrK2tcfXqVSxfvpzVFeYH/xITE3H+/Hm206hq1apqm/IpJwYAiu37Oc0hxHbAOjs7GySTmiORZDf4e/DgATu3a8oUN5VKWaDtpZoeI5ps2LCB3TZUSTqvml6sKT2gCOYOGzYMgwcPZvfxAz65FR8fz3axli5dGq1bt1b73HLlyrEdBTdv3sStW7cQHBzMsrVDQ0Nx7NgxQSaxPo0eXQ/cJeybN28QHh7OHhPNFFdqep3AW0D39fWFr6+vYIdErVq1RBNk8pOvry+77eXlBWdnZ1hbW6N06dKCEpx8WVlZbK5gaWmptta/tnK6NvL09ETbtm3z9D5LJBJ06OCHiIgIdl98fLwgiURfmeKxsbFo1KgRK+s2dOhQg9eUdvZ0ZgsTyvM6bT179oy9ryVLlhSUe+GC4unp6aLJkPoWHx/Pems5OlrmWDoF0L3XEve51WfSAXcuBmDQ8xDRjILiRCNuezGnSZMmuX4NKysrll1+6tQpREZGCoLGXFBcuXGffS5qil+5ckUlEJKVlcUmnPyTtb6D4hKJBD3nCmv1aZNtCijGqNyw7/r163jy5AnCwsKwfft2AIoTzK1bt5CYmMi2miYkJLBgorYmTpyoNiPOxMQEY8eOVZu5xse/2OvePRrjxo0TrAZrupjTdeJw+/ZtdOrUia3Uh4SEsDqDhuDqkx2YOnPmDJYvX45FixZh+fLlqFGjBrv47datG77//nvB944cORK//PIL+vXrh+joaKSkpOD58+d4/fo1rly5otIsRheNGjXC+vXrERISgpiYGL1tuSpTxh7Dhqlu0eR3dgeEWRGAalD8gEjNQX6d7OjoaPj5+eHnn38GoJgs56aBb164+rgiMjKS/Z/xV+Zz+uzGx8ez7c+NGjWCnZ0dzMzMBI0NIyMjNdYoPnfuHFauXAlAsYiyevVqVmaKq4kok8kwfvx4LFmyhB0vT58+zT5nNWtqFzgFxCd/t27dgp+fn2AxUTlTPLflU1JTUwV1PQ2ZeaeM32xTLCj+4sUL1KlTB+Hh4WjYsCE+fvyImzdv4rvvvmPP4S9mce8PAHTt2hUmJiawsrJSO2HlZ4qnpKQILvwCAwNZIOb06dOCCffTp08xdepUtpBiY2ODcuWyF5I14QfFZ86cyf42lINFTkpBcX6muLZZPIsWLVL7WMeOHQUBZn3iB8W1LZ8ybdo0QQ+D169fY8KECezrH374Aa6urkYJil+7dg2PHinKZTRt6glLS/WN77j+Ds+epaocT9SdYw2ZKZ6emo7MdMVr2hTXPTjj6Ja9ezD5qXhAuLCRy+VYsmQJ+3rYsAANzxYGxe/ffyP6HO49NpFIVI6j3LE5PSsLGTosfvCTMXK7uzG3Wo9ojcGDB6NTp044dOiQyg5U5c8hf4G/f//+al9X+ThnZmaGLl265DgesWNVs2bNDH6uqlYte4cqtxjNn4+XsbdX+R7nT8G/FyI9WY4ePYqlS5ciJUW1Lv+tW7fY7tjq1asLmrPrk52zHZr1bQYTMxP41PHB5cuXsXjxYsEOQ22vhziZmZmIiIiAo6OjYLFm5MiRGhuFWlhYsPf2ypUraN68Oft/dnZ2xuLFiw36Hjdv7oV9+3ohIED1s6/cRBVQzRSP5wXF/fz8YGVlhc6dO7P7DJ09rA3lfkeAYrfho0eP1I7v5MmT7Fq8devWRg/s5wZ/EUA5U1w5KK5LuaMXL16gY8eObEehv78/24FsSGYWZqxB6bVr1wS/l7bWrFnD5rJhYWGs3jyQHRQHkKskQV3IZDKMHDmSzZHGjm2Q4253ALC3z16o0ramOJD9vutzfsVPPqOguPFQUJxoxD8BmpmZoVWrVjq9jr9/9jbSWbNmoU2bNuwAxoLiSqtxFqam7L6cgqe//fab6P0PHz7E27dvWcZf8eLFdep6nZNi9sXQcXx2LWltJ4GnT58WzZ5t2rSpoGnf3LlzUa5cOXh4eLDxZ2ZmalUHVS6XY+nSpahQoQLLJLSxscHp06dx7NgxnDt3Dnfv3sXbt28xb948rSaNykGb+fPnCzLX9R0UT0tLQ7du3diKc+vWrbFp0ybBSVjfXMq5QPopE3f9+vUYMmQIRowYgSFDhrAdD3Z2doiKilKpdymRSDBy5EisWrUKnTt3hq2tLUqU0K4kQm706NEDMTExggZT+rB4cTv88Ud2zUWpVIr58+ezwG3jMmVgovQ7qwTFRYJMXPf5f/75B926dRNsIx46dChKliyp8j35gR8Uj42N1Rgo5P+d87OWOnTowMpr3LhxQ22ZDACC3gfz589H27bZZSf4AYpff/0Vw4cPR926dfHmzRuW6QoATZqUzeG3ymZrqxoUHzJkiEp2s0rjoFw22tyxYwcr3xEaGir4vQyN32zz4cOHKlnF48aNY2N7/PgxYmNjMWjQIHZM+frrrwUNvPhN3xo3bsxu8wM2YWFhbMcHPygeExPDAhVVqlTBH3/8wRpLpaWl4cKFCwAUmf+NGjUS1Ntv0KABpFLtLtz55VO4300ikQgaHwHqd+tkyeVaNQt68uQJ+3t2dnbG0qVL2THP2dkZc+bM0Wq8uuDXrRYrDaNs+fLlotuqT5w4AUCx/ZqrJ8ttBQeEQfGEhAQMGDAA33zzjU4NxTTh16IPDi6n4ZnZdcWzsuQqvQ74vUvyq9EmlyUOKJqu6cq2hC3LLv1cguJbt27FpUuXAAB165ZCrVridY855cplLwzcuPFC9DnchbnyHArQbRcPH7+khaGD4pY2lli2bBn++usv0TrJ/MztpUuXsvJXVapUEd1tw6lQoYIgG7RTp05a9Zdxc3NjPVs4+khUyEmtWtmBoqZNm6JMmTIsKcbOwgLuIpmtJT5lvb/68AGZvIWx/fv3o0WLFhg2bBjatWunkiDDbxBtyMblANCkdxNE/h2JnnN7wuLT36WtrS3KllXMUa5evar14mt6ejpCQ0Pxyy+/CDJMte2ZwwXRMzMzWUmdYsWKYevWraysoSEFBZXDyZMn2e/O8XFSXei2Umq0Ga+UKQ4o3sdZs2Zh06ZNKk0mjaF58+bsPVZ27949vH2r2h8hOjqa3dZm0aogUQ6K8xfblefLub22TU1NRc+ePdlctXHjxjh8+LCgD5shccfizMzMXO88l8lkWLFiBfta+bPJD4rzKwQ8fPgQBw8eVGl2nhe///47m1e5urpqtdsd0K3RJsArn6Kn+dW1a9fYNUGtWrUE/3ckf1FQnGjEdeOuVasWlixZonPQasCAAYKv4+Li8M8//wBQnykOZJ9kNG3zzsjIYPUHzczMBM3qHj58iDlz5rATdceOHXWuZZYTfp1M5XIb6vDLLPC3HiUkJLDbEyZMENRU5E+2xOrYKhs5ciSGDRsmaKYxffp01K1bF40bN0atWrXg6emZq6YeYtv7+QE7dVu7Ad2C4hMnTmQnjfLlyxs8IA4oVtLL11G/BcvExARLliyBi4v+6tMXJD17VsOiRW3YAo2/vz+io6Mxul49/MHLXuHwg+Jv0tJw9tEjABD8XZ04cQIXLlxA586dBZmP7u7umDhxogF/G80cHR3Zrphz585pLH/Crw3P73QvkUgE2aiDBg0SlOngHD58WLAdWHky2aBBA5UdOYmJiRg9erRgx0tuguLKk799+/aJ1izXWCNRi8DLvn372G3+9un8oq7Z5uHDhwWLjADw008/sbJRPj4+iIqKgqenp+hxhV9LvGfPntixYweWLVuGJUuWsOPxo0ePkJmZiXv37mHs2LHs+cuXL4eLi4sgsH706FEAQEREhMrOnVGjRmn9+1aurHo+bt68OYKDg1lwYJhIYy77XJYm+/XXX9lC54ABAzBkyBAkJCRg165dSEhIYBlHhmBmacZ6JeQUFH/79i0mTZrEvubPBTitWrViJd34wTguKP7hwwcEBQVh1apV+N///ocKFSqoNL/WxeXLl9GlSxfB30br1j4avgNwcVFfOkZdbVMLAwbF377MDnjYOOme7WdiasKC6inPVbNc9eH169dYv369wXYApKenC7bS83fcTJrUWOQ7hCpWdGY14y9eFM+k4z5zyotagFK96VwGxe/du4fY2FgAiixifuDHGPiZ2/zeI9OmTdM4zzMzM2M9ZczNzVUakqsjkUhUdr4ZqgwfX7t2vuDnnDx48IDdbuPjI5qQ4swrBfPyU0BOLpdjypQpbA514sQJBAcHY9iwYRg9ejRCQ0Mxa9YsAIpFQEPVi+cTGzuXbJCSkqKyAK/O6NGjVeZf3Fxbm2ChWJZ2TEyMTrucdWVmZqbSWL5JWdX5mnKm+H8iQXEbGxtMnDgR3bp1M9Boc8fe3p71jClRogQuXryITp06sceVE7VkMhkLipuZmaF9+/b5N1g98PLyYjGD+Ph4QTlTe6WSOLmpKS6TydClSxcWB3FycsKmTZtgL7JbxFD4uxCmTZsmuG7X5NWrV/juu+9YwkCrVq1Udv+IBcVv3LiBatWqITAwEJUqVdK5bAvfmzdvBMf9NWvWCJKANBHWFBfOgzWWT/n0udVXTXH+/NLQPbWIZhQUJzkaP348zp07pxLYzo2OHTviyJEjglXiqKgoyOVydnGnnCkO8GqfajjBLFq0iF0wduzYEdWrZ9cvjI+PZ9u+NdV61oeSniXZxJAfFE9PT8fPP/+MyMhIlrkAKA66XM0/U1NTLFy4UGVbWffu3TF79mzBhJN/IS8WdOM7cOCAYNu7paUl+vXrl+dteHZ2FoJMJ0DYwVqfHboPHDiAX375RfFalpbYsmUL7Ozscvgu/agXWo81iTIzM0NoaChmzJiBnTt3Ij4+Hj179tT8AoXc8OF1cOTIEZah0qJFC/wvOFh0my//Ij320SO2it6hQwc2YTpx4gQCAgJYlkDr1q1x4MABXLt2LV+yeDThB7TVZXnL5XIWFLezs1PZvt2+fXt2gZCcnIyhQ4dCLpcjMzMTr1+/xr179wRB8BkzZqg0R5VIJIiJicGwYcPQqFEjdv/atWsFXd5LldL+M+DgkP0zdu9OUFvTUaV8Si4yxeVyOZvgFytWTDD2/FKqQil2e8aMGYiMjET37t1FM9b5F96jR4+Gvb09TExMVAK8fn5+Krs8OnTogMGDB8PS0pIFxWUyGf7++29UrlwZL14oMj8rVqyI+vXrAxBmIm7evBn9+/cXNB+dOnUqTp48mavs+pIlrVWOwwMHDoSpqSnOnTuHm8OHY5HI6+XmGJyRkcF2GEmlUpYp7+3tjXbt2hn8Ik4ikbBjQ07lU8aNG8d2XnXv3h3z589X+YzydwMUK1aMLWpyF3i//PKL4LyakZGB3r17sxrHukhKSkLz5s2xbds2dl/Dhh6oUEHz7iEuUxxQ/d3VnWMFNcX1nSn+MjtTPC/lUwDArqTi+JX6OlWnrduaJCUloXr16ujVqxcqVaqUp5rGYnbv3o3SpUvD0dERBw8exMOHD1lpsEqVKqFjx5zrc5ubm7BFrZs3X+DNG9X/A42Z4nloWM7VXgVQIIJtYjW+TU1NERwcnOP3TpkyBbGxsbhz545oQFSdUaNGsbrEISEh+bIw4Opqg5CQ7POLmZkZfH190alTJ/ys5nd15pXd4Eqo7NixQ+V4dPDgQSxduhQLFiwQzF/69+8vaBaYn/jlN/mNpNVZvXo167lhZWWFf/75B8+fP8ebN2/QvXt3rX4mP7kIADw8PATJC/mlT58+2LhxI7744gssWLAAjZR2JgDqy6eYmpqKfiYKim+++QZPnjxBYmIiatSoIfjsPPqUDAMoEhPq1avH7gsKCsq3LGh9MTMzYzvK4uPj2e4FE4kE1moamAM5z6vmzp3Lspvt7OwQHR2d7xnCwcHBbL577tw5REZG5rijY8OGDShdurSgXKRYIoe7e/ZOqcTERMjlcowaNYrteEtMTETz5s0Fu4V1MWXKFDY36tKli8aeA8q4xseA5kxxc6XYFPe+Z8hk+JhD6bKHDx9i7dq1Gvvh8HdSdBZJOCP5h4LiJN80bdoUGzduZAfLvXv3YsCAARozxe1zqH36/PlzVs9ZIpFg3LhxrH45oKgLy21j79Gjh8pqpj6ZWZqhfHlFZvG1a9dYls/QoUMxZswYzJo1C7Vr12aB8Q0bNrDJQtu2bVG6dGl07NhR8JpiQVdtguJbt25F5cqVBeVuFi5ciA8fPmDVqlV6yZafOFEY9Lp58ya7zc+gyssWs99++w2tWrVi7/306dMFix6G5lnDE/0W9sPixYsRHx+PzZs3IzIyEu3btxdsvSfCoPgR3t9l7dq1BRc0XHZT/fr1ERMTg5YtWxaIiXJoaCjLSuO2wSu7fv06C3g2adJE5XPENRzkjkH79u1DtWrV4OjoCCcnJ3h5ebGmjtWqVRPsAOFzcnLC4sWLcfz4cUFtaw4/sKeN0qWzA+gJCa/Ubl1UrhMvCLzkkBVx6dIlVjuwRYsWarfYGpJPHR+YWSomrKdOnWLbjrmgW4MGDUQ/t/xAtPI2en6WuBj+NvzRo0ez7bVSqRRTp05lC5q+vr7s/HD+/HlBQHzt2rWYMmVKjj9LTKtW2b9PgwYNWCkEGxsb+JUoIZrBl5tj8LZt21j2V6dOnVTKDuQHLij+8uVLtbX6161bx4L3lpaW+OGHHwAAkydPZs+pXr26ykUH10z8yZMnCAgIEOxY4XoOpKeno1OnTjkuQouRy+UYMmSIoEyak5MVfv4554Cfm1t24Fk50zKd976pC4rndnvvx48fsW7dOlbmShk/Uzwv5VMAwL5k9mIKP1lAH+bMmcOycNPS0lR6fuTF69ev0aNHD7x48QLp6emYNGmSIAj55Zdfav1aTZtyC2py7NqlGhzQFBS3ySErUS6X4/bt27h79y7evXuHf//9F4cPH8aKFStYeSWJRJKr8RpKmTJlVErQBQQEaGymx5FIJAgICECpUqVyfC5fjRo1cPXqVezZswebNm3K1ffmxbp1X2DWrFmYMWMG7t27h//++w9//fUX3NQ0BeRnij9//x7PUlMFZTTUNRU1MTFBcHAwy+o1htwExSdOnCioHz9v3jy0atUKJUqUyFUN6urVqwuC4IMGDTLY7uCcfPnll9i2bZva3V/8+dW9N29w6VPgzNvb2+CNyfPK1dWV7QLlf/a4ucKff/6Jhg0bsrr2QO52wRUkXND//fv3uH79OgBFwp5Knwctaop//PgRbdq0Eexo27p1a76Ub1JmZmaGdevWsc/HvHnzsHjxYrXPT0hIQFhYmOD6vkGDBqKJHPyFkkOHDqFbt26CutmAIsu7du3aCAoKQs2aNREcHIwaNWqgVq1aGnfrci5fvsyS/qysrPC///0vx+/hE+6gFb5fmsqnaJss9ObNG9SrVw9hYWFo166daAwrPj6eldutX79+rs9jRL8oKE7ylampKaZMmcK+Xr16NQtaK2cpAtmZ4jK5HKkiQZmNGzeyAM/AgQNRt25dwUGFC0ABYHVEDYmrnZ6WloaLFy9ixYoVgtp+T58+xbhx4wCAZUQAYFuq+dn4pUqVQlBQkMrP4JdPEbtIv3LlCrp3785O3oDiYKvvJob9+9fErVsjWMAtPj6e1TXUR4fuJ0+eYNCgQezrevXqCTqB5xePyh4YNmxYgc7cKAj4F+n8nR21atXC4MGDBRcmHh4e+Ouvv1SypI2JnxFy584d0QkMv+6eukmsvb09Fi5cyL6+evUq3r17J3iOqakpli5dqtXFWv/+/bFy5UpUq1YNFSpUwJw5czTWWRVjZ2chyBYHFItr/JqAgDArDcg58MLHdaEHkKtsDX2ytLFEw+4NRR/z9vbGmjVrVPpi1K5dW/DZVh57Thcr/OMxv+xVXFycIAtTubwOoNi9NGPGjDxtmZw+vQVCQyuhS5cu2LJli1Z/U9o2sZbL5fjpp5/Y1+Hh4TqPMy+4oHhWVpZKbW1Acb7hN3hdtmwZW4D44osv2GLmnj17VP5/+E2NuFrGADBs2DBcuHCB9VV5/vw5evToIeiXoUlmZiYmTpwIOzs71jDb2dkZ8fHxePx4DAICcr748fPLziTn78QChJni/F12/Oy11FxmEA8fPhx9+vRB06ZNWbkyPn2VTwGyM8UB1YB/Xjx79kzluLZnzx5BqYq8+OWXXwSNDWNjYxEVFcW+zk197s6ds5sfbtlyXeVx7j1WnkMBmjPFMzMz0bVrV/j4+MDb2xu2trZo2LAhWrRogcGDB7P5Wffu3Q2aKKItCwsLQd8hIH9qfHt6eqJNmzYGL8XHZ2NjjokTJyIyMlKQTalOCX5QPDUVm65eZeUgv/jiC5YY1KdPH0RHR+Pw4cO4fPky0tLSsG/fPtbzwhiqVavGbqtLNAAUWe78vhSDBg3S+XpFIpHgjz/+QP/+/fHtt99qXVLHGBx4898NvD5UYnX3CzL+3/GjR49w+PBh9OzZMzvhzcICCxcu1LknmbHxA7zcMdlB5NpFm2vbDRs2CMoMDhkyxKj/LwEBAYLSX5MnTxadYyUkJKBRo0bsPa1atSoGDRqEzZs3iyZe+Pr6svsPHDggWDheuXIlWzB7+/Yt9u/fj4sXL+Kff/7BpUuXcOHCBXz11VcaF9LkcjmGDx/OkiQiIyNznbCha/kUOy0bqm7cuJElPp4/f15lDgdAsHuQssSNT30bZ0IMZNCgQfj48aNKCQ87kcxCO6XapzZKk1f+NtCRI0cCgNqVtpo1a+o8Zm01bdqUZZ306dNH0KyN89dff+HZs2espmPlypVZvdnmzZtjy5Yt2LdvHyIiIkQn6/wADr+mOLd9v3///oKmO7Vq1cLatWtVMnH0oVw5JwQEuOPhwxSkp6fj/v378Pb2FmaK67jFLCoqijUTa9euHTZs2KCx8zwxLuXPJqdKlSooWbIk5syZg/Hjx8PJyQnR0dFGa6qpSbly5XDz5k18+PABT548Ublo5ZpiAdC4tTskJATr1q3DiBEjkJycjJIlS8Lf3x+Wlpbw8fHB119/LbhgzEn//v0FWVS6KFPGXrBFv1evXiqlJZyU+gpok/kCKGqGcoEoiUSSLwuQ6jT5ugkGthqIEydOwN/fH82aNYONjQ1cXFwglUrRpUsXllEMqNY+Dw4ORmBgIA4cOIAqVaqoLTXDUW6oBSgaJvGz5DhhYWE4efIkVq9eDU9PT8TExKi8B7lVokQxbN4cCmCq1t+j7TH45MmTLNOrRo0agsbb+Yl/rHj69KlKoGfVqlVsl8IXX3yhssgQGhqqNljZoEEDlQyjHj16YN68eTA3N8fWrVsREBCAO3fu4NSpU/jqq6+wcuXKHMvGjBgxQqXh5/Llyz8F67U7j/n5Zf+e/J1YgDAozt/eq0vPDkCxwM7tSsnKysK2bdtU5kz88im2JfSXKa6vgDWgKIPFn38Aigvo9evXCxaluEVPrgxA5cqVBU0bxSQkJAgWiThc3fIqVaqgYsWKKo+r07ChB9zcbPDkyTvs2hWP/fv3Iz4+Hra2tvj48SOrxaq82w7QXFP8p59+ElxsiylVqhTmz5+v9VgNrUWLFoI+EMY61hQ0/EzxF+/f4zAvEWby5MkoVqwY2xVT0Pj5+cHKygofPnzAqVOnIJfLVQJoL1++FCy2/vjjjyxxSFeurq6iO+wKGuWa1Jx+/frl80jyRjlTnL9I2KdPHyxfvtwoOwf1Ray0kpvI7gVtaorzryFGjRqFH3/8UQ8jzJvw8HCcO3cOv/32G16/fo2goCB4eXnh7du36NSpE27evMlKmAKKOe+pU6c07uSxsrKCp6enSk+Pr7/+Gv369UPHjh3Rtm1bQSICX1paGkJDQ3Hs2DHRa8X58+ez5uk+Pj6CXi3asrfP/vzlptGmtrXj+f0xAEWCFL88o1wuZ/3wgMLXhPZzRBEmYhTDhw9HTEwMDh06xO5T3roPCDPaUtLTwQ933717F6dPnwagWLXktjpbW1vD0dFRsNrp7OycL9tS+BN5fkB83LhxePToEf7880+kpaVhwYIFbIVTORu8a9euGgMxDg4OsLOzQ0pKCssUl8vl6N69u6Bhg6urK+7cuZOrBpq64NdFvXnzJry9vbWvKa4m0BYXF8cmVubm5lixYkWOF6zEuMSC4sWKFWNZnmPHjkWfPn1gY2Nj8L9JXfFLa9y+fZsFxeVyORYsWMBqAHp4eLDjjTq9e/dGt27d8PLlS7i6uhpkUSo3PD0dcPlydl274OBglCtXDiYmJsjKyoKjpaXKNn1zExOYm5jgY1aWxgDbokWLWFAyJCREqww4Q5FIJOjRo4fa5mKBgYGYOXMm/vjjD4SGhqosNkilUvz999+4evUq/Pz8cryYUxcUVze2VatW4aeffoK1tbXRtkjzL8Y1va/8YPGYMWNEM4LyA78k2oMHD1CpUiUAiuDtu3fvMHfuXPY4v1yKNoKCgtj5FFDs4OLqpgOKUkbr169Ho0aNkJWVha1bt+Lx48c4evSo2kXa3bt3CwLi7u7uGDRoUK4Xizw9HWBhYYL09CyV5t38LGL++6LtQpYy5YUB/k4zTvKz7CZj+iyfoq9M8T///JPtzLOyssK+ffvQtGlTAIryDOfPn8fTp0+RkpIiKHEHKBZe/v33X7WZ03K5HEOHDmW7fmrUaIxHKAAAMcNJREFUqKHSKCy39blNTKQYOrQ2Jk8+AplMLrozEFBNLACE7zM/Uzw5OVmQdVu5cmVYWFigdu3acHJygqOjI/z8/NC4cWPWcLYgGDBgAJYuXYp3796hatWqFBT/hL9761lqKo59SoRxdHTM1cK6MZiZmaFBgwY4ePAgEhMTcefOHcHnKy0tDYGBgWzBr1atWqLNkT9X9iJzi17VqhW6v33+fO/u3btsnuzi4oKVK1cW+mQmsaC4WF8lWy2ubbmeRPb29pg/f36B+b+ZPn06KzV47tw5FqzmZ7UDijnsr7/+qlVpq3r16gmC4r/88gvCw8NZn5hDhw5hyZIleP78OUaOHImsrCzY2NggKCgIcXFx+O+//xAQEIDz588L+vrs379fsAMkKipKp0UXa2szSCSAXJ5DUFxDpri6+XNycjIOHjwouE95geDIkSO4du0aAEVyBr/hNDEOKp9CjEIikWDevHmC+2xFDmqatnlzTSoB4KuvvhI8ppyt4+/vny8X9H5+fipNbYYMGYK5c+cK6sXym1TktgmMRCJhB8979+4hLS0N06ZNEwTEAcV2ovwIPvKD4vv370evXr0E5R1yW1Oc2/rL1eYdOHCgUYNsRDtii1peXl6Cz52zs3OBDYgDEFywcY33AGDWrFkYM2YM+3ro0KFaHU8sLCzg7u5u9IA4ANSpk/0ZsrW1Rb169eDk5IQlS5YgpEIF7FA6hnK4baLJvIWulJQUREdHIzlZESRbu3YtAEVAuSBkvmgikUgwadIkXL9+HdOmTRN9H6VSKapVq6bVRLtChQoqJTnUBcU5Dg4ORq0ZqrwDS8zt27dZXUd3d3ej1h4WKxn27Nkz1KpVCw4ODqwmdYcOHXKdeW9ra4stW7agUaNGmDJliqARLqdevXrYtm0byw7/999/MX78eLx8+RK//fYbFi1ahDlz5uDrr79G586d0b59e/a9K1aswKNHjwRl47RlYiJFzZqK5lu3bt3C8+fP2WPqSmvokil++/Ztlax2saD4q0eKuug2TjYwt8pbyQl9ZIrL5XK2mJGYmCgoubBixQo0adIETZo0Yfdt3boVx48fx6VLl1TK4Dx79gyjR49W+7N+/fVXdpHr6emJo0ePChItTE1NBbWetTV0aIBKaStlOWaK897n+fPns2ZwYWFhuHr1Ks6fP4/ly5dj9uzZGD9+PDp16lSgAuKAIvB07tw5rFq1CocOHSowwSJjK8kLPu2/cwcvP+2CaNKkSYGYV+QkMDCQ3R42bJigYfDYsWPZwlLJkiWxevXqQvE76YuFqanK8TssjzvHjIHfIHLPnj1sh29QUNBn8TkWix/4ipQlssuh1vSrV69Yw8WaNWsWqP8bDw8PLF68WG0pKSsrK4SHh+P48eNal3vp27cvu92yZUuMHDlS8Pm2tbXFt99+i/nz56NMmTLw8vKCs7MzNm/ezBqgJyYmYsCAAWz3u0wmE5TKmzJlCtq0aZPbXxeA4lqAK6GSnKxjpriaxY9du3axzwGH34QWgGDOpVw5gRhH0Tn7kAJHuYagWFBN3cV7RkYGfvvtN/a1clBcuQt9vXr18jRWbUkkEsGFmbe3N+bPnw+JRCK4OOOYmpqK3p8TrtlkZmYmevXqhWnTprHHfHx8MHHiREG2myFVrJgdFF+wYAHWr18veFw5y4n/PotdtO/cuZPVgq9Vq1aB2uJL1LM0NYVUaeJY2OqwK2eKA4oSRfztyX379i2U2Uz9+vnD3V2R3RkZGckm5IMGDULMl1+ikZp6fFxQ/M2n4+/HrCzUq1cPXbt2RVBQEJ4+fcpqadetW5c1LiwqrK2tVc5lujTMzE/aBE5/++03VmJixIgR+Vp3V5lYybCIiAiVOrW6NlQMCgrC8ePHMXXqVLU12Tt27Ii9e/eyi7qff/4ZJUqUQN++fTFixAhMnDgRv//+u6C2fmBgoKBPiC4aNMheZD9+/Di7zZUIUQ6q5HR+FTNv3jzBRSCgCMLzm3m+e/cOqa8V/VucSuU9oGrvkh0UT0hIwPHjx1mtZG2kpaWhQYMGsLe3R3h4OL799lu2SNezZ0/WxHj69Omi31+xYkXUqVNHkJSwc+dOwWIoJy4uTrDQv2DBAtjZ2WHhwoUsWDJ58mSdznclShTD+vWdYW9vAQsLCwwbNoxlt3NEM8VFaoq/fPmSZfybmZnhu+++y/V4jMnPzw/9+vUTZAUWdfyM1JO8xSNjNObTBb/J+j///IOKFSvixo0biImJYU39LC0tceDAgQKf+W4IytniFQvh376FhQX7zPJLd/L7dRRmjo6OKqXE6orsPM/p3Hvr1i12m+t5UpD069cPjx8/xr///oubN28iPDwcLi4u6Ny5M65cuYKFCxeiYUPxnj1igoKCsH37dsybNw/R0dFaf1/58uVx5swZViZv+/bt+PLLL/Hx40ds27YNFy9eBKBYWNAl2YCPK6GSm0zxnBptyuVyQc84Dj8onpKSwuaKzs7OVE+8gKCgODEa5ZVX5a37gPpt3tOmTUN8fDwAoGHDhioXI8onY10Cz7oaO3Ysvv32W3Tp0gW7du1i24wqV67MSklw6tWrp1NZEP4Jmn+y+fHHH5GQkIBZs2bl2yo0P1NcjPJih5mJCct8Eps48Bc7Zs6cWaCaMRL1JBKJSgmV3DY+MTZ+pvjt27dx4sQJeHp6shX/cePGYc2aNUYNEOrKzc0W168PQ3x8uCDTIidcUDwlPR0yuRw7//uPlYaKjY0VNOkp6MFgQ+FnztSrVw92dnYanm18ymXJlMnlcrYTSyqVCjJ+jIGfKX7r1i2MGTNGsFMMUNTIV14M17f69etj3rx5OWYzmpqaom3btli3bl2ed6i1bJm9pZbf6JfLkFbuxWJpasrmUtqUT7l37x7b6WFra8uy3LOysgSNofgX9I7ujrn8LVRZ2VnB1EIxDzhy5AiaNGmChg0bssbpOVm1ahUrn7d48WJs3LgRgOICkwu2AYq5X0xMDHr06IEFCxbg5cuXSE5OxvXr13HmzBkcOHBAsHNPuUknoAisc+XuRowYgU6dOgFQ1K+/ceMGbty4ofOCDAC0bVsez56Nw5s3b7B48WIsWrRI8Li2NcW3b9/OdtgNGDBAsMhLCicXa2vR97+wBMU9PT0FgfFXr14hLCxMUDd7wYIFoj04igJ+w0Ybc3O4itSqLgzEdvPWrl3bCCMxDP5OOXdbW7QQKXVhZmLCFqnFzr38RuwFMSgOAMWLF0f9+vXh5+eHhQsXIikpCdHR0To3ZO7YsSPGjh2bYw8WZWXLlsXatWtZkkJ0dDSmTp0qOM/OmDEjz/MrLlM8NzXFc0oqiYmJwcmTJwFAUBKFHxQ/cuQI+xndunUrlNeUnyMKihOjGjVqFLvdWiTDUKx8Snx8PNuib2Zmhp9//lnl+9q1a8cC0G5ubrla3cwrU1NTzJkzB1u3bhWUcZFKpSq14nJbOoUjlvk+bdq0PDeo0YWtrYXGeu0uIpM87qSifEJ5/fo19uzZA0DxvvG3XpKCTzkozq8FXBjwJzCnT59G69at2dfOzs6YNGmSMYalN/b2lihfXnXbpybcRZscis/rPl5wDICgfm1RDYpHRETA398f7u7uKmXBCiI7DWXJAODUqVMsCNqsWTO4urrm29jEeHt7s3IzW7ZsEZzz58+fj+PHjwsWUw1pzJgxOHv2LIKCglC2bFn07dsXv/76K1avXo1Lly7h0aNHSElJwe7duwXbynXVsGH2wuKFCxcACMuGKAfFJRKJ2vOrmO+//55lhA8bNkwwV7p69Sq7zc/Kdy4rXNzXhUQiUXmdK1euYPXq1Tl+b3p6uuC4wzdy5EiVC/CQkBCsX78eo0aNgpOTk8qiVb9+/djf1+rVqwUZ8levXmVNK93c3FTKQ/n5+QmaZ+nK3NyEJQAo9ynIqaY4l63G36Xw9ddf53lMxPgkEglqKwUcfX19C1VW9cqVKwW7Wc+cOcNK/HTt2hWDBg0y0siMjz9n9nRwMFrfjrxSDppKpdLPaqEjIiICo0aNQuvWrbGje3dYqEk645LAxM69hSEoXpC0b98eu3btYgl+s2fPZv0HGjZsKLg+0xUXFH//PkMQCNeYKa6hfMrHjx8FSUe//PIL20XBD4rv37+f3VbXS4TkPwqKE6OaMWMGvv76a4SHh6ONWFCct4rOlU+JiopiB6zx48eLZofZ2dnh2LFjmDx5Mg4dOlRgso35GRMSiSTXjZk4AQEBgo7Mfn5+mDhxYp7HpyvlGu58LiINOcQu2m/fvo2KFSuy9/bLL79Uu5WdFEyFPShuZWXFmurcuXNHkLX4+++/w8HBwUgjMx5+JtObtDQc/lTTWUz9+vXzYUQFT8mSJXHhwgU8evQIjRo1MvZwcqQp0yU5OVnQxKggBNfMzc1Zc02OiYkJli5dim+++QaNGjXK11q0NWvWxN9//4179+5hzZo1GDBgAMLCwlCtWjW4u7vrtW+CnZ0FypRRBHm5i+rU1FRW2kY5KA5kX7SJbe3lu3v3Lsu4L168OCZNmoQqVaqwx/lBcS4gDwBuvnkP9gNA2WqqTWrHjx+P7777DgcPHmS/o7K1a9eyOvJ8xYsXR3h4eK7HUbJkSXTp0gUA8Pz5c1haWmLq1KmQyWSCGvPjxo3Ll7mk8u5BB5H32EapfMrb9HR2oe3u7o46deoYdpAk34Tz3ss6pUph586dhar2trW1NSZPnowZM2YI7i9btix+/fXXQhsI1oc0Xm8DsR0BhQVX0pPj5+eHYsWKGWk0+mdmZoYFCxZg7969qKWhxxV3PhY79xb08ikFUevWrUV3ts6cOVMvxw0np+y52suXL9ntNF65XpUSdRrmz8uWLRMklLRv355dBz9+/BgymQxyuRx79+4FoJjHFpZdP0VB4Tmrks+SjY0NfvvtNyxcuBAmIpM85Yv3TJkMW7duBaCoY8a/eFdWoUIFTJs2TS9ZPPoSEhKCefPmoUmTJli/fr3Khb62pFIpqxdZrFgxLFu2zKiN25SD4tyFdZ1SpeAkEiDgB8W5C98hQ4awJiRSqVRQw5MUDoU9KA4AwcHBKvedPXtW9P6igB+Qefz2LW6/fi36PG9vb71kxhLDU1eWLCsrC4GBgWzrp6urK0JDQ/N9fGKU67aPHz8+3/pmGJu3t6JcyatXr5CcnMyyxAHxoLi2meLz5s1jNWBHjRoFOzs7VK5cmT1++fJlyOVyyGQyHD58mN3vVl4/n/MqLaoASte1aWlpmDlzJgIDA9GlSxeVhpgZGRmCciexsbGYNWsW2rdvj61bt+q8cDl69GhBoHHatGlo27YtK9Hi7e2NwYMH6/TaeeUgEohXzlbbduMGy3APCQkpVEFTolm3ypVxYdAgxA4YgNP9+7OF+8Jm+PDhrBGyg4MDoqOji2SiAV8QL8ParxDWE+coB8WVvy4qbDWce7lFbYlEQqWtcmHatGn44YcfWCna3r17q/Td0JWbW/ZO9idPnrDbXM8WQHWxSl1D1Tdv3gh2xHD95Lid9JmZmXj27BkuX77MelY1bdq0wJdbLEpo1kQKNOXyKVMOH2aB07Zt2xa6g4lEIsHYsWNx9OhRleaguTVixAhcu3YN//33n9FXGtu2bctu16hRAxcvXkRcXBwO9+kjuprLnVRkcjneZ2QgOS1NcNH9ww8/FNqJf1H2OQTFlbfkeXp6olatWkYajfHxAzKxvO1/yllAHTt2zLcxkbzhT+rf8DJi/vnnH5w7dw6AYmFy5cqVBSbbq02bNuy2hYUFIiIijDeYfObt7cBu3717F48fP2ZflxBZdOYuzD9kZiLzUy1sZUlJSaxUiY2NDcuwLlu2LGtwxZWAMTExwZUrVwAApSuXhpWdfjLhS1UshbBfwrBs2TJcvXpVZeEjJiZGpanxkiVLWLPV1q1bIyAgABMnTsTOnTvzNA+qU6cONmzYIJhT/v3334Kfm5+fBf5OQHuRoDj/XPvqwwfM/bSQBYA1GSWfD383NwSUKlWos6odHBxw6tQpnDlzBv/991+Rnldx+vv7w8bcHN6OjpiuVF6zMFHeIVdUdw1yc6sMmQzpSgu6XAaxh4dHgdm9XhiYmJjg+++/x+PHj3HlyhW9lspTFxTnenMAQDGlhEOx8imZmZno0aMHXr16BUBxDuaOb/zyso8ePRJkvlODzYKFguKkQONfDGy8ehWzTpxgXxeEbd3GVqlSpQIReAwODsa8efPQu3dvbNmyBaampqhevbrKyYSjvAPg6P37LGOtX79+iIyMzJdxE/1SDoprqjVfULVo0ULQNKh79+6F+kI0r/hB8TO8oHhkZCR69OgBQFF2xlhZlCT3TKVSOH56X5/ySgStW7eO3f7tt9/Qrl27fB+bOp07d0bfvn1RtmxZrFy5UhA0/NxxmeKAoqwTv5FkOScnleery2TiW7BgAcssHjJkCBwdFT9DKpUKsrC4JAROtUD91jIuU7UMBg8ejMqVK+PChQt48OABFi1axHa+RUVFYfv27QCAXbt2YfTo0ex7J0+erNexdOvWDcnJySq71Bo3bpzvdT/5n8X2IgkC/C3c++/cwY0XLwAomsyL9ZwhpCCwtLREnTp1itTxW5PKJUvi5fjxuDF8ODwLcdZ8iRIl2AKmt7c3evfubeQRGQc/YMrPFn/16hULmPqIlIolObOzs0OVKlX0ej3m6qpDUFykfMrKlStZSRQHBwfMnDmTPYd/Hbxs2TK22O7s7Iw+ffro49cgekJBcVKg8S/u+BfvvXr1QqdOnYwxJCKCy4Bft26dVid85aD4gTt32Nf0vhZe9kpb+a1F6skXdJaWlli6dCns7e1Ro0YNjBkzxthDMip+UPw0r45vhQoV8Pvvv+PEiRO4fft2gSpTRXLm9qlu8eO3byGXy/HHH39g48aNABS1mXXtd2EopqamWLNmDe7du1fkMmG9vLKD4nFxcawOOAC04DUH5miqGQ8otvkuWbIEgKJeOz/QDAiz8vmqtqyKWh0Mm91ZunRpDB8+XBD4nzt3LgBFEJwrt9a3b1+DZSP+/PPP6NevH4oVKwZ/f3+j1D0ODg5GQkICbg4fjpoiZaksTExgIdJzZdGiRUV6EZeQwsbcxATmn0H/pPnz5+O///7D9evX2SJrUSNYkOY1YeTXE6egeMHh5pbdvyMpKYnd1hQUF3uP16xZw+7bunUrypTJbpDOT1xcuXIlu71w4ULY2GQH5YnxUVCcFGjOIttVLS0tsWrVKpr4F2L8k8qkQ4ewMDYWADWdKOzcPpMTfMeOHfH69WtcvHgRzs7Oxh6OUfGD4vfevGG3K1SoAKlUioYNG1It8ULI/VNQPC0zE/tu3RJkdoWFhcFcadcHMR5+pvi8efNYhnd7X1/UEdmNI7a9l2/JkiV4+/YtAKBPnz6CnTEA0KNHD7bI5enpifj4eNy5cwedv+sMqUn+XDYMGDCA9SY5deoUjh49iosXLwJQ9CxZtWqVwX62hYUFVq1ahXfv3uHChQvw8/Mz2M/SxMfHR22dYYlEwha2OH5+fqhdu3Z+DI0QQlT4+vrCQqTPRVGhLlOcguIFU+nS2eXSuDrfgLCmuKag+Ju0NBy4cwexn2IYNWrUQMuWLQXPF9sxbWVlRaVTCiAKipMCzcLUFC5K2ab16tWjC/ZCjn9S2XbjBrsdGBhY6OrEk2zNeVmLk5RqDBY2tOimINbkTSqVohyvQRQpfPgLWCP37WO327Rpo/eyFCRvKld2ZsejNF4N+IlqjrGaMsVTU1OxYMECAIrPsViz8mLFiiE2NhYHDx5EXFwcypcvDy+RjHRDkkgk+PLLL9nXYWFh7HbPnj3zpZFkQT8HKC9CN2jQwEgjIYQQoq502aVLl9jt8uXL5+uYiHoVK5YAd5rn+qYAwLt379ht5aC4pakpe59PJCai1e+/s8fEygaJBcUDAgJYiThScFBQnBR4pZWCpMoNPUjhY6cmk2D+/Pn5PBKiT23Ll8e6kBD8HByMSY0bG3s4RA/EguLe3t5FOhvoc+DOyzK99anWpbu7O3bs2AFbpQxUYly2thaoXLmy4L4yZcqgnpp+Iuqy1QDg119/xfPnzwEoamiry1qztbVFixYtYG9vn5eh5wm/ee/du3fZbcqwUlDOFG/YsKGRRkIIIUSs3jQAHDp0iN0uqk1ICyJra3P4+Cj6sly8eBF37tyBTCZj9d8BwEmkmblysiagKDuobVCc/gYKJgqKkwLPQ+mijILihZ9YUPzFixdsuzQpnKQSCXpXr46IevVgTbs5PgvKx18AtEX/M1BRpCxDaGgoTE1NjTAakhPleU+PHj0gVZPJrC5bTS6Xs1riAAp8Q+uqVasKanMCitIpviKNJ4sid6VM8ca0EE0IIUYjVm965syZOHfuHACgYsWKcHFxMcrYiLg6dRRB66ysLJQrVw7169dni/CmUqlovMJVpFTo6dOnRcttOjg4oJhSKWDa1VUwUVCcFHheSh25aYWt8FPOPi1pbY3ixYsbaTSEEHXcbW1VGrrVrVvXSKMh+iKWZcwvV0EKlrCwMFbOw9bWFqNGjVL7XHXlU44dO4aEhAQAQIsWLQr8IrREIlFpvN2jRw8jjabg8VSaG9O2fEIIMR5BP4/0dESdOYPvvvuO3RceHm6MYRENhg6tDak0O8EgNjaW1YAvbmUlWkbNRSkoPnr0aLW77iQSCcqWLSu4r169enkdNjEACoqTAq8lr5Zlc09Pqjn9GVBeZfWlgDghBZJUIkFdpQBqcHCwkUZD9KV88eKCRta+vr40US/A6tSpg/3792PYsGE4ePAgXF1d1T5X3RZurpY4oGhkWRiMGzeONQJ1dHQU1BYv6rpVrgz7T+/1j4GBBb4GOiGEfM74C9I/nz6NUbx+LTNmzMDQoUONMSyiQcOGZbBr11eiVQi8HB1FvkO1fErz5s01/gz+45UqVULJkiV1GCkxNAqKkwKvbfnymNmiBfpUr47VSllDpHBSPqH4OjkZaSSEkJxENm4M80/Z4pGNG6NixYpGHhHJK6lEgrG8LZzTp0+noFoB17JlSyxevBgBAQEanye2hTshIQHbt28HoKhx2aVLF8MNVI88PDxw6dIl/P7774iLi9O4GFDUeNjb4/LQoTg3cCDGUT1xQggxKmfete2NFy/Y7cjISEyaNInmWAVUmzblcfz4cfTs2VNwf0018w3lRL4mTZpofP1x48ahVKlSsLS0xLRp0/I2WGIwVDySFHgSiYSa9n1myijVKfYTqW9LCCkYgsqVQ2JEBDJkMpXGx6TwGtegAeqUKgVrMzMEdOtm7OEQPRFrtBkVFQW5XA4AGDlyJMwLUc+HEiVKoFevXsYeRoFUxt5eZT5FCCEk/4ntem7fvj1mzJhhhNGQ3Jo8eTJ27dqF5ORkWJuZYYia/kntypfHN//8g0yZDF9VqZJjQ3JPT08kJiYiPT0dViKNO0nBQEFxQki+s7WwQDEzM7zPyAAA1BHpzkwIKTiUa+iRwk8ikaCZp6exh0H0TLnR5sesLPz5558AACsrKwwaNMhYQyOEEEI+S242NrAxN8e7Tzu0AGD48OFGHBHJDV9fXyQkJODYsWOofvQofNTsYi/n5ITzgwbh6rNn+KJCBa1eWyqVUkC8gKPyKYQQo/izc2c4FyuG9r6+aFymjLGHQwghhBR6gkabHz9i361bePXqFQAgJCQEDkoNGgkhhBCSNxKJBBV5O5897OwQFBRkxBGR3HJ2dkaXLl3UBsQ51Vxc0KNqVViZmeXTyIihUaY4IcQoOlWogI5+flRjjRBCCNET5Uabv1++zL7u3bu3MYZECCGEfPYG1aqFs48fAwCmNG0KqZTyTwkpDCgoTggxGgqIE0IIIfrDzxRPTE5GwsuXABQZUK1atTLWsAghhJDPWn9/f/g4OUEqkaBJ2bLGHg4hREsUFCeEEEIIIeQzYG5iAnsLCySnp+Pqs2fs/q+++gqmpjTtJ4QQQgyBerUQUjjRng5CCCGEEEI+E6Xs7FTu69WrlxFGQgghhBBCSMFVaILir169Qs+ePWFnZwcHBwf0798f79690/g9K1asQLNmzWBnZweJRII3b97kz2AJIYQQQggxglK2toKvfX19Ubt2bSONhhBCCCGEkIKp0ATFe/bsiWvXrmH//v3YtWsXjh07hkGDBmn8nvfv36N169aYNGlSPo2SEEIIIYQQ4ymtlCneq1cv6uFBCCGEEEKIkkJRXPDGjRvYt28fzp49yzJdFi5ciLZt22L+/Plwd3cX/b6IiAgAwJEjR/JppIQQQgghhBiPh1JQvE+fPkYaCSGEEEIIIQVXocgUP3XqFBwcHARbPwMDAyGVSnHmzBm9/qz09HSkpKQI/hFCCCGEEFIYtClfnt3+okIFlClTxoijIYQQQgghpGAqFJniSUlJKFmypOA+U1NTODk5ISkpSa8/a/bs2Zg2bZpeX5MQQgghhJD8UK90afz+xRdIePkSo+vXN/ZwCCGEEEIIKZCMmik+YcIESCQSjf9u3ryZr2OaOHEikpOT2b8HDx7k688nhBBCCCEkL3pVq4ZpzZvDwdLS2EMhhBBCCCGkQDJqpvg333yDvn37anyOt7c3XF1d8ezZM8H9mZmZePXqFVxdXfU6JgsLC1hYWOj1NQkhhBBCCCGEEEIIIYQUDEYNijs7O8PZ2TnH59WvXx9v3rzB+fPnUatWLQDAoUOHIJPJULduXUMPkxBCCCGEEEIIIYQQQshnolA02qxYsSJat26NgQMHIjY2FidPnkR4eDi6d+8Od3d3AMCjR49QoUIFxMbGsu9LSkpCXFwcbt26BQC4cuUK4uLi8OrVK6P8HoQQQgghhBBCCCGEEEKMq1AExQFg/fr1qFChAlq2bIm2bduiUaNGWLFiBXs8IyMD//33H96/f8/uW7ZsGfz9/TFw4EAAQJMmTeDv748dO3bk+/gJIYQQQgghhBBCCCGEGJ9Ry6fkhpOTE/7880+1j3t6ekIulwvumzp1KqZOnWrgkRFCCCGEEEIIIYQQQggpLApNpjghhBBCCCGEEEIIIYQQklcUFCeEEEIIIYQQQgghhBBSZFBQnBBCCCGEEEIIIYQQQkiRQUFxQgghhBBCCCGEEEIIIUUGBcUJIYQQQgghhBBCCCGEFBkUFCeEEEIIIYQQQgghhBBSZFBQnBBCCCGEEEIIIYQQQkiRQUFxQgghhBBCCCGEEEIIIUUGBcUJIYQQQgghhBBCCCGEFBmmxh5AQSeXywEAKSkpRh5JEZCert3z9PBepKdq+bNy6fP4O9Hl/0bN763tewrk+X011HsKFOX3FVB5b/PxPQXos6peXv5f8vCeAgX6fQWK6nsr8jvTZ7WAoveXj95fDr3HhVNu/8+M+z7TuVdbhfNzTO+vGCO9l0CBPS4X3vcyJ4XzWpcYDve3zsV01ZHIc3pGEffw4UN4eHgYexiEEEIIIYQQQgghhBBCtPDgwQOULl1a7eMUFM+BTCbD48ePYWtrC4lEYuzh5KuUlBR4eHjgwYMHsLOzM/ZwCCH5gD73hBQ99LknpGihzzwhRQ997gkpWor6Z14ul+Pt27dwd3eHVKq+cjiVT8mBVCrVuKpQFNjZ2RXJDxEhRRl97gkpeuhzT0jRQp95Qooe+twTUrQU5c+8vb19js+hRpuEEEIIIYQQQgghhBBCigwKihNCCCGEEEIIIYQQQggpMigoTtSysLDAlClTYGFhYeyhEELyCX3uCSl66HNPSNFCn3lCih763BNStNBnXjvUaJMQQgghhBBCCCGEEEJIkUGZ4oQQQgghhBBCCCGEEEKKDAqKE0IIIYQQQgghhBBCCCkyKChOCCGEEEIIIYQQQgghpMigoDghhBBCCCGEEEIIIYSQIoOC4kStxYsXw9PTE5aWlqhbty5iY2ONPSRCiIHMnj0bAQEBsLW1RcmSJRESEoL//vvP2MMihOSTOXPmQCKRICIiwthDIYQY0KNHj9CrVy8UL14cVlZWqFq1Ks6dO2fsYRFCDCArKwvff/89vLy8YGVlhXLlymH69OmQy+XGHhohRE+OHTuGDh06wN3dHRKJBH/99ZfgcblcjsmTJ8PNzQ1WVlYIDAxEQkKCcQZbAFFQnIjatGkTxowZgylTpuDChQuoXr06goOD8ezZM2MPjRBiAEePHsXw4cNx+vRp7N+/HxkZGQgKCkJqaqqxh0YIMbCzZ89i+fLlqFatmrGHQggxoNevX6Nhw4YwMzPD3r17cf36dfz0009wdHQ09tAIIQYwd+5cLF26FIsWLcKNGzcwd+5c/Pjjj1i4cKGxh0YI0ZPU1FRUr14dixcvFn38xx9/RFRUFJYtW4YzZ87A2toawcHBSEtLy+eRFkwSOS0TEhF169ZFQEAAFi1aBACQyWTw8PDAiBEjMGHCBCOPjhBiaM+fP0fJkiVx9OhRNGnSxNjDIYQYyLt371CzZk0sWbIEM2bMQI0aNbBgwQJjD4sQYgATJkzAyZMncfz4cWMPhRCSD9q3bw8XFxesWrWK3delSxdYWVnhjz/+MOLICCGGIJFIEBMTg5CQEACKLHF3d3d88803GDt2LAAgOTkZLi4uWLt2Lbp3727E0RYMlClOVHz8+BHnz59HYGAgu08qlSIwMBCnTp0y4sgIIfklOTkZAODk5GTkkRBCDGn48OFo166d4JxPCPk87dixA7Vr10ZoaChKliwJf39//Prrr8YeFiHEQBo0aICDBw8iPj4eAHDp0iWcOHECbdq0MfLICCH54e7du0hKShLM8+3t7VG3bl2K7X1iauwBkILnxYsXyMrKgouLi+B+FxcX3Lx500ijIoTkF5lMhoiICDRs2BBVqlQx9nAIIQayceNGXLhwAWfPnjX2UAgh+eDOnTtYunQpxowZg0mTJuHs2bMYOXIkzM3N0adPH2MPjxCiZxMmTEBKSgoqVKgAExMTZGVlYebMmejZs6exh0YIyQdJSUkAIBrb4x4r6igoTgghRGD48OG4evUqTpw4YeyhEEIM5MGDBxg1ahT2798PS0tLYw+HEJIPZDIZateujVmzZgEA/P39cfXqVSxbtoyC4oR8hjZv3oz169fjzz//ROXKlREXF4eIiAi4u7vTZ54QQkDlU4iIEiVKwMTEBE+fPhXc//TpU7i6uhppVISQ/BAeHo5du3bh8OHDKF26tLGHQwgxkPPnz+PZs2eoWbMmTE1NYWpqiqNHjyIqKgqmpqbIysoy9hAJIXrm5uaGSpUqCe6rWLEiEhMTjTQiQoghjRs3DhMmTED37t1RtWpV9O7dG6NHj8bs2bONPTRCSD7g4ncU21OPguJEhbm5OWrVqoWDBw+y+2QyGQ4ePIj69esbcWSEEEORy+UIDw9HTEwMDh06BC8vL2MPiRBiQC1btsSVK1cQFxfH/tWuXRs9e/ZEXFwcTExMjD1EQoieNWzYEP/995/gvvj4eJQtW9ZIIyKEGNL79+8hlQpDPiYmJpDJZEYaESEkP3l5ecHV1VUQ20tJScGZM2cotvcJlU8hosaMGYM+ffqgdu3aqFOnDhYsWIDU1FSEhYUZe2iEEAMYPnw4/vzzT2zfvh22trasxpi9vT2srKyMPDpCiL7Z2tqq9AywtrZG8eLFqZcAIZ+p0aNHo0GDBpg1axa6deuG2NhYrFixAitWrDD20AghBtChQwfMnDkTZcqUQeXKlXHx4kX873//Q79+/Yw9NEKInrx79w63bt1iX9+9exdxcXFwcnJCmTJlEBERgRkzZqB8+fLw8vLC999/D3d3d4SEhBhv0AWIRC6Xy409CFIwLVq0CPPmzUNSUhJq1KiBqKgo1K1b19jDIoQYgEQiEb1/zZo16Nu3b/4OhhBiFM2aNUONGjWwYMECYw+FEGIgu3btwsSJE5GQkAAvLy+MGTMGAwcONPawCCEG8PbtW3z//feIiYnBs2fP4O7ujq+++gqTJ0+Gubm5sYdHCNGDI0eOoHnz5ir39+nTB2vXroVcLseUKVOwYsUKvHnzBo0aNcKSJUvg6+trhNEWPBQUJ4QQQgghhBBCCCGEEFJkUE1xQgghhBBCCCGEEEIIIUUGBcUJIYQQQgghhBBCCCGEFBkUFCeEEEIIIYQQQgghhBBSZFBQnBBCCCGEEEIIIYQQQkiRQUFxQgghhBBCCCGEEEIIIUUGBcUJIYQQQgghhBBCCCGEFBkUFCeEEEIIIYQQQgghhBBSZFBQnBBCCCGEEEIIIYQQQkiRQUFxQgghhBBCiEZNmjTBn3/+mW8/b9++fahRowZkMlm+/UxCCCGEEFJ0UFCcEEIIIYQQPevbty8kEgn7V7x4cbRu3RqXL1829tBybceOHXj69Cm6d++ebz+zdevWMDMzw/r16/PtZxJCCCGEkKKDguKEEEIIIYQYQOvWrfHkyRM8efIEBw8ehKmpKdq3b2/sYeVaVFQUwsLCIJXm76VD3759ERUVla8/kxBCCCGEFA0UFCeEEEIIIcQALCws4OrqCldXV9SoUQMTJkzAgwcP8Pz5cwDAvXv3IJFIsHHjRjRo0ACWlpaoUqUKjh49Knidq1evok2bNrCxsYGLiwt69+6NFy9esMebNWsGiUSCbdu2Cb7P398fEokER44cYfft2rUL1atXh5WVFctiDwkJUfs7PH/+HIcOHUKHDh0E97958waDBw+Gi4sLG/euXbvY4ydOnEDjxo1hZWUFDw8PjBw5EqmpqexxT09PLFiwgH393XffoXTp0rh37x67r0OHDjh37hxu376tdnyEEEIIIYTogoLihBBCCCGEGNi7d+/wxx9/wMfHB8WLFxc8Nm7cOHzzzTe4ePEi6tevjw4dOuDly5cAFMHnFi1awN/fH+fOncO+ffvw9OlTdOvWTfAapUqVwooVK9jXsbGxLPjOefPmDb788ks0a9YM169fx5MnT1ReR9mJEydQrFgxVKxYkd0nk8nQpk0bnDx5En/88QeuX7+OOXPmwMTEBABw+/ZttG7dGl26dMHly5exadMmnDhxAuHh4aI/46effsLy5cuxf/9+eHp6svvLlCkDFxcXHD9+XOMYCSGEEEIIyS1TYw+AEEIIIYSQz9GuXbtgY2MDAEhNTYWbmxt27dqlUoYkPDwcXbp0AQAsXboU+/btw6pVqzB+/HgsWrQI/v7+mDVrFnv+6tWr4eHhgfj4ePj6+gIAOnbsiOjoaNy/fx9ly5bFihUr0K9fP0yfPp19X3x8PN6/f49vv/0W7u7uAAArKyukp6er/R3u378PFxcXwZgPHDiA2NhY3Lhxg/18b29v9vjs2bPRs2dPREREAADKly+PqKgoNG3aFEuXLoWlpSV77sqVK/HDDz/g0KFDgsA7x93dHffv39fwv0wIIYQQQkjuUaY4IYQQQgghBtC8eXPExcUhLi4OsbGxCA4ORps2bVSCvPXr12e3TU1NUbt2bdy4cQMAcOnSJRw+fBg2NjbsX4UKFQBAUFbE3NwcvXv3xsqVK5GSkoKYmBh8/fXXgp/j4eEBU1NTbNiwATKZTKvf4cOHD4IgNgDExcWhdOnSLCCu7NKlS1i7dq1gzMHBwZDJZLh79y573vbt2zF48GC4u7ujSpUqoq9lZWWF9+/fazVWQgghhBBCtEVBcUIIIYQQQgzA2toaPj4+8PHxQUBAAFauXInU1FT8+uuvWr/Gu3fv0KFDBxZc5/4lJCSgSZMmgucOGjQIa9aswbp16xAUFIQSJUoIHndzc8PSpUsxa9YsWFpawsbGBuvXr9f480uUKIHXr18L7rOysspxzIMHDxaM99KlS0hISEC5cuXY806ePIlNmzZBIpFg6tSpoq/16tUrODs7a/x5hBBCCCGE5BaVTyGEEEIIISQfSCQSSKVSfPjwQXD/6dOnWYA7MzMT58+fZ/W3a9asiejoaHh6esLUVPPU3dfXF+XLl8ekSZPw119/iT6nT58+WLNmDfz9/REREYFvv/0WWVlZal/T398fSUlJeP36NRwdHQEA1apVw8OHDwXlW/hq1qyJ69evw8fHR+N4J0yYgK5du6JMmTJo0qQJOnfujICAAPZ4Wloabt++DX9/f42vQwghhBBCSG5RpjghhBBCCCEGkJ6ejqSkJCQlJeHGjRsYMWIEy/zmW7x4MWJiYnDz5k0MHz4cr1+/Rr9+/QAAw4cPx6tXr/DVV1/h7NmzuH37Nv7++2+EhYWJBrPnzp2LqVOnonnz5qJj+uabbyCRSPDzzz/Dx8cHtra2Gn8Hf39/lChRAidPnmT3NW3aFE2aNEGXLl2wf/9+3L17F3v37sW+ffsAAN9++y3+/fdfhIeHs6z27du3qzTadHJyAgDUqVMHERERCAsLw8ePH9njp0+fhoWFhaC8DCGEEEIIIfpAQXFCCCGEEEIMYN++fXBzc4Obmxvq1q2Ls2fPYsuWLWjWrJngeXPmzMGcOXNQvXp1nDhxAjt27GClT9zd3XHy5ElkZWUhKCgIVatWRUREBBwcHFQadgKKAPOYMWMgkUhUHtuwYQM2b96MzZs3w8zMTKvfwcTEBGFhYSplVqKjoxEQEICvvvoKlSpVwvjx41mQvlq1ajh69Cji4+PRuHFj+Pv7Y/Lkyay5p5hp06ZBJpMJyqhs2LABPXv2RLFixbQaKyGEEEIIIdqSyOVyubEHQQghhBBCSFFz7949eHl54eLFi6hRo4axh6NWUlISKleujAsXLqBs2bL58jNfvHgBPz8/nDt3Dl5eXvnyMwkhhBBCSNFBmeKEEEIIIYQQtVxdXbFq1SokJibm28+8d+8elixZQgFxQgghhBBiEJQpTgghhBBCiBEUlkxxQgghhBBCPjcUFCeEEEIIIYQQQgghhBBSZFD5FEIIIYQQQgghhBBCCCFFBgXFCSGEEEIIIYQQQgghhBQZFBQnhBBCCCGEEEIIIYQQUmRQUJwQQgghhBBCCCGEEEJIkUFBcUIIIYQQQgghhBBCCCFFBgXFCSGEEEIIIYQQQgghhBQZFBQnhBBCCCGEEEIIIYQQUmRQUJwQQgghhBBCCCGEEEJIkfF/evM2qoKn/McAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signals = np.load(\"/home/meshalkin/Diplom/ludb/data/signals/00001_hr_unsupervised.npy\")\n",
    "masks = np.load(\"/home/meshalkin/Diplom/ludb/data/masks/00001_hr_unsupervised.npy\")\n",
    "index = 10\n",
    "plot_signal_with_mask(signals[index], masks[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e1090-ac2e-4753-b924-9af6bb2fdcab",
   "metadata": {},
   "source": [
    "Так выглядит сигнал и оригинальная маска. Будем надеяться, что наша нейросеть, покажет такие же результаты!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6190e-524e-4398-82ee-f8ec7781fa38",
   "metadata": {},
   "source": [
    "### 1.2. Разработка метрики для контроля качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973b7a0-f74e-4bea-9342-9d5899121835",
   "metadata": {},
   "source": [
    "В коде, приведенном ниже производится разработка собственной метрики, основанной на f1score, precision, recall и confusion_matrix. Данная метрика будет отслеживать качество работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "363b040a-50e5-44d0-8066-a5733ef70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetric:\n",
    "    def __init__(self,\n",
    "                 monitor: Literal['p', 'qrs', 't', 'all'] = 'all',\n",
    "                 orientation_type: Literal['onset', 'offset', 'all'] = 'all',\n",
    "                 return_type: Literal['precision', 'recall', 'f1', 'confusion_matrix'] = 'confusion_matrix',\n",
    "                 samples=75):\n",
    "\n",
    "        assert monitor in ['p', 'qrs', 't', 'all']\n",
    "        assert orientation_type in ['onset', 'offset', 'all']\n",
    "        assert return_type in ['precision', 'recall', 'f1', 'confusion_matrix']\n",
    "\n",
    "        self.samples = samples\n",
    "        self.monitor = monitor\n",
    "        self.orientation_type = orientation_type\n",
    "        self.return_type = return_type\n",
    "        \n",
    "        self.metric_to_func = {'precision': self.__precision,\n",
    "                               'recall': self.__recall,\n",
    "                               'f1': self.__f1}\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        assert len(y_pred.shape) == 2 # Это для батча или для каналов ?\n",
    "        \n",
    "        matrix = np.zeros((2, 2), dtype=int)\n",
    "        monitors = ['p', 'qrs', 't'] if self.monitor == 'all' else [self.monitor]\n",
    "        orientations = ['onset', 'offset'] if self.orientation_type == 'all' else [self.orientation_type]\n",
    "        for wave in monitors:\n",
    "            for orientation in orientations:\n",
    "                matrix += self.__handle(y_pred, y_true, wave, orientation)\n",
    "        \n",
    "        if self.return_type == 'confusion_matrix':\n",
    "            return matrix\n",
    "\n",
    "        return self.metric_to_func[self.return_type](matrix[0, 1], matrix[1, 0], matrix[1, 1])\n",
    "\n",
    "    def __handle(self, y_pred, y_true, wave, orientation) -> tuple[int, int, int]:\n",
    "        \n",
    "        index = ['p', 'qrs', 't'].index(wave) + 1\n",
    "        orientation = 2 * ['offset', 'onset'].index(orientation) - 1\n",
    "        y_pred[y_true == 4] = 0\n",
    "\n",
    "        y_true, y_pred = (y_true == index), (y_pred == index)\n",
    "\n",
    "        wave_true = np.logical_and(np.roll(y_true, orientation) != 1, y_true == 1).astype(int)\n",
    "        wave_pred = np.logical_and(np.roll(y_pred, orientation) != 1, y_pred == 1).astype(int)\n",
    "\n",
    "        true_batch, true_indexes = np.where(wave_true == 1)\n",
    "        \n",
    "        tp = fn = 0\n",
    "        \n",
    "        for batch, x in zip(true_batch, true_indexes):\n",
    "            wave = wave_pred[batch][x - self.samples // 2: x + self.samples // 2]\n",
    "            if wave.sum():\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            wave[:] = -1\n",
    "        \n",
    "        fp = (wave_pred[:, self.samples:-self.samples] == 1).sum()\n",
    "        return np.array([[0, fp], [fn, tp]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __precision(fp, fn, tp):\n",
    "        if fp + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __recall(fp, fn, tp):\n",
    "        if fn + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __f1(fp, fn, tp):\n",
    "        precision = SegmentationMetric.__precision(fp, fn, tp)\n",
    "        recall = SegmentationMetric.__recall(fp, fn, tp)\n",
    "        if precision + recall == 0:\n",
    "            return 1\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.monitor}_{self.orientation_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352d955-6e4f-46e7-a285-9073a50b40ef",
   "metadata": {},
   "source": [
    "### 1.3. Создание датасета для загрузки данных и других вспомогательных функций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714bf6e-2004-46f7-854d-ef1a4b050c60",
   "metadata": {},
   "source": [
    "Необходимым шагом является правильная загрузка данных, уравнивание длины сигнала, если это необходимо, разделение данных на тренировочную и тестовую выбороки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ffa1a9e-6378-4b50-84dc-a912267a40df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: 493\n",
      "Размер валидационного датасета: 123\n",
      "Размер тестового датасета: 153\n",
      "\n",
      "Размеры сигналов и масок с батчом = 2:\n",
      "Размер сигнала = torch.Size([2, 12, 5000])\n",
      "Размер маски = torch.Size([2, 12, 5000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data_folder, label_folder, max_length=5000):\n",
    "        self.data_files = glob.glob(f'{data_folder}/*.npy')\n",
    "        self.label_files = glob.glob(f'{label_folder}/*.npy')\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_files[idx])\n",
    "        labels = np.load(self.label_files[idx])\n",
    "\n",
    "        # Обрезка данных и меток, если длина превышает max_length\n",
    "        if data.shape[1] > self.max_length:\n",
    "            data = data[:, :self.max_length]\n",
    "            labels = labels[:, :self.max_length]\n",
    "\n",
    "        return torch.from_numpy(data).float(), torch.from_numpy(labels).long()\n",
    "\n",
    "# Использование DataLoader\n",
    "data_folder = '/home/meshalkin/Diplom/ludb/data/signals'\n",
    "label_folder = '/home/meshalkin/Diplom/ludb/data/masks'\n",
    "dataset = SignalDataset(data_folder, label_folder)\n",
    "\n",
    "# Разделение на тренировочную, валидационную и тестовую выборки\n",
    "test_size = int(0.2 * len(dataset))\n",
    "val_size = int(0.2 * (len(dataset) - test_size))\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "\n",
    "print(f\"Размер тренировочного датасета: {train_size}\")\n",
    "print(f\"Размер валидационного датасета: {val_size}\")\n",
    "print(f\"Размер тестового датасета: {test_size}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Создание DataLoader для всех выборок\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "for i, (signal, label) in enumerate(train_loader):\n",
    "    print(f\"Размеры сигналов и масок с батчом = {batch_size}:\")\n",
    "    print(f\"Размер сигнала = {label.shape}\")\n",
    "    print(f\"Размер маски = {signal.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d4618-74bb-43e1-8303-a2cef8d84a08",
   "metadata": {},
   "source": [
    "Также нам понадобится функцию для валидации модели на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0329cca-be4e-443d-b8b1-27979136b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model_with_metrics(model, test_loader, metric, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "            \n",
    "        # Переводим outputs в формат [batch_size, length, num_channels], где num_channels - это наши классы\n",
    "        _, outputs = torch.max(F.softmax(outputs, dim=1), dim=1)  # получаем наиболее вероятные классы\n",
    "        if(outputs.shape[0] > 1):\n",
    "            outputs = torch.cat([outputs[0], outputs[1]], dim=0).cpu() \n",
    "        else:\n",
    "            outputs = outputs[0]\n",
    "        \n",
    "        outputs = outputs.unsqueeze(0) \n",
    "        outputs = outputs.expand(12, *outputs.shape[1:]).cpu() # считаем по батчу и объединяем, дублируем на 12 -> (12,10000)\n",
    "        if(labels.shape[0] > 1):\n",
    "            labels = torch.cat([labels[0],labels[1]], dim=1).cpu() # считаем по батчу и объединяем -> (12,10000)\n",
    "        else:\n",
    "            labels = labels[0]\n",
    "        all_metrics.append(metric(outputs.numpy(), labels.numpy()))\n",
    "    \n",
    "    # Средний расчет всех метрик по всем батчам\n",
    "    if metric.return_type == 'confusion_matrix':\n",
    "        final_metrics = np.sum(all_metrics, axis=0)\n",
    "    else:\n",
    "        final_metrics = np.mean(all_metrics, axis=0)\n",
    "\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e88b48-83a3-4344-a7bf-2a5d8f8a6807",
   "metadata": {},
   "source": [
    "Также необходимым аттрибутом является функция тренировки с ранней остановкой, если мы увидим деградацию на валидационном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c41d80e-1d0f-4d87-9d44-326d96b65ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция тренировки\n",
    "def train(model, train_loader, val_loader, num_epochs=100, learning_rate=0.001, patience=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_params = model.state_dict()\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            targets = targets[:, 0, :].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs.to(device), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_train_loss}')\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                targets = targets[:, 0, :].to(device)\n",
    "                outputs = model(inputs.to(device))\n",
    "                loss = criterion(outputs.to(device), targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss}')\n",
    "        \n",
    "        # Проверка ранней остановки\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_params = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"Total training time: {total_training_time:.2f} seconds\")\n",
    "    \n",
    "    # Восстановление лучшей модели\n",
    "    model.load_state_dict(best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc4336-a726-45a5-9233-59f014ab2c48",
   "metadata": {},
   "source": [
    "Функция печати метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a830a23-abb4-4b13-a666-25b7e96faece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric(model, test_loader):\n",
    "    # Пример использования:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    monitor= ['p', 't', 'qrs']\n",
    "    orintation_type = ['onset', 'offset']\n",
    "    print(\"Current f1 score:\")\n",
    "    for m in monitor:\n",
    "        for o in orintation_type:   \n",
    "            metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "            validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "            print(f\"{m}_{o}: {round(validation_metrics, 5)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea0dc4-e30e-420e-9386-392663cd7e73",
   "metadata": {},
   "source": [
    "Также введем функцию для вывода информации о модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ff886ec-c397-4c83-9184-bfb6017d3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_information_about_model(model, batch_size, num_channels, length):\n",
    "    # Создание случайных входных данных\n",
    "    inputs = torch.randn(batch_size, num_channels, length)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Проход через сеть\n",
    "    outputs = model(inputs.to(device))\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Размер входа: {inputs.shape}\")\n",
    "    print(f\"Размер выхода: {outputs.shape}\")  # Распечатает: torch.Size([2, 4, 5000])\n",
    "    summary(model.to(device), input_size=(12, 5000))\n",
    "    print(f\"Inference Time: {inference_time:.7f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775384b-81da-4a09-b704-93c104d4d53a",
   "metadata": {},
   "source": [
    "### 1.4. Разработка собственной неросети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ac786-7925-4f6d-b459-603f5a291f84",
   "metadata": {},
   "source": [
    "#### 1.4.1 Разработка версии №1. Простейшая full-convolutional сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c62cb9-3987-4327-917f-2ab1ae6536fa",
   "metadata": {},
   "source": [
    "Начнем с простой нейронной сети с тремя сверточноми слоями внутри. Так как маска распространяется вдоль всех каналов, мы можем объединить их и выдавать результат в виде распределения вероятностей по нашим классам. Точнее будет сказать, что все таки выход будет иметь ненормализированные числа, они нормализуются в процессе обучения.  \n",
    "То есть, наши данные имеют размер [2,12,5000], где 2 - размер батча, 12 - количество каналов, 5000 - длина сигнала, то выход нейронной сети будет иметь размер [2,4,5000], где 2 - размер батча, 12 - количество классов, 5000 - длина сигнала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db80ec24-4b2d-407b-89b2-f79cb945a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           2,368\n",
      "            Conv1d-2             [-1, 64, 5000]          12,352\n",
      "            Conv1d-3              [-1, 4, 5000]             772\n",
      "================================================================\n",
      "Total params: 15,492\n",
      "Trainable params: 15,492\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 5.04\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 5.32\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0014229 seconds\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SegmentationNetwork(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(SegmentationNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetwork(num_channels, num_classes).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "199223ef-c246-4df2-8394-4676d41714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9305289923420802\n",
      "Epoch 1/100, Validation Loss: 0.8425037514778876\n",
      "Epoch 2/100, Training Loss: 0.8463169908233983\n",
      "Epoch 2/100, Validation Loss: 0.8203014116133412\n",
      "Epoch 3/100, Training Loss: 0.8290192337653898\n",
      "Epoch 3/100, Validation Loss: 0.7945975988141952\n",
      "Epoch 4/100, Training Loss: 0.8170676600595235\n",
      "Epoch 4/100, Validation Loss: 0.778083925285647\n",
      "Epoch 5/100, Training Loss: 0.8015223649831918\n",
      "Epoch 5/100, Validation Loss: 0.7682302103888604\n",
      "Epoch 6/100, Training Loss: 0.7835064581048633\n",
      "Epoch 6/100, Validation Loss: 0.75904511395962\n",
      "Epoch 7/100, Training Loss: 0.7694759243413022\n",
      "Epoch 7/100, Validation Loss: 0.737248714893095\n",
      "Epoch 8/100, Training Loss: 0.749872198350999\n",
      "Epoch 8/100, Validation Loss: 0.7306437516404737\n",
      "Epoch 9/100, Training Loss: 0.7404720620346456\n",
      "Epoch 9/100, Validation Loss: 0.7166784891197758\n",
      "Epoch 10/100, Training Loss: 0.7287274964666559\n",
      "Epoch 10/100, Validation Loss: 0.7081186718517735\n",
      "Epoch 11/100, Training Loss: 0.7186712057966935\n",
      "Epoch 11/100, Validation Loss: 0.6978575221953853\n",
      "Epoch 12/100, Training Loss: 0.7088866432910024\n",
      "Epoch 12/100, Validation Loss: 0.6838101211094088\n",
      "Epoch 13/100, Training Loss: 0.6978385850244205\n",
      "Epoch 13/100, Validation Loss: 0.6761474008521726\n",
      "Epoch 14/100, Training Loss: 0.6873706021772222\n",
      "Epoch 14/100, Validation Loss: 0.6828686652644989\n",
      "Epoch 15/100, Training Loss: 0.6831215856528958\n",
      "Epoch 15/100, Validation Loss: 0.6693439195233006\n",
      "Epoch 16/100, Training Loss: 0.6784489451632326\n",
      "Epoch 16/100, Validation Loss: 0.6605812263104224\n",
      "Epoch 17/100, Training Loss: 0.6695755423321897\n",
      "Epoch 17/100, Validation Loss: 0.6674452082764718\n",
      "Epoch 18/100, Training Loss: 0.6685627884710366\n",
      "Epoch 18/100, Validation Loss: 0.6458613314936238\n",
      "Epoch 19/100, Training Loss: 0.6537456052747332\n",
      "Epoch 19/100, Validation Loss: 0.6378465838009312\n",
      "Epoch 20/100, Training Loss: 0.6505569617757913\n",
      "Epoch 20/100, Validation Loss: 0.6349855190323245\n",
      "Epoch 21/100, Training Loss: 0.6425189035624145\n",
      "Epoch 21/100, Validation Loss: 0.6268080213377553\n",
      "Epoch 22/100, Training Loss: 0.6368840978695796\n",
      "Epoch 22/100, Validation Loss: 0.6192938416234909\n",
      "Epoch 23/100, Training Loss: 0.6340930032344\n",
      "Epoch 23/100, Validation Loss: 0.62225337759141\n",
      "Epoch 24/100, Training Loss: 0.633617118905913\n",
      "Epoch 24/100, Validation Loss: 0.6182065144661935\n",
      "Epoch 25/100, Training Loss: 0.6295939435360403\n",
      "Epoch 25/100, Validation Loss: 0.6083162364459807\n",
      "Epoch 26/100, Training Loss: 0.6216484191205337\n",
      "Epoch 26/100, Validation Loss: 0.6072736603598441\n",
      "Epoch 27/100, Training Loss: 0.6184728969687875\n",
      "Epoch 27/100, Validation Loss: 0.6243041912394185\n",
      "Epoch 28/100, Training Loss: 0.6165020271592777\n",
      "Epoch 28/100, Validation Loss: 0.6077176284405493\n",
      "Epoch 29/100, Training Loss: 0.6136895281824506\n",
      "Epoch 29/100, Validation Loss: 0.6167690715482158\n",
      "Epoch 30/100, Training Loss: 0.6121461515725866\n",
      "Epoch 30/100, Validation Loss: 0.6083287385202223\n",
      "Epoch 31/100, Training Loss: 0.6104336823770392\n",
      "Epoch 31/100, Validation Loss: 0.6004093250920696\n",
      "Epoch 32/100, Training Loss: 0.6110001967744789\n",
      "Epoch 32/100, Validation Loss: 0.6094382674463333\n",
      "Epoch 33/100, Training Loss: 0.6084750403276822\n",
      "Epoch 33/100, Validation Loss: 0.6138782746368839\n",
      "Epoch 34/100, Training Loss: 0.6039554902657807\n",
      "Epoch 34/100, Validation Loss: 0.5910972005897953\n",
      "Epoch 35/100, Training Loss: 0.6028210815147832\n",
      "Epoch 35/100, Validation Loss: 0.602300922236135\n",
      "Epoch 36/100, Training Loss: 0.6013661657991679\n",
      "Epoch 36/100, Validation Loss: 0.5925910516131309\n",
      "Epoch 37/100, Training Loss: 0.600965994693007\n",
      "Epoch 37/100, Validation Loss: 0.595026740143376\n",
      "Epoch 38/100, Training Loss: 0.5987742105234972\n",
      "Epoch 38/100, Validation Loss: 0.5888487874500213\n",
      "Epoch 39/100, Training Loss: 0.5964026740688061\n",
      "Epoch 39/100, Validation Loss: 0.6062269143519863\n",
      "Epoch 40/100, Training Loss: 0.599261775190531\n",
      "Epoch 40/100, Validation Loss: 0.5854776117109484\n",
      "Epoch 41/100, Training Loss: 0.5944687741005469\n",
      "Epoch 41/100, Validation Loss: 0.6006579423143018\n",
      "Epoch 42/100, Training Loss: 0.5977495774807717\n",
      "Epoch 42/100, Validation Loss: 0.5877112707784099\n",
      "Epoch 43/100, Training Loss: 0.5955325135817895\n",
      "Epoch 43/100, Validation Loss: 0.5923827429932933\n",
      "Epoch 44/100, Training Loss: 0.5958957890508628\n",
      "Epoch 44/100, Validation Loss: 0.5993541296451322\n",
      "Epoch 45/100, Training Loss: 0.5940262536529587\n",
      "Epoch 45/100, Validation Loss: 0.5895848312685567\n",
      "Early stopping triggered\n",
      "Total training time: 35.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1276c6e0-66d6-4737-866c-87129a0c844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.35798\n",
      "p_offset: 0.37039\n",
      "t_onset: 0.45326\n",
      "t_offset: 0.47353\n",
      "qrs_onset: 0.81741\n",
      "qrs_offset: 0.82998\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f67d2888-88ad-4d6e-818a-187c2f61405f",
   "metadata": {},
   "source": [
    "Результаты выше - результаты нашей собственной метрики самой простейшей модели с тремя внутренними сверточными слоями. Как можно заметить, что примерно в 37% случаев правильно угадывается расположение p волны, t волна правильно определяется примерно в ~46% случаев. Но qrs сегмент правильно определяется в 82% случаев. Такие результаты говорят о том, что нам следует усложнить нашу модель, чтобы улучшить значения метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4741d-8210-4678-9dc8-3e800d748023",
   "metadata": {},
   "source": [
    "#### 1.4.2 Разработка версии №2. Усложненная full-convolutional сеть с добавлением дополнительных сверточных слоев и слоев пулинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c11f0b-eab2-4b98-8d32-d9007ae89191",
   "metadata": {},
   "source": [
    "В данном разделе интересно было бы проверить предыдущую нейронную сеть с добавлением дополнительных сверточных слоев лои пулинга для увеличения ее способности к извлечению признаков и повышения точности сегментации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "020ef2f7-a645-4be0-9455-b15224b96867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 5000]           1,184\n",
      "            Conv1d-2             [-1, 64, 5000]           6,208\n",
      "         MaxPool1d-3             [-1, 64, 5000]               0\n",
      "            Conv1d-4            [-1, 128, 5000]          24,704\n",
      "            Conv1d-5            [-1, 128, 5000]          49,280\n",
      "            Conv1d-6              [-1, 4, 5000]           1,540\n",
      "================================================================\n",
      "Total params: 82,916\n",
      "Trainable params: 82,916\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 16.02\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 16.57\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0013368 seconds\n"
     ]
    }
   ],
   "source": [
    "class SegmentationNetworkWithPooling(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(SegmentationNetworkWithPooling, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(128, num_classes, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # Добавляем пулинг со stride=1 и kernel_size=3\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetworkWithPooling(num_channels, num_classes).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6aa5ef-0de9-4783-8d1c-0d3147d319e3",
   "metadata": {},
   "source": [
    "Теперь обучим данную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f14f7c6e-895f-4aa4-a40f-b7684117a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8947975915453212\n",
      "Epoch 1/100, Validation Loss: 0.8208257652098133\n",
      "Epoch 2/100, Training Loss: 0.8082613462378622\n",
      "Epoch 2/100, Validation Loss: 0.7871443451412262\n",
      "Epoch 3/100, Training Loss: 0.7697572951857378\n",
      "Epoch 3/100, Validation Loss: 0.7395276393621198\n",
      "Epoch 4/100, Training Loss: 0.7363931902265741\n",
      "Epoch 4/100, Validation Loss: 0.6962132506793545\n",
      "Epoch 5/100, Training Loss: 0.7132801393024352\n",
      "Epoch 5/100, Validation Loss: 0.6937391772385566\n",
      "Epoch 6/100, Training Loss: 0.7004351050023608\n",
      "Epoch 6/100, Validation Loss: 0.6564625953474352\n",
      "Epoch 7/100, Training Loss: 0.6792988327109379\n",
      "Epoch 7/100, Validation Loss: 0.6640053002103683\n",
      "Epoch 8/100, Training Loss: 0.6643235047577847\n",
      "Epoch 8/100, Validation Loss: 0.6573777256473419\n",
      "Epoch 9/100, Training Loss: 0.6524669628152963\n",
      "Epoch 9/100, Validation Loss: 0.6306793473420604\n",
      "Epoch 10/100, Training Loss: 0.6396442342866288\n",
      "Epoch 10/100, Validation Loss: 0.6209924470993781\n",
      "Epoch 11/100, Training Loss: 0.6281844893930412\n",
      "Epoch 11/100, Validation Loss: 0.6002551115328266\n",
      "Epoch 12/100, Training Loss: 0.6207770331185839\n",
      "Epoch 12/100, Validation Loss: 0.613535090319572\n",
      "Epoch 13/100, Training Loss: 0.6135482897883967\n",
      "Epoch 13/100, Validation Loss: 0.6066482706416038\n",
      "Epoch 14/100, Training Loss: 0.6088173704350043\n",
      "Epoch 14/100, Validation Loss: 0.6241655960198371\n",
      "Epoch 15/100, Training Loss: 0.6048423078378685\n",
      "Epoch 15/100, Validation Loss: 0.5887883541084105\n",
      "Epoch 16/100, Training Loss: 0.5949348202842449\n",
      "Epoch 16/100, Validation Loss: 0.5760279514135853\n",
      "Epoch 17/100, Training Loss: 0.5977218274162849\n",
      "Epoch 17/100, Validation Loss: 0.5795877412442239\n",
      "Epoch 18/100, Training Loss: 0.5895824489081919\n",
      "Epoch 18/100, Validation Loss: 0.574301706206414\n",
      "Epoch 19/100, Training Loss: 0.5838909744009798\n",
      "Epoch 19/100, Validation Loss: 0.6143183390940389\n",
      "Epoch 20/100, Training Loss: 0.5815045878230801\n",
      "Epoch 20/100, Validation Loss: 0.5708033514599646\n",
      "Epoch 21/100, Training Loss: 0.5757388122651258\n",
      "Epoch 21/100, Validation Loss: 0.5742546964076257\n",
      "Epoch 22/100, Training Loss: 0.5697543925119315\n",
      "Epoch 22/100, Validation Loss: 0.5744116815828508\n",
      "Epoch 23/100, Training Loss: 0.5723568152802193\n",
      "Epoch 23/100, Validation Loss: 0.5610866580278643\n",
      "Epoch 24/100, Training Loss: 0.5663374869929634\n",
      "Epoch 24/100, Validation Loss: 0.5683122282066653\n",
      "Epoch 25/100, Training Loss: 0.5685400117022789\n",
      "Epoch 25/100, Validation Loss: 0.5668533002176592\n",
      "Epoch 26/100, Training Loss: 0.5624252009970939\n",
      "Epoch 26/100, Validation Loss: 0.5638511969197181\n",
      "Epoch 27/100, Training Loss: 0.5603778937808898\n",
      "Epoch 27/100, Validation Loss: 0.5590149880416931\n",
      "Epoch 28/100, Training Loss: 0.5582865232880782\n",
      "Epoch 28/100, Validation Loss: 0.5648324431911591\n",
      "Epoch 29/100, Training Loss: 0.5535565222564497\n",
      "Epoch 29/100, Validation Loss: 0.5709198141290296\n",
      "Epoch 30/100, Training Loss: 0.5523044777061292\n",
      "Epoch 30/100, Validation Loss: 0.5584944895198268\n",
      "Epoch 31/100, Training Loss: 0.5475538440561487\n",
      "Epoch 31/100, Validation Loss: 0.5512276661972846\n",
      "Epoch 32/100, Training Loss: 0.5450165452744796\n",
      "Epoch 32/100, Validation Loss: 0.542010651480767\n",
      "Epoch 33/100, Training Loss: 0.541161186058029\n",
      "Epoch 33/100, Validation Loss: 0.5427367067144763\n",
      "Epoch 34/100, Training Loss: 0.5381502597196864\n",
      "Epoch 34/100, Validation Loss: 0.5435107922361743\n",
      "Epoch 35/100, Training Loss: 0.536034877242347\n",
      "Epoch 35/100, Validation Loss: 0.5475174775046687\n",
      "Epoch 36/100, Training Loss: 0.5385171094162744\n",
      "Epoch 36/100, Validation Loss: 0.5489346707059491\n",
      "Epoch 37/100, Training Loss: 0.5318032354719726\n",
      "Epoch 37/100, Validation Loss: 0.5454370023742798\n",
      "Early stopping triggered\n",
      "Total training time: 34.82 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28104072-2a00-4c15-b398-c81eaddee241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.43625\n",
      "p_offset: 0.49384\n",
      "t_onset: 0.45427\n",
      "t_offset: 0.50726\n",
      "qrs_onset: 0.87772\n",
      "qrs_offset: 0.90411\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f727-c8c7-402d-ab2a-b871e5639c6f",
   "metadata": {},
   "source": [
    "Можно заметить как увеличились значения наших метрик. Теперь p волна определяется правильно примерно в ~45% случаев, t волна определяется правильно примерно в ~50% случаев, а qrs сегмент остался на уровне ~87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b951bb-1c67-4ef4-86aa-1cc38785c196",
   "metadata": {},
   "source": [
    "#### 1.4.3 Разработка версии №3. Более глубокая усложненная full-convolutional сеть с добавлением дополнительных сверточных слоев и слоев пулинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb966544-0950-4980-80cf-8bb371d8450a",
   "metadata": {},
   "source": [
    "Давайте добавим еще один блок свертки-пулинга для увеличения глубины и сложности модели. Также мы можем увеличить количество фильтров в каждом сверточном слое для более глубокого извлечения признаков. Вот обновленная версия модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a19ece1-1e60-4b6f-a10e-e6e06d93db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           2,368\n",
      "         MaxPool1d-2             [-1, 64, 5000]               0\n",
      "            Conv1d-3            [-1, 128, 5000]          24,704\n",
      "         MaxPool1d-4            [-1, 128, 5000]               0\n",
      "            Conv1d-5            [-1, 256, 5000]          98,560\n",
      "         MaxPool1d-6            [-1, 256, 5000]               0\n",
      "            Conv1d-7            [-1, 512, 5000]         393,728\n",
      "         MaxPool1d-8            [-1, 512, 5000]               0\n",
      "            Conv1d-9            [-1, 512, 5000]         786,944\n",
      "        MaxPool1d-10            [-1, 512, 5000]               0\n",
      "           Conv1d-11            [-1, 512, 5000]         786,944\n",
      "        MaxPool1d-12            [-1, 512, 5000]               0\n",
      "           Conv1d-13            [-1, 512, 5000]         786,944\n",
      "        MaxPool1d-14            [-1, 512, 5000]               0\n",
      "           Conv1d-15              [-1, 4, 5000]           6,148\n",
      "================================================================\n",
      "Total params: 2,886,340\n",
      "Trainable params: 2,886,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 190.58\n",
      "Params size (MB): 11.01\n",
      "Estimated Total Size (MB): 201.82\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0022309 seconds\n"
     ]
    }
   ],
   "source": [
    "class HardSegmentationNetworkWithPooling(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(HardSegmentationNetworkWithPooling, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv1d(512, num_classes, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv7(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.conv8(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = HardSegmentationNetworkWithPooling(num_channels, num_classes).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79d909-1a54-4934-9d4c-0404a2809673",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f0033ff-44c0-4729-b873-c1ce41f9faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.866666460568123\n",
      "Epoch 1/100, Validation Loss: 0.7339335252200404\n",
      "Epoch 2/100, Training Loss: 0.747371023603779\n",
      "Epoch 2/100, Validation Loss: 0.7218724566121255\n",
      "Epoch 3/100, Training Loss: 0.7124814581774507\n",
      "Epoch 3/100, Validation Loss: 0.6666085965210392\n",
      "Epoch 4/100, Training Loss: 0.6842156250467185\n",
      "Epoch 4/100, Validation Loss: 0.6458098830715302\n",
      "Epoch 5/100, Training Loss: 0.6526069092123132\n",
      "Epoch 5/100, Validation Loss: 0.6290888420997127\n",
      "Epoch 6/100, Training Loss: 0.6310243862360595\n",
      "Epoch 6/100, Validation Loss: 0.5838475395594874\n",
      "Epoch 7/100, Training Loss: 0.6062693293036719\n",
      "Epoch 7/100, Validation Loss: 0.5754510318079302\n",
      "Epoch 8/100, Training Loss: 0.5919646947731373\n",
      "Epoch 8/100, Validation Loss: 0.590262466380673\n",
      "Epoch 9/100, Training Loss: 0.5876099536052117\n",
      "Epoch 9/100, Validation Loss: 0.5547684863690407\n",
      "Epoch 10/100, Training Loss: 0.5685100228438976\n",
      "Epoch 10/100, Validation Loss: 0.535984992980957\n",
      "Epoch 11/100, Training Loss: 0.565696587326073\n",
      "Epoch 11/100, Validation Loss: 0.553225701855075\n",
      "Epoch 12/100, Training Loss: 0.5559354152997978\n",
      "Epoch 12/100, Validation Loss: 0.5475459137270527\n",
      "Epoch 13/100, Training Loss: 0.5451374466602619\n",
      "Epoch 13/100, Validation Loss: 0.5319104271550332\n",
      "Epoch 14/100, Training Loss: 0.54627362400414\n",
      "Epoch 14/100, Validation Loss: 0.5375840808114698\n",
      "Epoch 15/100, Training Loss: 0.5312069654464722\n",
      "Epoch 15/100, Validation Loss: 0.5274563527876331\n",
      "Epoch 16/100, Training Loss: 0.5282106079794617\n",
      "Epoch 16/100, Validation Loss: 0.5390996264834558\n",
      "Epoch 17/100, Training Loss: 0.5251656199997736\n",
      "Epoch 17/100, Validation Loss: 0.520342533626864\n",
      "Epoch 18/100, Training Loss: 0.5237077777443627\n",
      "Epoch 18/100, Validation Loss: 0.5080111834310717\n",
      "Epoch 19/100, Training Loss: 0.5106394532841709\n",
      "Epoch 19/100, Validation Loss: 0.5057173568394876\n",
      "Epoch 20/100, Training Loss: 0.5066328267095542\n",
      "Epoch 20/100, Validation Loss: 0.49597813789882966\n",
      "Epoch 21/100, Training Loss: 0.5048691023457871\n",
      "Epoch 21/100, Validation Loss: 0.4957082605650348\n",
      "Epoch 22/100, Training Loss: 0.5059880166642579\n",
      "Epoch 22/100, Validation Loss: 0.5135827994635028\n",
      "Epoch 23/100, Training Loss: 0.5041753077796596\n",
      "Epoch 23/100, Validation Loss: 0.49908981568390326\n",
      "Epoch 24/100, Training Loss: 0.49328215160833194\n",
      "Epoch 24/100, Validation Loss: 0.5209747177939261\n",
      "Epoch 25/100, Training Loss: 0.4905710810350503\n",
      "Epoch 25/100, Validation Loss: 0.4935708257459825\n",
      "Epoch 26/100, Training Loss: 0.4869199443442619\n",
      "Epoch 26/100, Validation Loss: 0.5035430572686657\n",
      "Epoch 27/100, Training Loss: 0.4910090893868975\n",
      "Epoch 27/100, Validation Loss: 0.5026922288440889\n",
      "Epoch 28/100, Training Loss: 0.4828166341492039\n",
      "Epoch 28/100, Validation Loss: 0.49675555575278496\n",
      "Epoch 29/100, Training Loss: 0.4844055136567668\n",
      "Epoch 29/100, Validation Loss: 0.5002485648278268\n",
      "Epoch 30/100, Training Loss: 0.479071022407246\n",
      "Epoch 30/100, Validation Loss: 0.48959834729471513\n",
      "Epoch 31/100, Training Loss: 0.4720535087681975\n",
      "Epoch 31/100, Validation Loss: 0.48078465173321383\n",
      "Epoch 32/100, Training Loss: 0.4775711757089445\n",
      "Epoch 32/100, Validation Loss: 0.5085474377678286\n",
      "Epoch 33/100, Training Loss: 0.47723109073001846\n",
      "Epoch 33/100, Validation Loss: 0.4918459814883048\n",
      "Epoch 34/100, Training Loss: 0.4668004644303187\n",
      "Epoch 34/100, Validation Loss: 0.4946108205664542\n",
      "Epoch 35/100, Training Loss: 0.45983711283216594\n",
      "Epoch 35/100, Validation Loss: 0.4781957174981794\n",
      "Epoch 36/100, Training Loss: 0.46237499233682144\n",
      "Epoch 36/100, Validation Loss: 0.4814502608872229\n",
      "Epoch 37/100, Training Loss: 0.4641555595977104\n",
      "Epoch 37/100, Validation Loss: 0.49016040347276196\n",
      "Epoch 38/100, Training Loss: 0.45981176113068817\n",
      "Epoch 38/100, Validation Loss: 0.4771531899609873\n",
      "Epoch 39/100, Training Loss: 0.4534122528214204\n",
      "Epoch 39/100, Validation Loss: 0.47957013355147454\n",
      "Epoch 40/100, Training Loss: 0.4539575567129652\n",
      "Epoch 40/100, Validation Loss: 0.48872893519939914\n",
      "Epoch 41/100, Training Loss: 0.4462454988647569\n",
      "Epoch 41/100, Validation Loss: 0.4897725387446342\n",
      "Epoch 42/100, Training Loss: 0.4545017648563694\n",
      "Epoch 42/100, Validation Loss: 0.49068379426194775\n",
      "Epoch 43/100, Training Loss: 0.4530251617977011\n",
      "Epoch 43/100, Validation Loss: 0.4944195475789808\n",
      "Early stopping triggered\n",
      "Total training time: 87.88 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2564215a-eec3-484d-b204-052981a3a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.42193\n",
      "p_offset: 0.46184\n",
      "t_onset: 0.53056\n",
      "t_offset: 0.54159\n",
      "qrs_onset: 0.90055\n",
      "qrs_offset: 0.90123\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f072fe-f169-42ab-a246-65006a4865f3",
   "metadata": {},
   "source": [
    "В данном случае мы видим, что метрика показывает результаты не особо лучше, чем в предыдущем случае, после усложнения модели дополнительными слоями, потому что увеличение сложности модели не всегда приводит к улучшению ее производительности. Наоборот, в некоторых случаях это может привести к переобучению или затуханию градиентов, особенно если модель становится слишком глубокой или сложной для данной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdf301-f078-405b-bc32-2afe18d12ef7",
   "metadata": {},
   "source": [
    "#### 1.4.4 Разработка версии №4. UNet-подобная сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4455f3-755a-46af-be1c-b781a74fc7fb",
   "metadata": {},
   "source": [
    "Так как элементарное углубление модели для данной задачи с имеющимся количеством данных не приносит ожидаемых результатов, мы можем привести модель к уже имеющимся архитектурам, которые зарекомендовали себя в задаче сегментаци данных, поэтому ниже произведено приведение нашей модели к Unet-подобной архитектуре, добавив соединения между сверточными слоями и их транспонированными аналогами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df6c0359-a619-4a33-9ac3-4afa2ab0ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           2,368\n",
      "              ReLU-2             [-1, 64, 5000]               0\n",
      "            Conv1d-3             [-1, 64, 5000]          12,352\n",
      "              ReLU-4             [-1, 64, 5000]               0\n",
      "         MaxPool1d-5             [-1, 64, 2500]               0\n",
      "            Conv1d-6             [-1, 64, 2500]          12,352\n",
      "              ReLU-7             [-1, 64, 2500]               0\n",
      "            Conv1d-8              [-1, 4, 2500]             772\n",
      "              ReLU-9              [-1, 4, 2500]               0\n",
      "         Upsample-10              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 27,844\n",
      "Trainable params: 27,844\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 13.73\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 14.07\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0175977 seconds\n"
     ]
    }
   ],
   "source": [
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # Энкодер\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='linear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Прямой проход через энкодер\n",
    "        x1 = self.encoder(x)\n",
    "        \n",
    "        # Прямой проход через декодер\n",
    "        output = self.decoder(x1)\n",
    "        return output\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SimpleUNet(num_channels, num_classes).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d355ce-894a-4372-a666-666591b50fd3",
   "metadata": {},
   "source": [
    "В данном случае, чтобы исследовать поведение UNet-подобной архитектуры мы начнем с простой версии Unet с одним энкодером и одним декодером. Она включает в себя сверточные слои для энкодера и декодера, а также операцию апсэмплинга для увеличения размера выходного изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43520b66-b0f8-4495-939e-ff2b858add1e",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c025cb24-5c7b-421b-b54a-916e74302aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9857561501414187\n",
      "Epoch 1/100, Validation Loss: 0.902706305826864\n",
      "Epoch 2/100, Training Loss: 0.9235286575097305\n",
      "Epoch 2/100, Validation Loss: 0.8796734165760779\n",
      "Epoch 3/100, Training Loss: 0.9019768889616375\n",
      "Epoch 3/100, Validation Loss: 0.8697957569553006\n",
      "Epoch 4/100, Training Loss: 0.8772514650696203\n",
      "Epoch 4/100, Validation Loss: 0.8411032394055398\n",
      "Epoch 5/100, Training Loss: 0.8542039548819848\n",
      "Epoch 5/100, Validation Loss: 0.8142638369914024\n",
      "Epoch 6/100, Training Loss: 0.83701624344235\n",
      "Epoch 6/100, Validation Loss: 0.8050783007375656\n",
      "Epoch 7/100, Training Loss: 0.8249689099277079\n",
      "Epoch 7/100, Validation Loss: 0.7968008609548691\n",
      "Epoch 8/100, Training Loss: 0.8150525937678843\n",
      "Epoch 8/100, Validation Loss: 0.7829075383563195\n",
      "Epoch 9/100, Training Loss: 0.8111010567862013\n",
      "Epoch 9/100, Validation Loss: 0.7797903668495917\n",
      "Epoch 10/100, Training Loss: 0.8059676374018434\n",
      "Epoch 10/100, Validation Loss: 0.7730174593387111\n",
      "Epoch 11/100, Training Loss: 0.8093798020590655\n",
      "Epoch 11/100, Validation Loss: 0.7754446546877584\n",
      "Epoch 12/100, Training Loss: 0.8017976059604753\n",
      "Epoch 12/100, Validation Loss: 0.7674641618805547\n",
      "Epoch 13/100, Training Loss: 0.798367060147799\n",
      "Epoch 13/100, Validation Loss: 0.8015950581719798\n",
      "Epoch 14/100, Training Loss: 0.7974304397579147\n",
      "Epoch 14/100, Validation Loss: 0.7778090334707691\n",
      "Epoch 15/100, Training Loss: 0.7974652158103974\n",
      "Epoch 15/100, Validation Loss: 0.7686784853858333\n",
      "Epoch 16/100, Training Loss: 0.7962284092961053\n",
      "Epoch 16/100, Validation Loss: 0.7619691072933136\n",
      "Epoch 17/100, Training Loss: 0.7925880259347831\n",
      "Epoch 17/100, Validation Loss: 0.7680716913553977\n",
      "Epoch 18/100, Training Loss: 0.793690211256506\n",
      "Epoch 18/100, Validation Loss: 0.7719969014006276\n",
      "Epoch 19/100, Training Loss: 0.7906726574608189\n",
      "Epoch 19/100, Validation Loss: 0.7620861833134005\n",
      "Epoch 20/100, Training Loss: 0.787334135186817\n",
      "Epoch 20/100, Validation Loss: 0.770294756177933\n",
      "Epoch 21/100, Training Loss: 0.7868555834901477\n",
      "Epoch 21/100, Validation Loss: 0.7606831236231711\n",
      "Epoch 22/100, Training Loss: 0.7885799854390534\n",
      "Epoch 22/100, Validation Loss: 0.7598330421793845\n",
      "Epoch 23/100, Training Loss: 0.7855628711974573\n",
      "Epoch 23/100, Validation Loss: 0.7626359486772168\n",
      "Epoch 24/100, Training Loss: 0.783729285846355\n",
      "Epoch 24/100, Validation Loss: 0.7597937233025028\n",
      "Epoch 25/100, Training Loss: 0.7813430271650615\n",
      "Epoch 25/100, Validation Loss: 0.7650377812885469\n",
      "Epoch 26/100, Training Loss: 0.7799892187842473\n",
      "Epoch 26/100, Validation Loss: 0.7546700407420436\n",
      "Epoch 27/100, Training Loss: 0.7764553516982537\n",
      "Epoch 27/100, Validation Loss: 0.757613637754994\n",
      "Epoch 28/100, Training Loss: 0.7774235901803623\n",
      "Epoch 28/100, Validation Loss: 0.7577178281161093\n",
      "Epoch 29/100, Training Loss: 0.7775384181665506\n",
      "Epoch 29/100, Validation Loss: 0.7581017320194552\n",
      "Epoch 30/100, Training Loss: 0.7770078440426815\n",
      "Epoch 30/100, Validation Loss: 0.7791951029531418\n",
      "Epoch 31/100, Training Loss: 0.7751746491381997\n",
      "Epoch 31/100, Validation Loss: 0.7509734385436581\n",
      "Epoch 32/100, Training Loss: 0.7749049442741069\n",
      "Epoch 32/100, Validation Loss: 0.7589651240456489\n",
      "Epoch 33/100, Training Loss: 0.775531405379415\n",
      "Epoch 33/100, Validation Loss: 0.765870526432991\n",
      "Epoch 34/100, Training Loss: 0.7717534185421129\n",
      "Epoch 34/100, Validation Loss: 0.7534817985949978\n",
      "Epoch 35/100, Training Loss: 0.7707195670498528\n",
      "Epoch 35/100, Validation Loss: 0.7638073092506777\n",
      "Epoch 36/100, Training Loss: 0.7690007933962201\n",
      "Epoch 36/100, Validation Loss: 0.749162238932425\n",
      "Epoch 37/100, Training Loss: 0.7707609387061857\n",
      "Epoch 37/100, Validation Loss: 0.7483171844674695\n",
      "Epoch 38/100, Training Loss: 0.7705150538610543\n",
      "Epoch 38/100, Validation Loss: 0.7590567652256258\n",
      "Epoch 39/100, Training Loss: 0.7663578926792994\n",
      "Epoch 39/100, Validation Loss: 0.758016275782739\n",
      "Epoch 40/100, Training Loss: 0.7670348708928838\n",
      "Epoch 40/100, Validation Loss: 0.7683235373227827\n",
      "Epoch 41/100, Training Loss: 0.767767235214411\n",
      "Epoch 41/100, Validation Loss: 0.7501453632308591\n",
      "Epoch 42/100, Training Loss: 0.764662678666443\n",
      "Epoch 42/100, Validation Loss: 0.7469104028517201\n",
      "Epoch 43/100, Training Loss: 0.7637344967981099\n",
      "Epoch 43/100, Validation Loss: 0.7469672007906821\n",
      "Epoch 44/100, Training Loss: 0.7626768774107883\n",
      "Epoch 44/100, Validation Loss: 0.746849748876787\n",
      "Epoch 45/100, Training Loss: 0.7613132106147797\n",
      "Epoch 45/100, Validation Loss: 0.748427556407067\n",
      "Epoch 46/100, Training Loss: 0.7631395401259665\n",
      "Epoch 46/100, Validation Loss: 0.7474092360465757\n",
      "Epoch 47/100, Training Loss: 0.7609551428300649\n",
      "Epoch 47/100, Validation Loss: 0.7516248774143958\n",
      "Epoch 48/100, Training Loss: 0.7587212503921648\n",
      "Epoch 48/100, Validation Loss: 0.7413247001747931\n",
      "Epoch 49/100, Training Loss: 0.758364220500475\n",
      "Epoch 49/100, Validation Loss: 0.7877667334771925\n",
      "Epoch 50/100, Training Loss: 0.7620650993185005\n",
      "Epoch 50/100, Validation Loss: 0.745319186199096\n",
      "Epoch 51/100, Training Loss: 0.7574811857721584\n",
      "Epoch 51/100, Validation Loss: 0.7428913866319964\n",
      "Epoch 52/100, Training Loss: 0.7543996239480703\n",
      "Epoch 52/100, Validation Loss: 0.7439913941967872\n",
      "Epoch 53/100, Training Loss: 0.7556403565262011\n",
      "Epoch 53/100, Validation Loss: 0.746747717741997\n",
      "Early stopping triggered\n",
      "Total training time: 47.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02decf-2c57-4bd8-a60a-38dffec2dde3",
   "metadata": {},
   "source": [
    "Результаты метрик на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a730b0c-0604-43ec-8f78-58e6bdef5d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.03519\n",
      "p_offset: 0.03519\n",
      "t_onset: 0.00544\n",
      "t_offset: 0.00783\n",
      "qrs_onset: 0.83835\n",
      "qrs_offset: 0.85625\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bde65-2c34-49f4-aba8-62539f54fdb7",
   "metadata": {},
   "source": [
    "Можно заметить, что метрики хуже, чем версия с усложненной версии full-convolutional сетью. Проблема в том, что сеть, которая реализована выше, состоит из двух сверточных слоев в энкодере и двух в декодере, что может быть недостаточно для эффективной сегментации сложных данных, таких как сигналы ЭКГ. Важно учитывать, что для успешной сегментации требуются глубокие и сложные архитектуры сетей, способные улавливать различные уровни признаков в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dddacd-1756-4516-9b7f-e8c54d524778",
   "metadata": {},
   "source": [
    "#### 1.4.5 Разработка версии №5. Усложненная UNet-подобная сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06f53f76-f97d-477e-b217-c4db77c0f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab1d4b40-738c-47f0-926c-6c1d56afff3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           2,368\n",
      "              ReLU-2             [-1, 64, 5000]               0\n",
      "       BatchNorm1d-3             [-1, 64, 5000]             128\n",
      "         MaxPool1d-4             [-1, 64, 2500]               0\n",
      "            Conv1d-5            [-1, 128, 2500]          24,704\n",
      "              ReLU-6            [-1, 128, 2500]               0\n",
      "       BatchNorm1d-7            [-1, 128, 2500]             256\n",
      "         MaxPool1d-8            [-1, 128, 1250]               0\n",
      "   ConvTranspose1d-9             [-1, 64, 5000]          65,600\n",
      "           Conv1d-10             [-1, 64, 5000]          24,640\n",
      "             ReLU-11             [-1, 64, 5000]               0\n",
      "      BatchNorm1d-12             [-1, 64, 5000]             128\n",
      "           Conv1d-13              [-1, 4, 5000]             772\n",
      "      UNetDecoder-14              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 118,596\n",
      "Trainable params: 118,596\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 27.16\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 27.84\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0222785 seconds\n"
     ]
    }
   ],
   "source": [
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetDecoder, self).__init__()\n",
    "        # Увеличиваем размер с 2500 до 5000 и количество каналов с 128 до 64\n",
    "        self.upconv1 = nn.ConvTranspose1d(128, 64, kernel_size=8, stride=4, padding=2)\n",
    "        # Сверточные слои после конкатенации\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        # Выходной слой, предполагая что нужно num_classes каналов на выходе\n",
    "        self.final_conv = nn.Conv1d(64, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        # Применяем апсемплинг\n",
    "        x = self.upconv1(x)  # x теперь [2, 64, 5000]\n",
    "        # Конкатенация с соответствующим слоем из skips\n",
    "        x = torch.cat((x, skips[0]), dim=1)  # x теперь [2, 128, 5000]\n",
    "        # Применяем сверточные слои\n",
    "        x = self.conv1(x)\n",
    "        # Применяем выходной слой\n",
    "        x = self.final_conv(x)  # x теперь [2, num_classes, 5000]\n",
    "        return x\n",
    "\n",
    "class ImprovedUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ImprovedUNet, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv1d(in_channels, 64, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm1d(64)),\n",
    "            nn.MaxPool1d(2),  # Уменьшает размерность в 2 раза\n",
    "            nn.Sequential(nn.Conv1d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm1d(128)),\n",
    "            nn.MaxPool1d(2)   # Уменьшает размерность в 2 раза\n",
    "        ])\n",
    "\n",
    "        self.decoder = UNetDecoder()\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.Sequential):\n",
    "                skips.append(x)\n",
    "        x = self.decoder(x, skips) \n",
    "        return x\n",
    "\n",
    "# Создадим модель\n",
    "model = ImprovedUNet(in_channels=12, out_channels=4).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea8450-291b-4a81-8eed-53b85e66815d",
   "metadata": {},
   "source": [
    "Давайте разберемся в этом коде:\n",
    "1. Энкодер: Он состоит из последовательности сверточных слоев и слоев максимального пулинга, которые уменьшают размерность входных данных вдоль оси длины сигнала.\n",
    "2. Декодер: Он состоит из слоев транспонированной свертки и слоев двойной свертки. Важно отметить, что каждый выход из слоя энкодера используется для соединения с соответствующим слоем декодера в процессе декодирования.\n",
    "3. Проход через декодер: В цикле for происходит перебор слоев декодера. В каждой итерации, если индекс i четный, то происходит объединение выхода из текущего слоя декодера с соответствующим выходом из энкодера. Затем, через текущий слой декодера пропускается объединенный тензор.\n",
    "4. cropped_encoder_output: Для каждого четного слоя декодера выбирается соответствующий выход из энкодера, который затем обрезается до размера выхода из декодера перед объединением.  \n",
    "5. Возвращаемый результат: Возвращается выход из последнего слоя декодера, который представляет собой предсказание модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4b84ed6-a839-4c14-8f5f-5910d11070bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8606298008428411\n",
      "Epoch 1/100, Validation Loss: 0.7243341736255153\n",
      "Epoch 2/100, Training Loss: 0.6999311555735013\n",
      "Epoch 2/100, Validation Loss: 0.6608641623489319\n",
      "Epoch 3/100, Training Loss: 0.6482505933475881\n",
      "Epoch 3/100, Validation Loss: 0.6213732256043342\n",
      "Epoch 4/100, Training Loss: 0.618589278174798\n",
      "Epoch 4/100, Validation Loss: 0.6167639215146342\n",
      "Epoch 5/100, Training Loss: 0.5985835112540828\n",
      "Epoch 5/100, Validation Loss: 0.6033990551387111\n",
      "Epoch 6/100, Training Loss: 0.5804389475086923\n",
      "Epoch 6/100, Validation Loss: 0.5639042205387547\n",
      "Epoch 7/100, Training Loss: 0.5625192824645564\n",
      "Epoch 7/100, Validation Loss: 0.5603744950025312\n",
      "Epoch 8/100, Training Loss: 0.5486247936482371\n",
      "Epoch 8/100, Validation Loss: 0.545039334604817\n",
      "Epoch 9/100, Training Loss: 0.5414414818470294\n",
      "Epoch 9/100, Validation Loss: 0.5583398154666347\n",
      "Epoch 10/100, Training Loss: 0.5287492275238037\n",
      "Epoch 10/100, Validation Loss: 0.5412135590468684\n",
      "Epoch 11/100, Training Loss: 0.525425348325297\n",
      "Epoch 11/100, Validation Loss: 0.5425673872232437\n",
      "Epoch 12/100, Training Loss: 0.5169108823726052\n",
      "Epoch 12/100, Validation Loss: 0.5445771491335284\n",
      "Epoch 13/100, Training Loss: 0.5110088096939118\n",
      "Epoch 13/100, Validation Loss: 0.5157290591347602\n",
      "Epoch 14/100, Training Loss: 0.5025087511732511\n",
      "Epoch 14/100, Validation Loss: 0.5245237446600391\n",
      "Epoch 15/100, Training Loss: 0.5002306135077226\n",
      "Epoch 15/100, Validation Loss: 0.5262235763572878\n",
      "Epoch 16/100, Training Loss: 0.4947310918979799\n",
      "Epoch 16/100, Validation Loss: 0.522304531547331\n",
      "Epoch 17/100, Training Loss: 0.4879676510206601\n",
      "Epoch 17/100, Validation Loss: 0.5031226484044906\n",
      "Epoch 18/100, Training Loss: 0.4814261251132981\n",
      "Epoch 18/100, Validation Loss: 0.5233989987642534\n",
      "Epoch 19/100, Training Loss: 0.4855728344878687\n",
      "Epoch 19/100, Validation Loss: 0.5069139570959152\n",
      "Epoch 20/100, Training Loss: 0.4772078837701666\n",
      "Epoch 20/100, Validation Loss: 0.5184706627361236\n",
      "Epoch 21/100, Training Loss: 0.4782643699452945\n",
      "Epoch 21/100, Validation Loss: 0.5045407135640422\n",
      "Epoch 22/100, Training Loss: 0.4729780788846344\n",
      "Epoch 22/100, Validation Loss: 0.5140428446954296\n",
      "Early stopping triggered\n",
      "Total training time: 27.02 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d790bc1-6eb1-42cf-b4e4-a27ae8eda420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.52808\n",
      "p_offset: 0.5513\n",
      "t_onset: 0.46816\n",
      "t_offset: 0.52646\n",
      "qrs_onset: 0.86413\n",
      "qrs_offset: 0.87802\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70534d2d-e6ee-43bb-bd0c-96fe653adad5",
   "metadata": {},
   "source": [
    "Можно заметить, что результаты метрики увеличились непосредственно с усложнением UNet-а. Но UNet давно изученная модель в использовании относительно задачи сегментации ЭКГ. Давайте рассмотрим для нашей задачи другие сегментационные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d4c3f-cd95-44b3-b335-201f368058ae",
   "metadata": {},
   "source": [
    "Для задач сегментации изображений существует множество архитектур нейронных сетей, каждая из которых имеет свои особенности и применяется в зависимости от специфики задачи. Вот несколько популярных архитектур:\n",
    "\n",
    "1. **UNet**: Одна из самых популярных архитектур для медицинской сегментации. Она использует скип-соединения для передачи информации между слоями энкодера и декодера, что помогает сохранить пространственную информацию при восстановлении изображения.  \n",
    "2. **SegNet**: Архитектура, похожая на UNet, с акцентом на использование индексов максимального пулинга из энкодера для нелинейной деиндексации в декодере. Это позволяет более эффективно использовать пространственные признаки при меньшем количестве параметров.  \n",
    "3. **DeepLab (v3 и v3+)**: Использует атроус свертки (dilated convolutions) для увеличения поля зрения сверточных слоев, а также включает ASPP (Atrous Spatial Pyramid Pooling), что позволяет захватывать контекст на нескольких масштабах. DeepLabv3+ добавляет к этому еще и улучшенный декодер для уточнения границ объектов.  \n",
    "4. **Mask R-CNN**: Расширение Faster R-CNN, добавляющее ветвь для предсказания масок на каждый ROI, позволяя проводить сегментацию на уровне экземпляра. Это хорошо подходит для задач, где необходимо различать отдельные объекты одного класса.  \n",
    "5. **PSPNet (Pyramid Scene Parsing Network)**: Использует пирамиду глобального пулинга для улавливания информации на различных масштабах. Это особенно полезно для сцен анализа, где контекст важен для точной сегментации.  \n",
    "6. **RefineNet**: Сеть для мультипатового рафинирования, которая использует информацию из всех уровней глубины для улучшения качества сегментации. Эта архитектура направлена на использование информации с высоким разрешением на всех этапах обработки.  \n",
    "7. **LinkNet**: Основана на идее эффективного использования энкодера, предназначенного для классификации (например, ResNet) с добавлением декодера, который восстанавливает размерность изображения, используя скип-соединения для улучшения точности.  \n",
    "8. **HRNet (High-Resolution Network)**: Уникально сочетает высокое разрешение с возможностями углубленного анализа через сеть, сохраняя высокое разрешение через все слои сети.  \n",
    "Эти архитектуры подходят для различных видов сегментационных задач и выбор конкретной архитектуры зависит от специфических требований приложения, доступности вычислительных ресурсов и требуемой точности.  \n",
    "**UNet мы опробовали, есть смысл протестировать несколько архитектур из этого списка в качестве экспериментов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2b2e1-66f1-45a8-b010-7c5ad1d6b232",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка SegNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69dd9c-16f7-4189-b25b-5119baf7055a",
   "metadata": {},
   "source": [
    "Для построения архитектуры SegNet, адаптированной под нашу задачу сегментации сигналов, мы можем воспользоваться модификацией стандартного подхода SegNet для работы с 1D данными, поскольку большинство стандартных реализаций SegNet предназначены для работы с изображениями (2D данных).\n",
    "\n",
    "В этом случае, основная идея заключается в использовании 1D сверточных слоев вместо 2D, и адаптации слоев пулинга и апсемплинга для работы с одномерными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "450baf56-89bf-4d32-a4ce-9e667cb50ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 5000]             128\n",
      "              ReLU-3             [-1, 64, 5000]               0\n",
      "         MaxPool1d-4  [[-1, 64, 2500], [-1, 64, 2500]]               0\n",
      "            Conv1d-5            [-1, 128, 2500]          57,472\n",
      "       BatchNorm1d-6            [-1, 128, 2500]             256\n",
      "              ReLU-7            [-1, 128, 2500]               0\n",
      "         MaxPool1d-8  [[-1, 128, 1250], [-1, 128, 1250]]               0\n",
      "       MaxUnpool1d-9            [-1, 128, 2500]               0\n",
      "           Conv1d-10             [-1, 64, 2500]          57,408\n",
      "      BatchNorm1d-11             [-1, 64, 2500]             128\n",
      "             ReLU-12             [-1, 64, 2500]               0\n",
      "      MaxUnpool1d-13             [-1, 64, 5000]               0\n",
      "           Conv1d-14              [-1, 4, 5000]           1,796\n",
      "      BatchNorm1d-15              [-1, 4, 5000]               8\n",
      "             ReLU-16              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 122,636\n",
      "Trainable params: 122,636\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 390601.35\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 390602.05\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0171697 seconds\n"
     ]
    }
   ],
   "source": [
    "class SegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(SegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices2)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices1)\n",
    "        x = self.decoder_conv2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = SegNet1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc496d08-5c49-47a0-b6cc-dd1baa05432d",
   "metadata": {},
   "source": [
    "##### Ключевые особенности:\n",
    "**1D сверточные слои**: Позволяют обрабатывать временные ряды или одномерные сигналы.  \n",
    "**MaxPool1d с return_indices**: Это позволяет в процессе пулинга сохранять индексы максимальных значений, которые затем используются в слое MaxUnpool1d для восстановления данных до исходного размера.  \n",
    "**MaxUnpool1d**: Используется для апсемплинга данных в декодере, возвращая значения в исходные позиции на основе сохраненных индексов.  \n",
    "Этот подход позволяет модели эффективно учиться на данных, представляющих собой одномерные сигналы, и проводить сегментацию, восстанавливая исходные размеры выходных данных для каждого класса.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0d461-511d-485f-b779-1e136ac187a6",
   "metadata": {},
   "source": [
    "Теперь натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c7a30b3-dbc4-4776-a275-d40372c9ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9723882354222811\n",
      "Epoch 1/100, Validation Loss: 0.8768770810096495\n",
      "Epoch 2/100, Training Loss: 0.8330523287236449\n",
      "Epoch 2/100, Validation Loss: 0.7937342476460242\n",
      "Epoch 3/100, Training Loss: 0.7436462587673172\n",
      "Epoch 3/100, Validation Loss: 0.7061725345350081\n",
      "Epoch 4/100, Training Loss: 0.684073604552852\n",
      "Epoch 4/100, Validation Loss: 0.6190995223099186\n",
      "Epoch 5/100, Training Loss: 0.6403333752261482\n",
      "Epoch 5/100, Validation Loss: 0.5922435483624858\n",
      "Epoch 6/100, Training Loss: 0.6078238087868401\n",
      "Epoch 6/100, Validation Loss: 0.5602325489444118\n",
      "Epoch 7/100, Training Loss: 0.5787337492352073\n",
      "Epoch 7/100, Validation Loss: 0.549669704129619\n",
      "Epoch 8/100, Training Loss: 0.5531724633475547\n",
      "Epoch 8/100, Validation Loss: 0.5485258477349435\n",
      "Epoch 9/100, Training Loss: 0.5396705419428436\n",
      "Epoch 9/100, Validation Loss: 0.5183079112921992\n",
      "Epoch 10/100, Training Loss: 0.5249681446233742\n",
      "Epoch 10/100, Validation Loss: 0.5166695718803713\n",
      "Epoch 11/100, Training Loss: 0.5121888129817329\n",
      "Epoch 11/100, Validation Loss: 0.4960267274610458\n",
      "Epoch 12/100, Training Loss: 0.5021435942968376\n",
      "Epoch 12/100, Validation Loss: 0.4823504676741938\n",
      "Epoch 13/100, Training Loss: 0.49584742499749185\n",
      "Epoch 13/100, Validation Loss: 0.49461097919171854\n",
      "Epoch 14/100, Training Loss: 0.48735206583250873\n",
      "Epoch 14/100, Validation Loss: 0.4828353202150714\n",
      "Epoch 15/100, Training Loss: 0.4793522474978134\n",
      "Epoch 15/100, Validation Loss: 0.4632761579367422\n",
      "Epoch 16/100, Training Loss: 0.47430343364897043\n",
      "Epoch 16/100, Validation Loss: 0.46354804332217864\n",
      "Epoch 17/100, Training Loss: 0.46364246037324913\n",
      "Epoch 17/100, Validation Loss: 0.4672727027247029\n",
      "Epoch 18/100, Training Loss: 0.45947288791177726\n",
      "Epoch 18/100, Validation Loss: 0.4587389761882444\n",
      "Epoch 19/100, Training Loss: 0.4524229267830791\n",
      "Epoch 19/100, Validation Loss: 0.4494342957773516\n",
      "Epoch 20/100, Training Loss: 0.4519317634554527\n",
      "Epoch 20/100, Validation Loss: 0.46533418254506204\n",
      "Epoch 21/100, Training Loss: 0.4425761210411666\n",
      "Epoch 21/100, Validation Loss: 0.4447278031899083\n",
      "Epoch 22/100, Training Loss: 0.4433684658545714\n",
      "Epoch 22/100, Validation Loss: 0.4572036004354877\n",
      "Epoch 23/100, Training Loss: 0.4361993254799592\n",
      "Epoch 23/100, Validation Loss: 0.4436773323724347\n",
      "Epoch 24/100, Training Loss: 0.4301183179684496\n",
      "Epoch 24/100, Validation Loss: 0.4477122452470564\n",
      "Epoch 25/100, Training Loss: 0.4302538542853676\n",
      "Epoch 25/100, Validation Loss: 0.43719675512083117\n",
      "Epoch 26/100, Training Loss: 0.42767131968065797\n",
      "Epoch 26/100, Validation Loss: 0.44555325493697195\n",
      "Epoch 27/100, Training Loss: 0.4255540854776437\n",
      "Epoch 27/100, Validation Loss: 0.4230877007207563\n",
      "Epoch 28/100, Training Loss: 0.4197283101829923\n",
      "Epoch 28/100, Validation Loss: 0.4476043110893619\n",
      "Epoch 29/100, Training Loss: 0.41452322025530736\n",
      "Epoch 29/100, Validation Loss: 0.43559501175918885\n",
      "Epoch 30/100, Training Loss: 0.41278533528932193\n",
      "Epoch 30/100, Validation Loss: 0.4500950433073505\n",
      "Epoch 31/100, Training Loss: 0.41027419836173656\n",
      "Epoch 31/100, Validation Loss: 0.4415244561049246\n",
      "Epoch 32/100, Training Loss: 0.40845104732252807\n",
      "Epoch 32/100, Validation Loss: 0.44045024942005834\n",
      "Early stopping triggered\n",
      "Total training time: 35.81 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6813b5-ff59-4fcf-8d73-b6dd2f73c325",
   "metadata": {},
   "source": [
    "Результаты метрик на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ceee918-af98-4b68-a8cb-5f2ad8fc24bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.59639\n",
      "p_offset: 0.59639\n",
      "t_onset: 0.60449\n",
      "t_offset: 0.58324\n",
      "qrs_onset: 0.89724\n",
      "qrs_offset: 0.91828\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321f057-f081-4ed7-8457-0bacd1971c63",
   "metadata": {},
   "source": [
    "Модель показала неплохие результаты для такой небольшой глубины, можем попробовать усложнить эту сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992dbd22-e9e5-418d-8814-1d4631e71690",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка улучшенного SegNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e273e-f856-494a-b488-c391e3feba36",
   "metadata": {},
   "source": [
    "Для улучшения производительности и точности сегментации в модели SegNet для одномерных данных, мы можем внести несколько изменений, направленных на улучшение изучения признаков и увеличение глубины сети. Это включает добавление дополнительных слоев, увеличение количества каналов в сверточных слоях, а также внедрение дополнительных элементов, таких как Dropout для предотвращения переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "717fec3c-75e4-4e8a-ba4f-b8d8c2bb770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 5000]             128\n",
      "              ReLU-3             [-1, 64, 5000]               0\n",
      "            Conv1d-4             [-1, 64, 5000]          28,736\n",
      "       BatchNorm1d-5             [-1, 64, 5000]             128\n",
      "              ReLU-6             [-1, 64, 5000]               0\n",
      "         MaxPool1d-7  [[-1, 64, 2500], [-1, 64, 2500]]               0\n",
      "            Conv1d-8            [-1, 128, 2500]          57,472\n",
      "       BatchNorm1d-9            [-1, 128, 2500]             256\n",
      "             ReLU-10            [-1, 128, 2500]               0\n",
      "           Conv1d-11            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-12            [-1, 128, 2500]             256\n",
      "             ReLU-13            [-1, 128, 2500]               0\n",
      "        MaxPool1d-14  [[-1, 128, 1250], [-1, 128, 1250]]               0\n",
      "           Conv1d-15            [-1, 256, 1250]         229,632\n",
      "      BatchNorm1d-16            [-1, 256, 1250]             512\n",
      "             ReLU-17            [-1, 256, 1250]               0\n",
      "           Conv1d-18            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-19            [-1, 256, 1250]             512\n",
      "             ReLU-20            [-1, 256, 1250]               0\n",
      "        MaxPool1d-21  [[-1, 256, 625], [-1, 256, 625]]               0\n",
      "      MaxUnpool1d-22            [-1, 256, 1250]               0\n",
      "           Conv1d-23            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-24            [-1, 256, 1250]             512\n",
      "             ReLU-25            [-1, 256, 1250]               0\n",
      "           Conv1d-26            [-1, 128, 1250]         229,504\n",
      "      BatchNorm1d-27            [-1, 128, 1250]             256\n",
      "             ReLU-28            [-1, 128, 1250]               0\n",
      "      MaxUnpool1d-29            [-1, 128, 2500]               0\n",
      "           Conv1d-30            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-31            [-1, 128, 2500]             256\n",
      "             ReLU-32            [-1, 128, 2500]               0\n",
      "           Conv1d-33             [-1, 64, 2500]          57,408\n",
      "      BatchNorm1d-34             [-1, 64, 2500]             128\n",
      "             ReLU-35             [-1, 64, 2500]               0\n",
      "      MaxUnpool1d-36             [-1, 64, 5000]               0\n",
      "           Conv1d-37             [-1, 64, 5000]          28,736\n",
      "      BatchNorm1d-38             [-1, 64, 5000]             128\n",
      "             ReLU-39             [-1, 64, 5000]               0\n",
      "           Conv1d-40              [-1, 4, 5000]           1,796\n",
      "      BatchNorm1d-41              [-1, 4, 5000]               8\n",
      "             ReLU-42              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 1,789,452\n",
      "Trainable params: 1,789,452\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 585856.48\n",
      "Params size (MB): 6.83\n",
      "Estimated Total Size (MB): 585863.53\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0228584 seconds\n"
     ]
    }
   ],
   "source": [
    "class AdvancedSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(AdvancedSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices3)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices2)\n",
    "        x = self.decoder_conv2(x)\n",
    "\n",
    "        x = self.decoder_unpool3(x, indices1)\n",
    "        x = self.decoder_conv3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = AdvancedSegNet1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe906f7-dd58-460a-9cc6-8a8324a095d4",
   "metadata": {},
   "source": [
    "##### Ключевые особенности и улучшения:\n",
    "**Больше сверточных слоев**: Каждый блок свертки теперь содержит два сверточных слоя, что позволяет извлекать более сложные признаки на каждом уровне.  \n",
    "**Увеличенное количество фильтров**: Увеличение количества каналов в сверточных слоях помогает сети обучаться на более сложной иерархии признаков.  \n",
    "**Больше уровней глубины**: Добавление дополнительного уровня глубины в энкодер и декодер улучшает способность сети восстанавливать детализированные сегментации.  \n",
    "Эти изменения направлены на улучшение способности модели извлекать сложные признаки из данных и более точно восстанавливать детали в процессе сегментации, что потенциально приведет к улучшению точности сегментации.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e861abda-ee0f-4e51-b8b3-b6aeaf5a147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9063484774910004\n",
      "Epoch 1/100, Validation Loss: 0.761651857245353\n",
      "Epoch 2/100, Training Loss: 0.7335673949496466\n",
      "Epoch 2/100, Validation Loss: 0.6580292414272985\n",
      "Epoch 3/100, Training Loss: 0.6513267014673364\n",
      "Epoch 3/100, Validation Loss: 0.589721568649815\n",
      "Epoch 4/100, Training Loss: 0.5952184802366172\n",
      "Epoch 4/100, Validation Loss: 0.5499089562123821\n",
      "Epoch 5/100, Training Loss: 0.550406792989144\n",
      "Epoch 5/100, Validation Loss: 0.5046583414077759\n",
      "Epoch 6/100, Training Loss: 0.5207834500774198\n",
      "Epoch 6/100, Validation Loss: 0.4785232942911886\n",
      "Epoch 7/100, Training Loss: 0.4913287305156229\n",
      "Epoch 7/100, Validation Loss: 0.47915894802539577\n",
      "Epoch 8/100, Training Loss: 0.4741291154010093\n",
      "Epoch 8/100, Validation Loss: 0.439211503632607\n",
      "Epoch 9/100, Training Loss: 0.45361778924339696\n",
      "Epoch 9/100, Validation Loss: 0.4328716212222653\n",
      "Epoch 10/100, Training Loss: 0.4346788041746085\n",
      "Epoch 10/100, Validation Loss: 0.4272030068020667\n",
      "Epoch 11/100, Training Loss: 0.4312871300015855\n",
      "Epoch 11/100, Validation Loss: 0.4143025062737926\n",
      "Epoch 12/100, Training Loss: 0.41952045117071285\n",
      "Epoch 12/100, Validation Loss: 0.40339043784526085\n",
      "Epoch 13/100, Training Loss: 0.40378988875068633\n",
      "Epoch 13/100, Validation Loss: 0.392274176641818\n",
      "Epoch 14/100, Training Loss: 0.398379158454868\n",
      "Epoch 14/100, Validation Loss: 0.4059802702357692\n",
      "Epoch 15/100, Training Loss: 0.3901961415040831\n",
      "Epoch 15/100, Validation Loss: 0.3952975724973986\n",
      "Epoch 16/100, Training Loss: 0.38535664577474477\n",
      "Epoch 16/100, Validation Loss: 0.41102432748002393\n",
      "Epoch 17/100, Training Loss: 0.3772851931542037\n",
      "Epoch 17/100, Validation Loss: 0.39551517511567763\n",
      "Epoch 18/100, Training Loss: 0.3717706208890266\n",
      "Epoch 18/100, Validation Loss: 0.368062216908701\n",
      "Epoch 19/100, Training Loss: 0.36542087033210013\n",
      "Epoch 19/100, Validation Loss: 0.3931676372885704\n",
      "Epoch 20/100, Training Loss: 0.3553597886070066\n",
      "Epoch 20/100, Validation Loss: 0.3858144271277612\n",
      "Epoch 21/100, Training Loss: 0.35445724548357216\n",
      "Epoch 21/100, Validation Loss: 0.37762658802732346\n",
      "Epoch 22/100, Training Loss: 0.3472506148733108\n",
      "Epoch 22/100, Validation Loss: 0.3757251498679961\n",
      "Epoch 23/100, Training Loss: 0.35091177123760886\n",
      "Epoch 23/100, Validation Loss: 0.42283116064725385\n",
      "Early stopping triggered\n",
      "Total training time: 46.84 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab6922-9442-49c9-8845-76d89bd7aa1f",
   "metadata": {},
   "source": [
    "Результаты метрик на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cb7de8ba-a505-4eee-95a5-e1c55e606406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.72365\n",
      "p_offset: 0.71373\n",
      "t_onset: 0.74621\n",
      "t_offset: 0.81163\n",
      "qrs_onset: 0.94413\n",
      "qrs_offset: 0.94495\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd655f-c98a-430a-879a-ce179d578df7",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка улучшенного SegNet с добавлением дополнительных сверточных слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d039b-40e5-4bfb-ba9c-a20556f1f234",
   "metadata": {},
   "source": [
    "Предыдущая модель показала неплохие результаты, мы можем попробовать увеличить глубину сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7aa94a47-c19b-46f7-842e-7911d4bd2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 5000]             128\n",
      "              ReLU-3             [-1, 64, 5000]               0\n",
      "            Conv1d-4             [-1, 64, 5000]          28,736\n",
      "       BatchNorm1d-5             [-1, 64, 5000]             128\n",
      "              ReLU-6             [-1, 64, 5000]               0\n",
      "         MaxPool1d-7  [[-1, 64, 2500], [-1, 64, 2500]]               0\n",
      "            Conv1d-8            [-1, 128, 2500]          57,472\n",
      "       BatchNorm1d-9            [-1, 128, 2500]             256\n",
      "             ReLU-10            [-1, 128, 2500]               0\n",
      "           Conv1d-11            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-12            [-1, 128, 2500]             256\n",
      "             ReLU-13            [-1, 128, 2500]               0\n",
      "        MaxPool1d-14  [[-1, 128, 1250], [-1, 128, 1250]]               0\n",
      "           Conv1d-15            [-1, 256, 1250]         229,632\n",
      "      BatchNorm1d-16            [-1, 256, 1250]             512\n",
      "             ReLU-17            [-1, 256, 1250]               0\n",
      "           Conv1d-18            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-19            [-1, 256, 1250]             512\n",
      "             ReLU-20            [-1, 256, 1250]               0\n",
      "        MaxPool1d-21  [[-1, 256, 625], [-1, 256, 625]]               0\n",
      "           Conv1d-22             [-1, 512, 625]         918,016\n",
      "      BatchNorm1d-23             [-1, 512, 625]           1,024\n",
      "             ReLU-24             [-1, 512, 625]               0\n",
      "           Conv1d-25             [-1, 512, 625]       1,835,520\n",
      "      BatchNorm1d-26             [-1, 512, 625]           1,024\n",
      "             ReLU-27             [-1, 512, 625]               0\n",
      "        MaxPool1d-28  [[-1, 512, 312], [-1, 512, 312]]               0\n",
      "      MaxUnpool1d-29             [-1, 512, 624]               0\n",
      "           Conv1d-30             [-1, 512, 624]       1,835,520\n",
      "      BatchNorm1d-31             [-1, 512, 624]           1,024\n",
      "             ReLU-32             [-1, 512, 624]               0\n",
      "           Conv1d-33             [-1, 256, 625]       1,048,832\n",
      "      BatchNorm1d-34             [-1, 256, 625]             512\n",
      "             ReLU-35             [-1, 256, 625]               0\n",
      "      MaxUnpool1d-36            [-1, 256, 1250]               0\n",
      "           Conv1d-37            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-38            [-1, 256, 1250]             512\n",
      "             ReLU-39            [-1, 256, 1250]               0\n",
      "           Conv1d-40            [-1, 128, 1250]         229,504\n",
      "      BatchNorm1d-41            [-1, 128, 1250]             256\n",
      "             ReLU-42            [-1, 128, 1250]               0\n",
      "      MaxUnpool1d-43            [-1, 128, 2500]               0\n",
      "           Conv1d-44            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-45            [-1, 128, 2500]             256\n",
      "             ReLU-46            [-1, 128, 2500]               0\n",
      "           Conv1d-47             [-1, 64, 2500]          57,408\n",
      "      BatchNorm1d-48             [-1, 64, 2500]             128\n",
      "             ReLU-49             [-1, 64, 2500]               0\n",
      "      MaxUnpool1d-50             [-1, 64, 5000]               0\n",
      "           Conv1d-51             [-1, 64, 5000]          28,736\n",
      "      BatchNorm1d-52             [-1, 64, 5000]             128\n",
      "             ReLU-53             [-1, 64, 5000]               0\n",
      "           Conv1d-54              [-1, 4, 5000]           1,796\n",
      "      BatchNorm1d-55              [-1, 4, 5000]               8\n",
      "             ReLU-56              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 7,430,924\n",
      "Trainable params: 7,430,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 780516.42\n",
      "Params size (MB): 28.35\n",
      "Estimated Total Size (MB): 780544.99\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0172303 seconds\n"
     ]
    }
   ],
   "source": [
    "class DeeperAdvancedSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(DeeperAdvancedSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "\n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "\n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeeperAdvancedSegNet1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4933c5a8-8bbe-446b-aeff-004c1d55fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8532776019351203\n",
      "Epoch 1/100, Validation Loss: 0.7251434518444922\n",
      "Epoch 2/100, Training Loss: 0.6976993997328678\n",
      "Epoch 2/100, Validation Loss: 0.6321463705070557\n",
      "Epoch 3/100, Training Loss: 0.6072847011842226\n",
      "Epoch 3/100, Validation Loss: 0.5764294579144447\n",
      "Epoch 4/100, Training Loss: 0.5607825423541822\n",
      "Epoch 4/100, Validation Loss: 0.5191138838568041\n",
      "Epoch 5/100, Training Loss: 0.5119769563559096\n",
      "Epoch 5/100, Validation Loss: 0.4700165948560161\n",
      "Epoch 6/100, Training Loss: 0.48356712600480206\n",
      "Epoch 6/100, Validation Loss: 0.45519432906181584\n",
      "Epoch 7/100, Training Loss: 0.461587048614556\n",
      "Epoch 7/100, Validation Loss: 0.44494781667186367\n",
      "Epoch 8/100, Training Loss: 0.4380583752263413\n",
      "Epoch 8/100, Validation Loss: 0.4161361273257963\n",
      "Epoch 9/100, Training Loss: 0.4274614119698644\n",
      "Epoch 9/100, Validation Loss: 0.39605167243749867\n",
      "Epoch 10/100, Training Loss: 0.41726104064508973\n",
      "Epoch 10/100, Validation Loss: 0.39844680048765674\n",
      "Epoch 11/100, Training Loss: 0.4025281260491383\n",
      "Epoch 11/100, Validation Loss: 0.38427438130301816\n",
      "Epoch 12/100, Training Loss: 0.39261423316803057\n",
      "Epoch 12/100, Validation Loss: 0.3793932591234484\n",
      "Epoch 13/100, Training Loss: 0.38392421277428446\n",
      "Epoch 13/100, Validation Loss: 0.3949193692495746\n",
      "Epoch 14/100, Training Loss: 0.3807970019366577\n",
      "Epoch 14/100, Validation Loss: 0.36526744620453927\n",
      "Epoch 15/100, Training Loss: 0.3786844595482475\n",
      "Epoch 15/100, Validation Loss: 0.35141772175988845\n",
      "Epoch 16/100, Training Loss: 0.3644623788986129\n",
      "Epoch 16/100, Validation Loss: 0.35274268734839653\n",
      "Epoch 17/100, Training Loss: 0.3583781692059899\n",
      "Epoch 17/100, Validation Loss: 0.36429032154621616\n",
      "Epoch 18/100, Training Loss: 0.3518765060766506\n",
      "Epoch 18/100, Validation Loss: 0.3400515043927777\n",
      "Epoch 19/100, Training Loss: 0.3428725000576452\n",
      "Epoch 19/100, Validation Loss: 0.34186851593755907\n",
      "Epoch 20/100, Training Loss: 0.3392124560921781\n",
      "Epoch 20/100, Validation Loss: 0.3545075760733697\n",
      "Epoch 21/100, Training Loss: 0.33205561140770856\n",
      "Epoch 21/100, Validation Loss: 0.33082152422397365\n",
      "Epoch 22/100, Training Loss: 0.3239839303228054\n",
      "Epoch 22/100, Validation Loss: 0.3345318472673816\n",
      "Epoch 23/100, Training Loss: 0.3186329514512166\n",
      "Epoch 23/100, Validation Loss: 0.34614067524671555\n",
      "Epoch 24/100, Training Loss: 0.3253762314194127\n",
      "Epoch 24/100, Validation Loss: 0.31615669785007355\n",
      "Epoch 25/100, Training Loss: 0.31634079547304855\n",
      "Epoch 25/100, Validation Loss: 0.3256471724279465\n",
      "Epoch 26/100, Training Loss: 0.3094859003176091\n",
      "Epoch 26/100, Validation Loss: 0.3172789545309159\n",
      "Epoch 27/100, Training Loss: 0.3051513730876359\n",
      "Epoch 27/100, Validation Loss: 0.31862532059031146\n",
      "Epoch 28/100, Training Loss: 0.3010309616684431\n",
      "Epoch 28/100, Validation Loss: 0.3289927772937282\n",
      "Epoch 29/100, Training Loss: 0.297117974956026\n",
      "Epoch 29/100, Validation Loss: 0.31058854032908717\n",
      "Epoch 30/100, Training Loss: 0.29114502867465075\n",
      "Epoch 30/100, Validation Loss: 0.3212280934376101\n",
      "Epoch 31/100, Training Loss: 0.29177130475218\n",
      "Epoch 31/100, Validation Loss: 0.3165116790802248\n",
      "Epoch 32/100, Training Loss: 0.29066120926667804\n",
      "Epoch 32/100, Validation Loss: 0.3241122117446315\n",
      "Epoch 33/100, Training Loss: 0.29043084781179546\n",
      "Epoch 33/100, Validation Loss: 0.31870741733620245\n",
      "Epoch 34/100, Training Loss: 0.28132648265313526\n",
      "Epoch 34/100, Validation Loss: 0.3243100044708098\n",
      "Early stopping triggered\n",
      "Total training time: 84.47 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b4977-84b3-42b1-a55d-79cdce504018",
   "metadata": {},
   "source": [
    "Результаты метрик на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f0c0553-09df-4f54-bdbc-83ddfc2fe90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.76417\n",
      "p_offset: 0.77315\n",
      "t_onset: 0.85639\n",
      "t_offset: 0.85438\n",
      "qrs_onset: 0.96112\n",
      "qrs_offset: 0.96118\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2326684-726c-4c38-a331-684ddd59e953",
   "metadata": {},
   "source": [
    "Можем видеть, что теперь метрики стали еще выше, расположение p-волны правильно сегментируется в 77% случаев, t-волны примерно в 85% случаев, а qrs сегмента в 96% случаев. Однако последующее увеличение глубины сети скорее всего не покажет метрики сильно выше этих, но сильно утежелит модель, что повлияет на ее быстродействие и скорость обученик, поэтому предлагается попробовать другие способы увеличения точности сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a082c-886f-43da-9b36-57b4b06eb8e1",
   "metadata": {},
   "source": [
    "#### 1.4.7. Разработка улучшенного SegNet с добавлением механизма влияния."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43f17a-690c-4c00-aaf5-40b3f48ae30f",
   "metadata": {},
   "source": [
    "Для дальнейшего улучшения качества сегментации, одним из эффективных подходов может быть внедрение механизма внимания или \"attention\", который помогает сети фокусироваться на наиболее информативных частях входных данных. Это может особенно хорошо работать в задачах, где не все части входных данных одинаково важны для определения класса каждой точки данных.  \n",
    "\n",
    "##### Добавление Attention механизма  \n",
    "Мы можем добавить простой self-attention механизм в вашу модель. Это можно сделать путём внедрения специального attention слоя, который будет учитывать веса каждого канала в данных после каждого блока декодирования. Этот подход позволит модели уделять больше внимания важным признакам.  \n",
    "\n",
    "##### Реализация Channel Attention  \n",
    "Один из простых и эффективных способов внедрения attention — использование channel attention, который фокусируется на важности каждого канала. Простой способ реализации — использовать global average pooling для получения средних значений по каждому каналу, затем применить полносвязный слой для расчёта весов каналов, и, наконец, умножить исходные каналы на вычисленные веса.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bf22264d-d039-4c82-8895-40dd6b23ac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 5000]             128\n",
      "              ReLU-3             [-1, 64, 5000]               0\n",
      "            Conv1d-4             [-1, 64, 5000]          28,736\n",
      "       BatchNorm1d-5             [-1, 64, 5000]             128\n",
      "              ReLU-6             [-1, 64, 5000]               0\n",
      "         MaxPool1d-7  [[-1, 64, 2500], [-1, 64, 2500]]               0\n",
      "            Conv1d-8            [-1, 128, 2500]          57,472\n",
      "       BatchNorm1d-9            [-1, 128, 2500]             256\n",
      "             ReLU-10            [-1, 128, 2500]               0\n",
      "           Conv1d-11            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-12            [-1, 128, 2500]             256\n",
      "             ReLU-13            [-1, 128, 2500]               0\n",
      "        MaxPool1d-14  [[-1, 128, 1250], [-1, 128, 1250]]               0\n",
      "           Conv1d-15            [-1, 256, 1250]         229,632\n",
      "      BatchNorm1d-16            [-1, 256, 1250]             512\n",
      "             ReLU-17            [-1, 256, 1250]               0\n",
      "           Conv1d-18            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-19            [-1, 256, 1250]             512\n",
      "             ReLU-20            [-1, 256, 1250]               0\n",
      "        MaxPool1d-21  [[-1, 256, 625], [-1, 256, 625]]               0\n",
      "           Conv1d-22             [-1, 512, 625]         918,016\n",
      "      BatchNorm1d-23             [-1, 512, 625]           1,024\n",
      "             ReLU-24             [-1, 512, 625]               0\n",
      "           Conv1d-25             [-1, 512, 625]       1,835,520\n",
      "      BatchNorm1d-26             [-1, 512, 625]           1,024\n",
      "             ReLU-27             [-1, 512, 625]               0\n",
      "        MaxPool1d-28  [[-1, 512, 312], [-1, 512, 312]]               0\n",
      "      MaxUnpool1d-29             [-1, 512, 624]               0\n",
      "           Conv1d-30             [-1, 512, 624]       1,835,520\n",
      "      BatchNorm1d-31             [-1, 512, 624]           1,024\n",
      "             ReLU-32             [-1, 512, 624]               0\n",
      "           Conv1d-33             [-1, 256, 625]       1,048,832\n",
      "      BatchNorm1d-34             [-1, 256, 625]             512\n",
      "             ReLU-35             [-1, 256, 625]               0\n",
      "AdaptiveAvgPool1d-36               [-1, 256, 1]               0\n",
      "           Linear-37                   [-1, 16]           4,096\n",
      "             ReLU-38                   [-1, 16]               0\n",
      "           Linear-39                  [-1, 256]           4,096\n",
      "          Sigmoid-40                  [-1, 256]               0\n",
      "ChannelAttentionModule-41             [-1, 256, 625]               0\n",
      "      MaxUnpool1d-42            [-1, 256, 1250]               0\n",
      "           Conv1d-43            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-44            [-1, 256, 1250]             512\n",
      "             ReLU-45            [-1, 256, 1250]               0\n",
      "           Conv1d-46            [-1, 128, 1250]         229,504\n",
      "      BatchNorm1d-47            [-1, 128, 1250]             256\n",
      "             ReLU-48            [-1, 128, 1250]               0\n",
      "AdaptiveAvgPool1d-49               [-1, 128, 1]               0\n",
      "           Linear-50                    [-1, 8]           1,024\n",
      "             ReLU-51                    [-1, 8]               0\n",
      "           Linear-52                  [-1, 128]           1,024\n",
      "          Sigmoid-53                  [-1, 128]               0\n",
      "ChannelAttentionModule-54            [-1, 128, 1250]               0\n",
      "      MaxUnpool1d-55            [-1, 128, 2500]               0\n",
      "           Conv1d-56            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-57            [-1, 128, 2500]             256\n",
      "             ReLU-58            [-1, 128, 2500]               0\n",
      "           Conv1d-59             [-1, 64, 2500]          57,408\n",
      "      BatchNorm1d-60             [-1, 64, 2500]             128\n",
      "             ReLU-61             [-1, 64, 2500]               0\n",
      "AdaptiveAvgPool1d-62                [-1, 64, 1]               0\n",
      "           Linear-63                    [-1, 4]             256\n",
      "             ReLU-64                    [-1, 4]               0\n",
      "           Linear-65                   [-1, 64]             256\n",
      "          Sigmoid-66                   [-1, 64]               0\n",
      "ChannelAttentionModule-67             [-1, 64, 2500]               0\n",
      "      MaxUnpool1d-68             [-1, 64, 5000]               0\n",
      "           Conv1d-69             [-1, 64, 5000]          28,736\n",
      "      BatchNorm1d-70             [-1, 64, 5000]             128\n",
      "             ReLU-71             [-1, 64, 5000]               0\n",
      "           Conv1d-72              [-1, 4, 5000]           1,796\n",
      "      BatchNorm1d-73              [-1, 4, 5000]               8\n",
      "             ReLU-74              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 7,441,676\n",
      "Trainable params: 7,441,676\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 780512.74\n",
      "Params size (MB): 28.39\n",
      "Estimated Total Size (MB): 780541.36\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0282965 seconds\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=16):\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c) \n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(AttentionSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Внедрение модуля внимания\n",
    "        self.attention1 = ChannelAttentionModule(256)\n",
    "        self.attention2 = ChannelAttentionModule(128)\n",
    "        self.attention3 = ChannelAttentionModule(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.attention1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "        x = self.attention2(x)\n",
    "        \n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "        x = self.attention3(x)\n",
    "        \n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "       \n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = AttentionSegNet1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916047d-2d2e-445d-8c50-9c71c198fe37",
   "metadata": {},
   "source": [
    "Эта модификация позволяет улучшить способность модели к фокусировке на ключевых признаках, что может повысить точность сегментации, особенно в сложных условиях или при наличии шума в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab906acd-bda8-4094-8511-f1319fbc58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8968825608129926\n",
      "Epoch 1/100, Validation Loss: 0.7872986899268243\n",
      "Epoch 2/100, Training Loss: 0.6993828277114914\n",
      "Epoch 2/100, Validation Loss: 0.605374411709847\n",
      "Epoch 3/100, Training Loss: 0.6130962761548849\n",
      "Epoch 3/100, Validation Loss: 0.5347305372838052\n",
      "Epoch 4/100, Training Loss: 0.5535463012664424\n",
      "Epoch 4/100, Validation Loss: 0.5081355653462871\n",
      "Epoch 5/100, Training Loss: 0.5121886475607451\n",
      "Epoch 5/100, Validation Loss: 0.4691997977995103\n",
      "Epoch 6/100, Training Loss: 0.4874200635110801\n",
      "Epoch 6/100, Validation Loss: 0.4588422035017321\n",
      "Epoch 7/100, Training Loss: 0.460272544550027\n",
      "Epoch 7/100, Validation Loss: 0.4345672553585422\n",
      "Epoch 8/100, Training Loss: 0.4457284062497529\n",
      "Epoch 8/100, Validation Loss: 0.40545741540770375\n",
      "Epoch 9/100, Training Loss: 0.4256325429267729\n",
      "Epoch 9/100, Validation Loss: 0.39701217869597094\n",
      "Epoch 10/100, Training Loss: 0.4183274105734188\n",
      "Epoch 10/100, Validation Loss: 0.3975501166236016\n",
      "Epoch 11/100, Training Loss: 0.4006713777177247\n",
      "Epoch 11/100, Validation Loss: 0.3719931554890448\n",
      "Epoch 12/100, Training Loss: 0.3948445362359406\n",
      "Epoch 12/100, Validation Loss: 0.3731279445271338\n",
      "Epoch 13/100, Training Loss: 0.3830485169583487\n",
      "Epoch 13/100, Validation Loss: 0.36792219622481254\n",
      "Epoch 14/100, Training Loss: 0.3760247898367252\n",
      "Epoch 14/100, Validation Loss: 0.360228732949303\n",
      "Epoch 15/100, Training Loss: 0.36474316377147487\n",
      "Epoch 15/100, Validation Loss: 0.3535864326742388\n",
      "Epoch 16/100, Training Loss: 0.35704953600520545\n",
      "Epoch 16/100, Validation Loss: 0.3438101754553856\n",
      "Epoch 17/100, Training Loss: 0.3557986839700807\n",
      "Epoch 17/100, Validation Loss: 0.3528088564353605\n",
      "Epoch 18/100, Training Loss: 0.35137314871255204\n",
      "Epoch 18/100, Validation Loss: 0.3648658221767795\n",
      "Epoch 19/100, Training Loss: 0.34433657660899375\n",
      "Epoch 19/100, Validation Loss: 0.3267030571737597\n",
      "Epoch 20/100, Training Loss: 0.3336082542473488\n",
      "Epoch 20/100, Validation Loss: 0.3287303144893339\n",
      "Epoch 21/100, Training Loss: 0.3347605632142982\n",
      "Epoch 21/100, Validation Loss: 0.3204303198764401\n",
      "Epoch 22/100, Training Loss: 0.3276321037940168\n",
      "Epoch 22/100, Validation Loss: 0.33786699968960976\n",
      "Epoch 23/100, Training Loss: 0.32343645659294207\n",
      "Epoch 23/100, Validation Loss: 0.3293957022889968\n",
      "Epoch 24/100, Training Loss: 0.32194900645418206\n",
      "Epoch 24/100, Validation Loss: 0.3120270145516242\n",
      "Epoch 25/100, Training Loss: 0.30665998589172055\n",
      "Epoch 25/100, Validation Loss: 0.3130733197735202\n",
      "Epoch 26/100, Training Loss: 0.30326274670811315\n",
      "Epoch 26/100, Validation Loss: 0.3182640577996931\n",
      "Epoch 27/100, Training Loss: 0.30609145917390523\n",
      "Epoch 27/100, Validation Loss: 0.30558271129285136\n",
      "Epoch 28/100, Training Loss: 0.2946782641203297\n",
      "Epoch 28/100, Validation Loss: 0.31441901071417716\n",
      "Epoch 29/100, Training Loss: 0.2925493442698529\n",
      "Epoch 29/100, Validation Loss: 0.3030451185280277\n",
      "Epoch 30/100, Training Loss: 0.294279650637978\n",
      "Epoch 30/100, Validation Loss: 0.30744147036344777\n",
      "Epoch 31/100, Training Loss: 0.28227944521286225\n",
      "Epoch 31/100, Validation Loss: 0.31315659419182806\n",
      "Epoch 32/100, Training Loss: 0.2852969946045625\n",
      "Epoch 32/100, Validation Loss: 0.30141236464823445\n",
      "Epoch 33/100, Training Loss: 0.27825162170628304\n",
      "Epoch 33/100, Validation Loss: 0.30023278800710557\n",
      "Epoch 34/100, Training Loss: 0.2778061609036527\n",
      "Epoch 34/100, Validation Loss: 0.3036577292988377\n",
      "Epoch 35/100, Training Loss: 0.27516119037321224\n",
      "Epoch 35/100, Validation Loss: 0.305802398150967\n",
      "Epoch 36/100, Training Loss: 0.2671010666168653\n",
      "Epoch 36/100, Validation Loss: 0.3043766661036399\n",
      "Epoch 37/100, Training Loss: 0.27147996455792955\n",
      "Epoch 37/100, Validation Loss: 0.29856963768120737\n",
      "Epoch 38/100, Training Loss: 0.2658185271719689\n",
      "Epoch 38/100, Validation Loss: 0.29286521937577953\n",
      "Epoch 39/100, Training Loss: 0.257888126288831\n",
      "Epoch 39/100, Validation Loss: 0.3075346425175667\n",
      "Epoch 40/100, Training Loss: 0.26353992226152767\n",
      "Epoch 40/100, Validation Loss: 0.29766491199693373\n",
      "Epoch 41/100, Training Loss: 0.2541760106680364\n",
      "Epoch 41/100, Validation Loss: 0.29770286501415316\n",
      "Epoch 42/100, Training Loss: 0.2542352311403645\n",
      "Epoch 42/100, Validation Loss: 0.30031965312457853\n",
      "Epoch 43/100, Training Loss: 0.25473315181278505\n",
      "Epoch 43/100, Validation Loss: 0.3041246586268948\n",
      "Early stopping triggered\n",
      "Total training time: 149.48 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08fdeb67-bf2f-4963-8d63-7d243566b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.83115\n",
      "p_offset: 0.82901\n",
      "t_onset: 0.87987\n",
      "t_offset: 0.87111\n",
      "qrs_onset: 0.96081\n",
      "qrs_offset: 0.95714\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb6c54-09cc-4e59-a6dd-9ea4f7ef6938",
   "metadata": {},
   "source": [
    "Можем заметить, что attention механизм действительно помог улучшить определение t волны, на данный момент она определяется с точностью примерно в 87%. P волна определяется с точностью 83%, qrs сегмент с точностью 96%. Попробуем интегрировать дополнительные алгоритмы для повышения точности сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5174bc-058b-442b-98b1-f956c9761d89",
   "metadata": {},
   "source": [
    "#### 1.4.8. Разработка SegNet с добавлением механизма влияния и остаточными блоками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d31bf-6afe-4b7f-8b1e-b5864afff2e3",
   "metadata": {},
   "source": [
    "Для дальнейшего повышения эффективности модели можно рассмотреть добавление дополнительных усовершенствований, таких как использование глубоких остаточных блоков (deep residual blocks).  \n",
    "\n",
    "Остаточные блоки (Residual Blocks) могут помочь уменьшить проблему исчезающих градиентов в глубоких сетях, улучшая обучение и способность сети к извлечению сложных признаков без потери информации на промежуточных слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "593c78c4-55ba-4c12-bbaa-a199b4dfc3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 5000]             128\n",
      "              ReLU-3             [-1, 64, 5000]               0\n",
      "            Conv1d-4             [-1, 64, 5000]          28,736\n",
      "       BatchNorm1d-5             [-1, 64, 5000]             128\n",
      "              ReLU-6             [-1, 64, 5000]               0\n",
      "         MaxPool1d-7  [[-1, 64, 2500], [-1, 64, 2500]]               0\n",
      "            Conv1d-8            [-1, 128, 2500]          57,472\n",
      "       BatchNorm1d-9            [-1, 128, 2500]             256\n",
      "             ReLU-10            [-1, 128, 2500]               0\n",
      "           Conv1d-11            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-12            [-1, 128, 2500]             256\n",
      "             ReLU-13            [-1, 128, 2500]               0\n",
      "        MaxPool1d-14  [[-1, 128, 1250], [-1, 128, 1250]]               0\n",
      "           Conv1d-15            [-1, 256, 1250]         229,632\n",
      "      BatchNorm1d-16            [-1, 256, 1250]             512\n",
      "             ReLU-17            [-1, 256, 1250]               0\n",
      "           Conv1d-18            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-19            [-1, 256, 1250]             512\n",
      "             ReLU-20            [-1, 256, 1250]               0\n",
      "        MaxPool1d-21  [[-1, 256, 625], [-1, 256, 625]]               0\n",
      "           Conv1d-22             [-1, 512, 625]         918,016\n",
      "      BatchNorm1d-23             [-1, 512, 625]           1,024\n",
      "             ReLU-24             [-1, 512, 625]               0\n",
      "           Conv1d-25             [-1, 512, 625]       1,835,520\n",
      "      BatchNorm1d-26             [-1, 512, 625]           1,024\n",
      "             ReLU-27             [-1, 512, 625]               0\n",
      "        MaxPool1d-28  [[-1, 512, 312], [-1, 512, 312]]               0\n",
      "      MaxUnpool1d-29             [-1, 512, 624]               0\n",
      "           Conv1d-30             [-1, 512, 624]       1,835,520\n",
      "      BatchNorm1d-31             [-1, 512, 624]           1,024\n",
      "             ReLU-32             [-1, 512, 624]               0\n",
      "           Conv1d-33             [-1, 256, 625]       1,048,832\n",
      "      BatchNorm1d-34             [-1, 256, 625]             512\n",
      "             ReLU-35             [-1, 256, 625]               0\n",
      "           Conv1d-36             [-1, 256, 625]         196,864\n",
      "      BatchNorm1d-37             [-1, 256, 625]             512\n",
      "             ReLU-38             [-1, 256, 625]               0\n",
      "           Conv1d-39             [-1, 256, 625]         196,864\n",
      "      BatchNorm1d-40             [-1, 256, 625]             512\n",
      "             ReLU-41             [-1, 256, 625]               0\n",
      "    ResidualBlock-42             [-1, 256, 625]               0\n",
      "AdaptiveAvgPool1d-43               [-1, 256, 1]               0\n",
      "           Linear-44                   [-1, 16]           4,096\n",
      "             ReLU-45                   [-1, 16]               0\n",
      "           Linear-46                  [-1, 256]           4,096\n",
      "          Sigmoid-47                  [-1, 256]               0\n",
      "ChannelAttentionModule-48             [-1, 256, 625]               0\n",
      "      MaxUnpool1d-49            [-1, 256, 1250]               0\n",
      "           Conv1d-50            [-1, 256, 1250]         459,008\n",
      "      BatchNorm1d-51            [-1, 256, 1250]             512\n",
      "             ReLU-52            [-1, 256, 1250]               0\n",
      "           Conv1d-53            [-1, 128, 1250]         229,504\n",
      "      BatchNorm1d-54            [-1, 128, 1250]             256\n",
      "             ReLU-55            [-1, 128, 1250]               0\n",
      "           Conv1d-56            [-1, 128, 1250]          49,280\n",
      "      BatchNorm1d-57            [-1, 128, 1250]             256\n",
      "             ReLU-58            [-1, 128, 1250]               0\n",
      "           Conv1d-59            [-1, 128, 1250]          49,280\n",
      "      BatchNorm1d-60            [-1, 128, 1250]             256\n",
      "             ReLU-61            [-1, 128, 1250]               0\n",
      "    ResidualBlock-62            [-1, 128, 1250]               0\n",
      "AdaptiveAvgPool1d-63               [-1, 128, 1]               0\n",
      "           Linear-64                    [-1, 8]           1,024\n",
      "             ReLU-65                    [-1, 8]               0\n",
      "           Linear-66                  [-1, 128]           1,024\n",
      "          Sigmoid-67                  [-1, 128]               0\n",
      "ChannelAttentionModule-68            [-1, 128, 1250]               0\n",
      "      MaxUnpool1d-69            [-1, 128, 2500]               0\n",
      "           Conv1d-70            [-1, 128, 2500]         114,816\n",
      "      BatchNorm1d-71            [-1, 128, 2500]             256\n",
      "             ReLU-72            [-1, 128, 2500]               0\n",
      "           Conv1d-73             [-1, 64, 2500]          57,408\n",
      "      BatchNorm1d-74             [-1, 64, 2500]             128\n",
      "             ReLU-75             [-1, 64, 2500]               0\n",
      "           Conv1d-76             [-1, 64, 2500]          12,352\n",
      "      BatchNorm1d-77             [-1, 64, 2500]             128\n",
      "             ReLU-78             [-1, 64, 2500]               0\n",
      "           Conv1d-79             [-1, 64, 2500]          12,352\n",
      "      BatchNorm1d-80             [-1, 64, 2500]             128\n",
      "             ReLU-81             [-1, 64, 2500]               0\n",
      "    ResidualBlock-82             [-1, 64, 2500]               0\n",
      "AdaptiveAvgPool1d-83                [-1, 64, 1]               0\n",
      "           Linear-84                    [-1, 4]             256\n",
      "             ReLU-85                    [-1, 4]               0\n",
      "           Linear-86                   [-1, 64]             256\n",
      "          Sigmoid-87                   [-1, 64]               0\n",
      "ChannelAttentionModule-88             [-1, 64, 2500]               0\n",
      "      MaxUnpool1d-89             [-1, 64, 5000]               0\n",
      "           Conv1d-90             [-1, 64, 5000]          28,736\n",
      "      BatchNorm1d-91             [-1, 64, 5000]             128\n",
      "             ReLU-92             [-1, 64, 5000]               0\n",
      "           Conv1d-93              [-1, 4, 5000]           1,796\n",
      "      BatchNorm1d-94              [-1, 4, 5000]               8\n",
      "             ReLU-95              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 7,960,460\n",
      "Trainable params: 7,960,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 780487.11\n",
      "Params size (MB): 30.37\n",
      "Estimated Total Size (MB): 780517.70\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0130553 seconds\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResAttentionSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(ResAttentionSegNet1D, self).__init__()\n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Внедрение модуля внимания\n",
    "        self.attention1 = ChannelAttentionModule(256)\n",
    "        self.attention2 = ChannelAttentionModule(128)\n",
    "        self.attention3 = ChannelAttentionModule(64)\n",
    "        \n",
    "        # Добавление остаточных блоков\n",
    "        self.res_block1 = ResidualBlock(256)\n",
    "        self.res_block2 = ResidualBlock(128)\n",
    "        self.res_block3 = ResidualBlock(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "\n",
    "        # Декодер с остаточными блоками\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.res_block1(x)  # Применение остаточного блока\n",
    "        x = self.attention1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.attention2(x)\n",
    "        \n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.attention3(x)\n",
    "        \n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = ResAttentionSegNet1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ac0bbbd-2506-4302-91b1-c11d196a9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.9279591730731701\n",
      "Epoch 1/100, Validation Loss: 0.8127460575872852\n",
      "Epoch 2/100, Training Loss: 0.7798083670708814\n",
      "Epoch 2/100, Validation Loss: 0.7134575507333202\n",
      "Epoch 3/100, Training Loss: 0.6481134264092696\n",
      "Epoch 3/100, Validation Loss: 0.5522382100743632\n",
      "Epoch 4/100, Training Loss: 0.5645432764219369\n",
      "Epoch 4/100, Validation Loss: 0.505205441386469\n",
      "Epoch 5/100, Training Loss: 0.5199967928019612\n",
      "Epoch 5/100, Validation Loss: 0.4849419944709347\n",
      "Epoch 6/100, Training Loss: 0.4919208184427578\n",
      "Epoch 6/100, Validation Loss: 0.45181229374101084\n",
      "Epoch 7/100, Training Loss: 0.47216953475948287\n",
      "Epoch 7/100, Validation Loss: 0.42374066095198354\n",
      "Epoch 8/100, Training Loss: 0.44148505421785206\n",
      "Epoch 8/100, Validation Loss: 0.42298857723512956\n",
      "Epoch 9/100, Training Loss: 0.42766312090491476\n",
      "Epoch 9/100, Validation Loss: 0.3891171697647341\n",
      "Epoch 10/100, Training Loss: 0.41093709564160724\n",
      "Epoch 10/100, Validation Loss: 0.3831646315032436\n",
      "Epoch 11/100, Training Loss: 0.40500850094716073\n",
      "Epoch 11/100, Validation Loss: 0.3963964427671125\n",
      "Epoch 12/100, Training Loss: 0.3930342030911311\n",
      "Epoch 12/100, Validation Loss: 0.3730746315371606\n",
      "Epoch 13/100, Training Loss: 0.38567049161866607\n",
      "Epoch 13/100, Validation Loss: 0.3664037058911016\n",
      "Epoch 14/100, Training Loss: 0.3796670538211158\n",
      "Epoch 14/100, Validation Loss: 0.36179179962604274\n",
      "Epoch 15/100, Training Loss: 0.3687768503721909\n",
      "Epoch 15/100, Validation Loss: 0.3534211107800084\n",
      "Epoch 16/100, Training Loss: 0.3630941947582762\n",
      "Epoch 16/100, Validation Loss: 0.34001355065453437\n",
      "Epoch 17/100, Training Loss: 0.36000799981929993\n",
      "Epoch 17/100, Validation Loss: 0.3565860294526623\n",
      "Epoch 18/100, Training Loss: 0.35089849182951305\n",
      "Epoch 18/100, Validation Loss: 0.3367893902524825\n",
      "Epoch 19/100, Training Loss: 0.34706580397571146\n",
      "Epoch 19/100, Validation Loss: 0.3380065810295843\n",
      "Epoch 20/100, Training Loss: 0.3379870720720484\n",
      "Epoch 20/100, Validation Loss: 0.33490527613509086\n",
      "Epoch 21/100, Training Loss: 0.34770235871737787\n",
      "Epoch 21/100, Validation Loss: 0.3323724505401427\n",
      "Epoch 22/100, Training Loss: 0.33005970728542156\n",
      "Epoch 22/100, Validation Loss: 0.3258975080905422\n",
      "Epoch 23/100, Training Loss: 0.32395313487120486\n",
      "Epoch 23/100, Validation Loss: 0.32169755620341145\n",
      "Epoch 24/100, Training Loss: 0.32347915976153696\n",
      "Epoch 24/100, Validation Loss: 0.3205075187067832\n",
      "Epoch 25/100, Training Loss: 0.31606303625985194\n",
      "Epoch 25/100, Validation Loss: 0.31786403468539637\n",
      "Epoch 26/100, Training Loss: 0.3115031736099768\n",
      "Epoch 26/100, Validation Loss: 0.31947250423892853\n",
      "Epoch 27/100, Training Loss: 0.307479275925922\n",
      "Epoch 27/100, Validation Loss: 0.3247074585768484\n",
      "Epoch 28/100, Training Loss: 0.3092823283151094\n",
      "Epoch 28/100, Validation Loss: 0.31383642890760977\n",
      "Epoch 29/100, Training Loss: 0.30281114131815523\n",
      "Epoch 29/100, Validation Loss: 0.31183875712656206\n",
      "Epoch 30/100, Training Loss: 0.3035092456982686\n",
      "Epoch 30/100, Validation Loss: 0.3139573121743818\n",
      "Epoch 31/100, Training Loss: 0.29799590594614084\n",
      "Epoch 31/100, Validation Loss: 0.31391750540464153\n",
      "Epoch 32/100, Training Loss: 0.2918569671842251\n",
      "Epoch 32/100, Validation Loss: 0.30919372554748287\n",
      "Epoch 33/100, Training Loss: 0.28738668657507493\n",
      "Epoch 33/100, Validation Loss: 0.3087067419002133\n",
      "Epoch 34/100, Training Loss: 0.28951890820916365\n",
      "Epoch 34/100, Validation Loss: 0.2993192672729492\n",
      "Epoch 35/100, Training Loss: 0.2862436526458756\n",
      "Epoch 35/100, Validation Loss: 0.2958274490890964\n",
      "Epoch 36/100, Training Loss: 0.2758231146132898\n",
      "Epoch 36/100, Validation Loss: 0.29764757185213025\n",
      "Epoch 37/100, Training Loss: 0.2743520731868049\n",
      "Epoch 37/100, Validation Loss: 0.2956747823665219\n",
      "Epoch 38/100, Training Loss: 0.2726475032958907\n",
      "Epoch 38/100, Validation Loss: 0.29386238537488446\n",
      "Epoch 39/100, Training Loss: 0.27286004247935675\n",
      "Epoch 39/100, Validation Loss: 0.30381658360842734\n",
      "Epoch 40/100, Training Loss: 0.26882866344712525\n",
      "Epoch 40/100, Validation Loss: 0.2919880382476314\n",
      "Epoch 41/100, Training Loss: 0.26795459988146175\n",
      "Epoch 41/100, Validation Loss: 0.2910815729729591\n",
      "Epoch 42/100, Training Loss: 0.26452185659997374\n",
      "Epoch 42/100, Validation Loss: 0.2995984039960369\n",
      "Epoch 43/100, Training Loss: 0.2650404009621153\n",
      "Epoch 43/100, Validation Loss: 0.29219911175389446\n",
      "Epoch 44/100, Training Loss: 0.2574785205758052\n",
      "Epoch 44/100, Validation Loss: 0.288324871130528\n",
      "Epoch 45/100, Training Loss: 0.2590915952858172\n",
      "Epoch 45/100, Validation Loss: 0.28813870299247\n",
      "Epoch 46/100, Training Loss: 0.2522819348071751\n",
      "Epoch 46/100, Validation Loss: 0.2891159699328484\n",
      "Epoch 47/100, Training Loss: 0.2543976621227226\n",
      "Epoch 47/100, Validation Loss: 0.30076024152578845\n",
      "Epoch 48/100, Training Loss: 0.2834426085596625\n",
      "Epoch 48/100, Validation Loss: 0.29727589459188525\n",
      "Epoch 49/100, Training Loss: 0.25353136767259976\n",
      "Epoch 49/100, Validation Loss: 0.29648175811575306\n",
      "Epoch 50/100, Training Loss: 0.24539136681479481\n",
      "Epoch 50/100, Validation Loss: 0.290107284342089\n",
      "Early stopping triggered\n",
      "Total training time: 327.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10ed9196-ce63-45c5-ba57-08469792367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.81838\n",
      "p_offset: 0.81341\n",
      "t_onset: 0.86896\n",
      "t_offset: 0.88847\n",
      "qrs_onset: 0.95882\n",
      "qrs_offset: 0.95972\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05704e-e8c3-49e6-a5ab-82eb582d6631",
   "metadata": {},
   "source": [
    "Можно заметить, что применение остаточных блоков ухудшили результаты метрик.\n",
    "Добавление остаточных блоков или других архитектурных компонентов не всегда гарантирует улучшение результатов, поскольку это зависит от ряда факторов:\n",
    "\n",
    "1. **Глубина сети и сложность задачи**:  \n",
    "Если модель изначально уже хорошо справлялась с задачей, дополнительная глубина может создать излишнюю сложность и привести к переобучению, особенно если данных для обучения недостаточно.  \n",
    "2. **Гиперпараметры**:  \n",
    "Возможно, что параметры оптимизатора, такие как скорость обучения, не были скорректированы для новой, более сложной модели, что могло замедлить или затруднить обучение.  \n",
    "3. **Собственный шум в данных**:  \n",
    "Если данные содержат много шума или погрешностей, более сложная модель может быть более чувствительна к этим ошибкам и переобучаться на них.  \n",
    "4. **Совместимость с другими компонентами**:  \n",
    "Остаточные блоки могут нарушить взаимодействие с другими частями модели, например, с механизмами внимания. Это приводит к проблемам в передаче признаков между слоями.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdbc25-3eb5-4072-a87f-3445d0e5e0bc",
   "metadata": {},
   "source": [
    "Мы можем запомнить нашу модель AttentionSegNet1D (которая на данный момент показывает наилучший результат) для дальнейших экспериментов, и попробовать другие известные архитектуры нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bbb4f-7f99-49fe-9f21-8dedde5e5d2d",
   "metadata": {},
   "source": [
    "#### 1.4.9. Разработка DeepLabV3Plus1D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce18ce2-a735-4c0b-9f75-d452ba6bc305",
   "metadata": {},
   "source": [
    "Для адаптации DeepLabV3+ под нашу задачу с одномерными сигналами, необходимо модифицировать архитектуру так, чтобы она подходила для обработки одномерных данных, вместо двумерных, как в стандартной версии, используемой для изображений. Это потребует замены всех двумерных сверточных операций на одномерные аналоги.  \n",
    "\n",
    "Основные компоненты модификации DeepLabV3+:  \n",
    "1. Одномерные сверточные слои вместо двумерных.  \n",
    "2. Одномерный Atrous Spatial Pyramid Pooling (ASPP), который адаптируется к одномерным данным.  \n",
    "3. Декодер, который адаптирован для восстановления одномерных данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8d5fd7c-f245-435e-8aa6-35dac4d39816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      "         MaxPool1d-4             [-1, 64, 1250]               0\n",
      "            Conv1d-5            [-1, 256, 1250]          16,640\n",
      "            Conv1d-6            [-1, 256, 1250]          49,408\n",
      "            Conv1d-7            [-1, 256, 1250]          49,408\n",
      "            Conv1d-8            [-1, 256, 1250]          49,408\n",
      "       BatchNorm1d-9           [-1, 1024, 1250]           2,048\n",
      "             ReLU-10           [-1, 1024, 1250]               0\n",
      "           Conv1d-11            [-1, 256, 1250]         262,400\n",
      "             ASPP-12            [-1, 256, 1250]               0\n",
      "           Conv1d-13            [-1, 256, 5000]         196,864\n",
      "      BatchNorm1d-14            [-1, 256, 5000]             512\n",
      "             ReLU-15            [-1, 256, 5000]               0\n",
      "           Conv1d-16              [-1, 4, 5000]           1,028\n",
      "================================================================\n",
      "Total params: 633,284\n",
      "Trainable params: 633,284\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 67.90\n",
      "Params size (MB): 2.42\n",
      "Estimated Total Size (MB): 70.55\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0520885 seconds\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 4, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x = torch.cat((x1, x6, x12, x18), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(64, 256)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)  # Upsample to match input size\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10a7c7-f215-45a4-b1c9-60971351a92d",
   "metadata": {},
   "source": [
    "В коде данной модели используются основные элементы:  \n",
    "**ASPP: Atrous Spatial Pyramid Pooling** адаптирован для 1D. Это позволяет сети захватывать контекст на разных масштабах.  \n",
    "**Декодер**: Простой декодер используется для восстановления размера до исходного, используя интерполяцию для увеличения размера выхода ASPP до размера входного сигнала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "02efa98a-40fc-40d0-82da-66a7146de362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.5535530519147633\n",
      "Epoch 1/100, Validation Loss: 0.4548309834734086\n",
      "Epoch 2/100, Training Loss: 0.45208611101032753\n",
      "Epoch 2/100, Validation Loss: 0.43702697345326025\n",
      "Epoch 3/100, Training Loss: 0.4235838134037821\n",
      "Epoch 3/100, Validation Loss: 0.4411222953950205\n",
      "Epoch 4/100, Training Loss: 0.4013021109316513\n",
      "Epoch 4/100, Validation Loss: 0.40806274933199727\n",
      "Epoch 5/100, Training Loss: 0.38223201446687644\n",
      "Epoch 5/100, Validation Loss: 0.41044038173652464\n",
      "Epoch 6/100, Training Loss: 0.36589540987603575\n",
      "Epoch 6/100, Validation Loss: 0.3998807606197173\n",
      "Epoch 7/100, Training Loss: 0.3609281351209169\n",
      "Epoch 7/100, Validation Loss: 0.3868204093267841\n",
      "Epoch 8/100, Training Loss: 0.3488586171556581\n",
      "Epoch 8/100, Validation Loss: 0.3855990450228414\n",
      "Epoch 9/100, Training Loss: 0.3340737769598903\n",
      "Epoch 9/100, Validation Loss: 0.3810670495994629\n",
      "Epoch 10/100, Training Loss: 0.3320740141004686\n",
      "Epoch 10/100, Validation Loss: 0.375561980230193\n",
      "Epoch 11/100, Training Loss: 0.3310003575043157\n",
      "Epoch 11/100, Validation Loss: 0.35658301941810117\n",
      "Epoch 12/100, Training Loss: 0.3191773329789822\n",
      "Epoch 12/100, Validation Loss: 0.37371853859193865\n",
      "Epoch 13/100, Training Loss: 0.3178186874519958\n",
      "Epoch 13/100, Validation Loss: 0.3758356280384525\n",
      "Epoch 14/100, Training Loss: 0.3112463500456289\n",
      "Epoch 14/100, Validation Loss: 0.3598158871454577\n",
      "Epoch 15/100, Training Loss: 0.31276268919228545\n",
      "Epoch 15/100, Validation Loss: 0.35968627924880675\n",
      "Epoch 16/100, Training Loss: 0.30540125602893986\n",
      "Epoch 16/100, Validation Loss: 0.36250551958237925\n",
      "Early stopping triggered\n",
      "Total training time: 22.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a1246618-777d-4a0a-8e9d-1eba378dde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.70742\n",
      "p_offset: 0.73209\n",
      "t_onset: 0.82983\n",
      "t_offset: 0.82164\n",
      "qrs_onset: 0.95702\n",
      "qrs_offset: 0.95594\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4daf93-2e4f-4e25-b8cc-3f94980edf43",
   "metadata": {},
   "source": [
    "Сходу DeepLabV3 показал неплохой потенциал. Можно попробовать увеличить глубину сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9ffe9-5963-41f2-9478-9e41126a9aa9",
   "metadata": {},
   "source": [
    "#### 1.4.10. Разработка DeepLabV3Plus1D с увеличинной глубиной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacaf69-df51-49fc-9015-df051ebe7d3d",
   "metadata": {},
   "source": [
    "Чтобы увеличить глубину модели, можно добавить больше сверточных слоев в features и decoder, а также расширить сам модуль ASPP. Однако важно сбалансировать увеличение глубины с вычислительной эффективностью и избежать излишнего усложнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "105c0f6e-cfce-4294-9068-c59dbf18915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      "            Conv1d-4            [-1, 128, 1250]          24,704\n",
      "       BatchNorm1d-5            [-1, 128, 1250]             256\n",
      "              ReLU-6            [-1, 128, 1250]               0\n",
      "            Conv1d-7             [-1, 256, 625]          98,560\n",
      "       BatchNorm1d-8             [-1, 256, 625]             512\n",
      "              ReLU-9             [-1, 256, 625]               0\n",
      "        MaxPool1d-10             [-1, 256, 313]               0\n",
      "           Conv1d-11             [-1, 512, 313]         131,584\n",
      "           Conv1d-12             [-1, 512, 313]         393,728\n",
      "           Conv1d-13             [-1, 512, 313]         393,728\n",
      "           Conv1d-14             [-1, 512, 313]         393,728\n",
      "           Conv1d-15             [-1, 512, 313]         393,728\n",
      "      BatchNorm1d-16            [-1, 2560, 313]           5,120\n",
      "             ReLU-17            [-1, 2560, 313]               0\n",
      "           Conv1d-18             [-1, 512, 313]       1,311,232\n",
      "             ASPP-19             [-1, 512, 313]               0\n",
      "           Conv1d-20            [-1, 256, 5000]         393,472\n",
      "      BatchNorm1d-21            [-1, 256, 5000]             512\n",
      "             ReLU-22            [-1, 256, 5000]               0\n",
      "           Conv1d-23              [-1, 4, 5000]           1,028\n",
      "================================================================\n",
      "Total params: 3,547,460\n",
      "Trainable params: 3,547,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 61.83\n",
      "Params size (MB): 13.53\n",
      "Estimated Total Size (MB): 75.59\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0298283 seconds\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DDeeper(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DDeeper, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DDeeper(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7aee0-c218-409f-8010-b06030088f65",
   "metadata": {},
   "source": [
    "##### Основные изменения:  \n",
    "**ASPP**: Добавлен еще один atrous_block для улавливания еще более широкого контекста.  \n",
    "**Features**: Увеличена глубина путем добавления нескольких дополнительных сверточных слоев.  \n",
    "**Decoder**: Используется простой декодер, но он обрабатывает выход более глубокой сети.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7941522f-9d33-4923-a5fb-582c3f1402df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.5144306482815066\n",
      "Epoch 1/100, Validation Loss: 0.44289941124377713\n",
      "Epoch 2/100, Training Loss: 0.4234909991986356\n",
      "Epoch 2/100, Validation Loss: 0.3839777508570302\n",
      "Epoch 3/100, Training Loss: 0.38389544243272017\n",
      "Epoch 3/100, Validation Loss: 0.38589970863634543\n",
      "Epoch 4/100, Training Loss: 0.3613919229642582\n",
      "Epoch 4/100, Validation Loss: 0.34593039126165454\n",
      "Epoch 5/100, Training Loss: 0.3518125515597069\n",
      "Epoch 5/100, Validation Loss: 0.37075468609409945\n",
      "Epoch 6/100, Training Loss: 0.3309643882126943\n",
      "Epoch 6/100, Validation Loss: 0.3480653094668542\n",
      "Epoch 7/100, Training Loss: 0.31695210438990884\n",
      "Epoch 7/100, Validation Loss: 0.34054247169725355\n",
      "Epoch 8/100, Training Loss: 0.3096617816792809\n",
      "Epoch 8/100, Validation Loss: 0.33356449825148426\n",
      "Epoch 9/100, Training Loss: 0.30308613573250015\n",
      "Epoch 9/100, Validation Loss: 0.3356512054320305\n",
      "Epoch 10/100, Training Loss: 0.29174521975671713\n",
      "Epoch 10/100, Validation Loss: 0.32453656364833156\n",
      "Epoch 11/100, Training Loss: 0.2773764543687766\n",
      "Epoch 11/100, Validation Loss: 0.348904071075301\n",
      "Epoch 12/100, Training Loss: 0.2739317964325067\n",
      "Epoch 12/100, Validation Loss: 0.3241280449494239\n",
      "Epoch 13/100, Training Loss: 0.26754642540385365\n",
      "Epoch 13/100, Validation Loss: 0.32002467493857106\n",
      "Epoch 14/100, Training Loss: 0.25815208859530536\n",
      "Epoch 14/100, Validation Loss: 0.322345316650406\n",
      "Epoch 15/100, Training Loss: 0.25109186159213065\n",
      "Epoch 15/100, Validation Loss: 0.34009933904294043\n",
      "Epoch 16/100, Training Loss: 0.24804807125556808\n",
      "Epoch 16/100, Validation Loss: 0.3461402933443746\n",
      "Epoch 17/100, Training Loss: 0.2398425206119715\n",
      "Epoch 17/100, Validation Loss: 0.3311024661506376\n",
      "Epoch 18/100, Training Loss: 0.23452309847843308\n",
      "Epoch 18/100, Validation Loss: 0.32022495639901005\n",
      "Early stopping triggered\n",
      "Total training time: 34.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76cf19e1-8ffa-45eb-898c-5df4fe7d45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.77403\n",
      "p_offset: 0.78926\n",
      "t_onset: 0.88835\n",
      "t_offset: 0.88879\n",
      "qrs_onset: 0.9665\n",
      "qrs_offset: 0.96513\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01275f-df22-4002-ba02-9a3a03f2f56c",
   "metadata": {},
   "source": [
    "Отлично! С увеличением глубины сети, метрики улучшили свои показатели. Теперь p-волна определяется верно в 77% случаев, t-волна определяется верно в 88% случаев, а qrs-сегмент в 96% случаев. Можно попробовать еще увеличить глубину сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926e2e-1467-400f-8430-4b6a227f7dda",
   "metadata": {},
   "source": [
    "#### 1.4.11. Разработка DeepLabV3Plus1D с увеличинной глубиной V2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d12f3-4070-4fbf-992f-71642689bfd1",
   "metadata": {},
   "source": [
    "В коде ниже приведена модель с еще большим количеством внутренних сверточных слоев в сравнении с моделью выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7aecdd2a-3bc9-4c67-9998-37b25b66e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      "            Conv1d-4            [-1, 128, 1250]          24,704\n",
      "       BatchNorm1d-5            [-1, 128, 1250]             256\n",
      "              ReLU-6            [-1, 128, 1250]               0\n",
      "            Conv1d-7             [-1, 256, 625]          98,560\n",
      "       BatchNorm1d-8             [-1, 256, 625]             512\n",
      "              ReLU-9             [-1, 256, 625]               0\n",
      "           Conv1d-10             [-1, 512, 313]         393,728\n",
      "      BatchNorm1d-11             [-1, 512, 313]           1,024\n",
      "             ReLU-12             [-1, 512, 313]               0\n",
      "           Conv1d-13            [-1, 1024, 157]       1,573,888\n",
      "      BatchNorm1d-14            [-1, 1024, 157]           2,048\n",
      "             ReLU-15            [-1, 1024, 157]               0\n",
      "        MaxPool1d-16             [-1, 1024, 79]               0\n",
      "           Conv1d-17              [-1, 512, 79]         524,800\n",
      "           Conv1d-18              [-1, 512, 79]       1,573,376\n",
      "           Conv1d-19              [-1, 512, 79]       1,573,376\n",
      "           Conv1d-20              [-1, 512, 79]       1,573,376\n",
      "           Conv1d-21              [-1, 512, 79]       1,573,376\n",
      "      BatchNorm1d-22             [-1, 2560, 79]           5,120\n",
      "             ReLU-23             [-1, 2560, 79]               0\n",
      "           Conv1d-24              [-1, 512, 79]       1,311,232\n",
      "             ASPP-25              [-1, 512, 79]               0\n",
      "           Conv1d-26            [-1, 256, 5000]         393,472\n",
      "      BatchNorm1d-27            [-1, 256, 5000]             512\n",
      "             ReLU-28            [-1, 256, 5000]               0\n",
      "           Conv1d-29            [-1, 128, 5000]          98,432\n",
      "      BatchNorm1d-30            [-1, 128, 5000]             256\n",
      "             ReLU-31            [-1, 128, 5000]               0\n",
      "           Conv1d-32              [-1, 4, 5000]             516\n",
      "================================================================\n",
      "Total params: 10,728,132\n",
      "Trainable params: 10,728,132\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 68.30\n",
      "Params size (MB): 40.92\n",
      "Estimated Total Size (MB): 109.45\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0308635 seconds\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeeperV2DeepLabV3Plus1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeeperV2DeepLabV3Plus1D, self).__init__()\n",
    "        \n",
    "        # Глубокая часть features\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Расширенный ASPP\n",
    "        self.aspp = ASPP(1024, 512)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeeperV2DeepLabV3Plus1D(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "29ac196a-f3c0-44a0-b6ab-99e05dd467e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.6979826037217731\n",
      "Epoch 1/100, Validation Loss: 0.6476650963867864\n",
      "Epoch 2/100, Training Loss: 0.5288765670558219\n",
      "Epoch 2/100, Validation Loss: 0.4921221060137595\n",
      "Epoch 3/100, Training Loss: 0.48236862392078045\n",
      "Epoch 3/100, Validation Loss: 0.4781120280104299\n",
      "Epoch 4/100, Training Loss: 0.45183731669839095\n",
      "Epoch 4/100, Validation Loss: 0.4328951143449353\n",
      "Epoch 5/100, Training Loss: 0.43071542553573483\n",
      "Epoch 5/100, Validation Loss: 0.4223929533073979\n",
      "Epoch 6/100, Training Loss: 0.40221478780995495\n",
      "Epoch 6/100, Validation Loss: 0.42342770748561426\n",
      "Epoch 7/100, Training Loss: 0.3823821653238675\n",
      "Epoch 7/100, Validation Loss: 0.422566813326651\n",
      "Epoch 8/100, Training Loss: 0.37110593323765495\n",
      "Epoch 8/100, Validation Loss: 0.4259588908283941\n",
      "Epoch 9/100, Training Loss: 0.3590241489019471\n",
      "Epoch 9/100, Validation Loss: 0.44586468319739064\n",
      "Epoch 10/100, Training Loss: 0.35897454227271836\n",
      "Epoch 10/100, Validation Loss: 0.38321185760921045\n",
      "Epoch 11/100, Training Loss: 0.3391001632942362\n",
      "Epoch 11/100, Validation Loss: 0.4131985905189668\n",
      "Epoch 12/100, Training Loss: 0.33159688549485766\n",
      "Epoch 12/100, Validation Loss: 0.38973688550533786\n",
      "Epoch 13/100, Training Loss: 0.3135882675768393\n",
      "Epoch 13/100, Validation Loss: 0.3666338954241045\n",
      "Epoch 14/100, Training Loss: 0.2986126021455657\n",
      "Epoch 14/100, Validation Loss: 0.3772487512999965\n",
      "Epoch 15/100, Training Loss: 0.3016984730596967\n",
      "Epoch 15/100, Validation Loss: 0.3721449579442701\n",
      "Epoch 16/100, Training Loss: 0.2914319416651359\n",
      "Epoch 16/100, Validation Loss: 0.3961979484846515\n",
      "Epoch 17/100, Training Loss: 0.2800588681388963\n",
      "Epoch 17/100, Validation Loss: 0.36954305393080555\n",
      "Epoch 18/100, Training Loss: 0.2677745153667473\n",
      "Epoch 18/100, Validation Loss: 0.39288582845080283\n",
      "Early stopping triggered\n",
      "Total training time: 40.72 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93c7c0f0-0218-41de-a981-8b2f42ec69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.81331\n",
      "p_offset: 0.80728\n",
      "t_onset: 0.84854\n",
      "t_offset: 0.81258\n",
      "qrs_onset: 0.97094\n",
      "qrs_offset: 0.96905\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcaa6b-aecc-490e-ad79-65d61d439b57",
   "metadata": {},
   "source": [
    "Как и ожидалось, еще большее увеличение глубины сети не привело к значимым изменениям результатов. Причин этому может быть множество: \n",
    "\n",
    "\n",
    "**Переобучение**: Более глубокая модель может быть более склонна к переобучению на данных обучения, особенно если обучающий набор данных невелик. Проверка на переобучение может помочь выявить проблему.  \n",
    "**Недостаточно данных:** Глубокие модели обычно требуют большого количества данных для эффективного обучения. Если данных недостаточно, модель не сможет учиться на всех уровнях глубины.  \n",
    "**Избыточная сложность:** Глубокие сети могут стать слишком сложными для задачи, в результате чего они не могут правильно учить необходимые признаки.\n",
    "Проблемы с обучением: Увеличение глубины может затруднить обучение, приводя к затуханию градиентов или другим проблемам. Добавление слоев нормализации, изменения функции активации или уменьшение шага обучения может улучшить стабильность.  \n",
    "**Время тренировки:** Более глубокая модель может потребовать больше времени для конвергенции. Возможно, стоит увеличить количество эпох или проверить кривые обучения, чтобы понять, достигается ли стабильная точка.  \n",
    "\n",
    "**Поэтому есть смысл вернуться к предыдущей версии и продолжить работу над ней.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a638578-db14-4103-830a-f097bccdf25d",
   "metadata": {},
   "source": [
    "#### 1.4.12. Разработка DeepLabV3Plus1D с применением регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14afbc-6bb6-4362-bf31-3b76acd7a895",
   "metadata": {},
   "source": [
    "В коде модели ниже попробуем применить алгоритм регуляризации. Чтобы избежать переобучения, добавим слой Dropout в декодер. Это помогает случайно отключать некоторые нейроны во время тренировки, что повышает обобщающую способность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3ee830da-3d40-45ad-801f-2a6568389181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      "            Conv1d-4            [-1, 128, 1250]          24,704\n",
      "       BatchNorm1d-5            [-1, 128, 1250]             256\n",
      "              ReLU-6            [-1, 128, 1250]               0\n",
      "            Conv1d-7             [-1, 256, 625]          98,560\n",
      "       BatchNorm1d-8             [-1, 256, 625]             512\n",
      "              ReLU-9             [-1, 256, 625]               0\n",
      "        MaxPool1d-10             [-1, 256, 313]               0\n",
      "           Conv1d-11             [-1, 512, 313]         131,584\n",
      "           Conv1d-12             [-1, 512, 313]         393,728\n",
      "           Conv1d-13             [-1, 512, 313]         393,728\n",
      "           Conv1d-14             [-1, 512, 313]         393,728\n",
      "           Conv1d-15             [-1, 512, 313]         393,728\n",
      "      BatchNorm1d-16            [-1, 2560, 313]           5,120\n",
      "             ReLU-17            [-1, 2560, 313]               0\n",
      "           Conv1d-18             [-1, 512, 313]       1,311,232\n",
      "             ASPP-19             [-1, 512, 313]               0\n",
      "           Conv1d-20            [-1, 256, 5000]         393,472\n",
      "      BatchNorm1d-21            [-1, 256, 5000]             512\n",
      "             ReLU-22            [-1, 256, 5000]               0\n",
      "          Dropout-23            [-1, 256, 5000]               0\n",
      "           Conv1d-24              [-1, 4, 5000]           1,028\n",
      "================================================================\n",
      "Total params: 3,547,460\n",
      "Trainable params: 3,547,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 71.60\n",
      "Params size (MB): 13.53\n",
      "Estimated Total Size (MB): 85.36\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0102856 seconds\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DWithDropout(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DWithDropout, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DWithDropout(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8783872c-3071-4b01-a2a3-b4c447aa33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.53006110439899\n",
      "Epoch 1/100, Validation Loss: 0.4340935371095134\n",
      "Epoch 2/100, Training Loss: 0.4258193755560076\n",
      "Epoch 2/100, Validation Loss: 0.3860023692250252\n",
      "Epoch 3/100, Training Loss: 0.4031854707461137\n",
      "Epoch 3/100, Validation Loss: 0.38159913040937915\n",
      "Epoch 4/100, Training Loss: 0.3722906313565096\n",
      "Epoch 4/100, Validation Loss: 0.3569611546493346\n",
      "Epoch 5/100, Training Loss: 0.3569397037087182\n",
      "Epoch 5/100, Validation Loss: 0.3631174528310376\n",
      "Epoch 6/100, Training Loss: 0.34303156132640145\n",
      "Epoch 6/100, Validation Loss: 0.34925683083072784\n",
      "Epoch 7/100, Training Loss: 0.3255565016858491\n",
      "Epoch 7/100, Validation Loss: 0.3331419553968214\n",
      "Epoch 8/100, Training Loss: 0.317421373145783\n",
      "Epoch 8/100, Validation Loss: 0.33126230802266826\n",
      "Epoch 9/100, Training Loss: 0.31413802130502244\n",
      "Epoch 9/100, Validation Loss: 0.32283227674422726\n",
      "Epoch 10/100, Training Loss: 0.2992820635980923\n",
      "Epoch 10/100, Validation Loss: 0.34574528471116095\n",
      "Epoch 11/100, Training Loss: 0.293887034179228\n",
      "Epoch 11/100, Validation Loss: 0.3255623980395256\n",
      "Epoch 12/100, Training Loss: 0.28643486561321535\n",
      "Epoch 12/100, Validation Loss: 0.32006534861941494\n",
      "Epoch 13/100, Training Loss: 0.28451963698091776\n",
      "Epoch 13/100, Validation Loss: 0.3284849827328036\n",
      "Epoch 14/100, Training Loss: 0.2744013238170369\n",
      "Epoch 14/100, Validation Loss: 0.3335878798557866\n",
      "Epoch 15/100, Training Loss: 0.2665213303648026\n",
      "Epoch 15/100, Validation Loss: 0.32432683485169567\n",
      "Epoch 16/100, Training Loss: 0.2580137263666763\n",
      "Epoch 16/100, Validation Loss: 0.33327586828700956\n",
      "Epoch 17/100, Training Loss: 0.25380116429647454\n",
      "Epoch 17/100, Validation Loss: 0.3123618905102053\n",
      "Epoch 18/100, Training Loss: 0.24828319384260217\n",
      "Epoch 18/100, Validation Loss: 0.3229533991506023\n",
      "Epoch 19/100, Training Loss: 0.24064821939960665\n",
      "Epoch 19/100, Validation Loss: 0.3306046219602708\n",
      "Epoch 20/100, Training Loss: 0.23611775824898168\n",
      "Epoch 20/100, Validation Loss: 0.34036362243275486\n",
      "Epoch 21/100, Training Loss: 0.23057149652286096\n",
      "Epoch 21/100, Validation Loss: 0.34080458552606646\n",
      "Epoch 22/100, Training Loss: 0.2263260133835951\n",
      "Epoch 22/100, Validation Loss: 0.32197205265683515\n",
      "Early stopping triggered\n",
      "Total training time: 37.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f98e8945-2dc3-4b71-b07f-a010eb45c549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.79081\n",
      "p_offset: 0.80331\n",
      "t_onset: 0.85832\n",
      "t_offset: 0.8767\n",
      "qrs_onset: 0.9672\n",
      "qrs_offset: 0.96742\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9c631-fd7e-4189-98d2-65d484ecbb8d",
   "metadata": {},
   "source": [
    "Можно сказать, что при применении Dropout метрики несколько ухудшились, возможно, это произошло по одной из нескольких причин:  \n",
    "\n",
    "**1. Недостаточное количество данных:** Если тренировочный набор данных невелик, использование Dropout может привести к потере важных признаков, необходимых для обобщения. Это особенно заметно, когда Dropout слишком высок или применяется к большим слоям.  \n",
    "**2. Слишком высокое значение Dropout:** Если коэффициент Dropout слишком высок, модель может потерять слишком много нейронов в процессе тренировки, что приведет к недостаточной производительности.  \n",
    "**3. Изменения в структуре нейронной сети:** При использовании Dropout меняется структура нейронной сети, так как случайным образом отключаются нейроны. Если отключенные нейроны несут существенную информацию, модель не сможет должным образом обучиться на ограниченном наборе данных.  \n",
    "**4. Недостаточное время тренировки:** Dropout обычно требует большего времени для тренировки, чтобы модель могла обобщить признаки из данных. Если модель обучается недостаточно долго, она может не достичь своего полного потенциала.  \n",
    "**Чтобы минимизировать негативный эффект от Dropout, можно использовать более низкие значения коэффициента (например, 0.2 - 0.3) или применять его только к верхним слоям сети.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf857-7368-464d-b79d-01625108e8a9",
   "metadata": {},
   "source": [
    "#### 1.4.13. Разработка DeepLabV3Plus1D с применением регуляризации на верхнем слое."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb473ff2-fabf-4f41-b73b-b142893e72c4",
   "metadata": {},
   "source": [
    "В данном коде происходят эксперименты с различным местоположением Dropout, а также со значением регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db7d8cec-690d-489c-a673-4ae0e831fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      "            Conv1d-4            [-1, 128, 1250]          24,704\n",
      "       BatchNorm1d-5            [-1, 128, 1250]             256\n",
      "              ReLU-6            [-1, 128, 1250]               0\n",
      "            Conv1d-7             [-1, 256, 625]          98,560\n",
      "       BatchNorm1d-8             [-1, 256, 625]             512\n",
      "           Dropout-9             [-1, 256, 625]               0\n",
      "             ReLU-10             [-1, 256, 625]               0\n",
      "        MaxPool1d-11             [-1, 256, 313]               0\n",
      "           Conv1d-12             [-1, 512, 313]         131,584\n",
      "           Conv1d-13             [-1, 512, 313]         393,728\n",
      "           Conv1d-14             [-1, 512, 313]         393,728\n",
      "           Conv1d-15             [-1, 512, 313]         393,728\n",
      "           Conv1d-16             [-1, 512, 313]         393,728\n",
      "      BatchNorm1d-17            [-1, 2560, 313]           5,120\n",
      "             ReLU-18            [-1, 2560, 313]               0\n",
      "           Conv1d-19             [-1, 512, 313]       1,311,232\n",
      "             ASPP-20             [-1, 512, 313]               0\n",
      "           Conv1d-21            [-1, 256, 5000]         393,472\n",
      "      BatchNorm1d-22            [-1, 256, 5000]             512\n",
      "             ReLU-23            [-1, 256, 5000]               0\n",
      "           Conv1d-24              [-1, 4, 5000]           1,028\n",
      "================================================================\n",
      "Total params: 3,547,460\n",
      "Trainable params: 3,547,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 63.05\n",
      "Params size (MB): 13.53\n",
      "Estimated Total Size (MB): 76.81\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0029194 seconds\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DWithDropoutExp(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DWithDropoutExp, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DWithDropoutExp(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6313ff0-21b7-4bab-a245-850c71bd2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.5285123973964196\n",
      "Epoch 1/100, Validation Loss: 0.6558572943172147\n",
      "Epoch 2/100, Training Loss: 0.43930810364151773\n",
      "Epoch 2/100, Validation Loss: 0.5889199900050317\n",
      "Epoch 3/100, Training Loss: 0.4013990869044292\n",
      "Epoch 3/100, Validation Loss: 0.47950321411894214\n",
      "Epoch 4/100, Training Loss: 0.37285867080032103\n",
      "Epoch 4/100, Validation Loss: 0.5076951019225582\n",
      "Epoch 5/100, Training Loss: 0.3550661480137211\n",
      "Epoch 5/100, Validation Loss: 0.4063737820233068\n",
      "Epoch 6/100, Training Loss: 0.33606404011790086\n",
      "Epoch 6/100, Validation Loss: 0.41577624577668404\n",
      "Epoch 7/100, Training Loss: 0.3270542743476296\n",
      "Epoch 7/100, Validation Loss: 0.4882594544079996\n",
      "Epoch 8/100, Training Loss: 0.31885483064632186\n",
      "Epoch 8/100, Validation Loss: 0.5237049325819938\n",
      "Epoch 9/100, Training Loss: 0.31088985629409915\n",
      "Epoch 9/100, Validation Loss: 0.41509241009912184\n",
      "Epoch 10/100, Training Loss: 0.2985209736988129\n",
      "Epoch 10/100, Validation Loss: 0.38636242982841307\n",
      "Epoch 11/100, Training Loss: 0.291855070996381\n",
      "Epoch 11/100, Validation Loss: 0.4314045937311265\n",
      "Epoch 12/100, Training Loss: 0.2827940817907272\n",
      "Epoch 12/100, Validation Loss: 0.43743703105757314\n",
      "Epoch 13/100, Training Loss: 0.27937226498175244\n",
      "Epoch 13/100, Validation Loss: 0.36460584113674777\n",
      "Epoch 14/100, Training Loss: 0.2728213967099363\n",
      "Epoch 14/100, Validation Loss: 0.45243503874348057\n",
      "Epoch 15/100, Training Loss: 0.2636631537786862\n",
      "Epoch 15/100, Validation Loss: 0.3556580432961064\n",
      "Epoch 16/100, Training Loss: 0.2593091665371227\n",
      "Epoch 16/100, Validation Loss: 0.3880888918234456\n",
      "Epoch 17/100, Training Loss: 0.2551393853387369\n",
      "Epoch 17/100, Validation Loss: 0.3610592482070769\n",
      "Epoch 18/100, Training Loss: 0.2513016005035354\n",
      "Epoch 18/100, Validation Loss: 0.38555825982362996\n",
      "Epoch 19/100, Training Loss: 0.2458703791805607\n",
      "Epoch 19/100, Validation Loss: 0.3858904802510815\n",
      "Epoch 20/100, Training Loss: 0.2368283915495583\n",
      "Epoch 20/100, Validation Loss: 0.3874459156105595\n",
      "Early stopping triggered\n",
      "Total training time: 37.39 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06d17f6d-1c1a-4a8a-bf7c-e9455cc383b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.76676\n",
      "p_offset: 0.77096\n",
      "t_onset: 0.78253\n",
      "t_offset: 0.80585\n",
      "qrs_onset: 0.96779\n",
      "qrs_offset: 0.9713\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991226df-facb-4018-adbf-092f2b8ead85",
   "metadata": {},
   "source": [
    "После различных экспериментов с местоположением Dropout и значением коэффициента регуляризации, так и не получилось найти оптимальные значения для Dropout, чтобы повысить точность сегментации. Давайте аналогично с SegNet попробуем применить механизм внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e617e1-57cb-4a97-b3cc-002688641bd8",
   "metadata": {},
   "source": [
    "#### 1.4.14. Разработка DeepLabV3Plus1D с применением механизма внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08432f32-4705-46a8-a2c9-4284b98292af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 2500]           5,440\n",
      "       BatchNorm1d-2             [-1, 64, 2500]             128\n",
      "              ReLU-3             [-1, 64, 2500]               0\n",
      " AdaptiveAvgPool1d-4                [-1, 64, 1]               0\n",
      "            Linear-5                    [-1, 4]             260\n",
      "              ReLU-6                    [-1, 4]               0\n",
      "            Linear-7                   [-1, 64]             320\n",
      "           Sigmoid-8                   [-1, 64]               0\n",
      "  ChannelAttention-9             [-1, 64, 2500]               0\n",
      "           Conv1d-10            [-1, 128, 1250]          24,704\n",
      "      BatchNorm1d-11            [-1, 128, 1250]             256\n",
      "             ReLU-12            [-1, 128, 1250]               0\n",
      "AdaptiveAvgPool1d-13               [-1, 128, 1]               0\n",
      "           Linear-14                    [-1, 8]           1,032\n",
      "             ReLU-15                    [-1, 8]               0\n",
      "           Linear-16                  [-1, 128]           1,152\n",
      "          Sigmoid-17                  [-1, 128]               0\n",
      " ChannelAttention-18            [-1, 128, 1250]               0\n",
      "           Conv1d-19             [-1, 256, 625]          98,560\n",
      "      BatchNorm1d-20             [-1, 256, 625]             512\n",
      "             ReLU-21             [-1, 256, 625]               0\n",
      "AdaptiveAvgPool1d-22               [-1, 256, 1]               0\n",
      "           Linear-23                   [-1, 16]           4,112\n",
      "             ReLU-24                   [-1, 16]               0\n",
      "           Linear-25                  [-1, 256]           4,352\n",
      "          Sigmoid-26                  [-1, 256]               0\n",
      " ChannelAttention-27             [-1, 256, 625]               0\n",
      "        MaxPool1d-28             [-1, 256, 313]               0\n",
      "           Conv1d-29             [-1, 512, 313]         131,584\n",
      "           Conv1d-30             [-1, 512, 313]         393,728\n",
      "           Conv1d-31             [-1, 512, 313]         393,728\n",
      "           Conv1d-32             [-1, 512, 313]         393,728\n",
      "           Conv1d-33             [-1, 512, 313]         393,728\n",
      "      BatchNorm1d-34            [-1, 2560, 313]           5,120\n",
      "             ReLU-35            [-1, 2560, 313]               0\n",
      "           Conv1d-36             [-1, 512, 313]       1,311,232\n",
      "             ASPP-37             [-1, 512, 313]               0\n",
      "           Conv1d-38            [-1, 256, 5000]         393,472\n",
      "      BatchNorm1d-39            [-1, 256, 5000]             512\n",
      "             ReLU-40            [-1, 256, 5000]               0\n",
      "AdaptiveAvgPool1d-41               [-1, 256, 1]               0\n",
      "           Linear-42                   [-1, 16]           4,112\n",
      "             ReLU-43                   [-1, 16]               0\n",
      "           Linear-44                  [-1, 256]           4,352\n",
      "          Sigmoid-45                  [-1, 256]               0\n",
      " ChannelAttention-46            [-1, 256, 5000]               0\n",
      "           Conv1d-47              [-1, 4, 5000]           1,028\n",
      "================================================================\n",
      "Total params: 3,567,152\n",
      "Trainable params: 3,567,152\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 75.28\n",
      "Params size (MB): 13.61\n",
      "Estimated Total Size (MB): 89.11\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0040028 seconds\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# Внедрение модуля внимания в DeepLabV3+ модель\n",
    "class DeepLabV3Plus1DAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DAttention, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(64),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(128),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(256),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(256),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DAttention(input_channels, output_channels).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4f357d4-282a-41ce-a673-b9d494c74706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.5320406375143693\n",
      "Epoch 1/100, Validation Loss: 0.4646386006666768\n",
      "Epoch 2/100, Training Loss: 0.4234491075098756\n",
      "Epoch 2/100, Validation Loss: 0.3940226284246291\n",
      "Epoch 3/100, Training Loss: 0.38760898446264536\n",
      "Epoch 3/100, Validation Loss: 0.3637659506451699\n",
      "Epoch 4/100, Training Loss: 0.36316211581954105\n",
      "Epoch 4/100, Validation Loss: 0.35069506663468575\n",
      "Epoch 5/100, Training Loss: 0.3435924369917225\n",
      "Epoch 5/100, Validation Loss: 0.34631468716167635\n",
      "Epoch 6/100, Training Loss: 0.3275068492783226\n",
      "Epoch 6/100, Validation Loss: 0.3492160843264672\n",
      "Epoch 7/100, Training Loss: 0.3216397760488726\n",
      "Epoch 7/100, Validation Loss: 0.32918623642575356\n",
      "Epoch 8/100, Training Loss: 0.30645883101442084\n",
      "Epoch 8/100, Validation Loss: 0.33839528935570873\n",
      "Epoch 9/100, Training Loss: 0.30072053935122395\n",
      "Epoch 9/100, Validation Loss: 0.35171766627219414\n",
      "Epoch 10/100, Training Loss: 0.2934646753043781\n",
      "Epoch 10/100, Validation Loss: 0.32876879361367994\n",
      "Epoch 11/100, Training Loss: 0.2815051145157833\n",
      "Epoch 11/100, Validation Loss: 0.30566629454974203\n",
      "Epoch 12/100, Training Loss: 0.2731434527920325\n",
      "Epoch 12/100, Validation Loss: 0.3215605239233663\n",
      "Epoch 13/100, Training Loss: 0.26611183052844845\n",
      "Epoch 13/100, Validation Loss: 0.3218415182444357\n",
      "Epoch 14/100, Training Loss: 0.25659993007356824\n",
      "Epoch 14/100, Validation Loss: 0.3078893586512535\n",
      "Epoch 15/100, Training Loss: 0.2505020251278935\n",
      "Epoch 15/100, Validation Loss: 0.3183942134341886\n",
      "Epoch 16/100, Training Loss: 0.2443860455864837\n",
      "Epoch 16/100, Validation Loss: 0.3225849378974207\n",
      "Early stopping triggered\n",
      "Total training time: 37.17 seconds\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "37743e08-a192-4fd8-a493-80728c195caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.79394\n",
      "p_offset: 0.80754\n",
      "t_onset: 0.83066\n",
      "t_offset: 0.86519\n",
      "qrs_onset: 0.96924\n",
      "qrs_offset: 0.9686\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea2290-7013-445c-b49c-75193c1f60bd",
   "metadata": {},
   "source": [
    "Механзим внимания к DeepLabV3 не дал ожидаемых результатов, поэтому есть смысл запомнить модель из раздела DeepLab с названием DeepLabV3Plus1DDeeper для дальнейших экспериментов, так как эта модель показала неплохие результаты на данный момент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b610c-e779-45b7-a627-9f916cfc938f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad5084-c0d7-4397-b8d3-fd1d7e461018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f070916-9591-431c-ab9e-b8b4b761bb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fdc18-a394-4e3a-a3e7-22d48667f83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576f682-a7f3-416c-a21f-e5127ee45ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d87ff2-e585-41b7-8454-6998223ce550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b493c1-d82b-4619-937a-2b52099a1a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e69656-6c04-4c08-a0d1-91f6f8560061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c52fbc-a31c-4335-9159-88dd84ecf8ef",
   "metadata": {},
   "source": [
    "### 1.5 Анализ UNet от ученых ННГУ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d2f0-60c6-4118-8e05-26f477d6463e",
   "metadata": {},
   "source": [
    "Объявим модель, которую разработали ученые ННГУ и проверим точность на ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c933f9b9-1037-4358-80b4-e65597748c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ks, p):\n",
    "        in_channels = int(in_channels)\n",
    "        out_channels = int(out_channels)\n",
    "        super(UNetConv, self).__init__()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=ks, padding=ks//2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(p=p),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=ks, padding=ks//2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self._model(X)\n",
    "    \n",
    "    \n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ks, p):\n",
    "        super(UNetDown, self).__init__()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            UNetConv(in_channels, out_channels, ks, p)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self._model(X)\n",
    "    \n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, in_channels_skip, out_channels, ks, p):\n",
    "        super(UNetUp, self).__init__()\n",
    "        in_channels = int(in_channels)\n",
    "        in_channels_skip = int(in_channels_skip)\n",
    "        out_channels = int(out_channels)\n",
    "        \n",
    "        self._up = nn.ConvTranspose1d(in_channels, in_channels, \n",
    "                                      kernel_size=ks - 1,\n",
    "                                      stride=2, \n",
    "                                      padding=(ks - 1) // 2 - 1)\n",
    "        self._model = UNetConv(in_channels + in_channels_skip, out_channels, ks, p)\n",
    "    \n",
    "    def forward(self, X_skip, X):\n",
    "        X = self._up(X)  \n",
    "        diff = X_skip.size()[2] - X.size()[2]\n",
    "        X = F.pad(X, (diff // 2, diff - diff // 2))  \n",
    "        return self._model(torch.cat([X_skip, X], dim=1))\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, channels_coeff=1, q=2, kernel_size=23, p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.q = q\n",
    "        self.p = p\n",
    "        self._input = UNetConv(q ** 0 * self.in_channels, q ** 1 * in_channels, kernel_size, p)\n",
    "        self._down1 = UNetDown(q ** 1 * self.in_channels, q ** 2 * self.in_channels, kernel_size, p)\n",
    "        self._down2 = UNetDown(q ** 2 * self.in_channels, q ** 3 * self.in_channels, kernel_size, p)\n",
    "        self._down3 = UNetDown(q ** 3 * self.in_channels, q ** 4 * self.in_channels, kernel_size, p)\n",
    "        self._down4 = UNetDown(q ** 4 * self.in_channels, q ** 5 * self.in_channels, kernel_size, p)\n",
    "        self._down5 = UNetDown(q ** 5 * self.in_channels, q ** 6 * self.in_channels, kernel_size, p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self._input(x)\n",
    "        x2 = self._down1(x1)\n",
    "        x3 = self._down2(x2)\n",
    "        x4 = self._down3(x3)\n",
    "        x5 = self._down4(x4)\n",
    "        return x1, x2, x3, x4, x5, self._down5(x5)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, num_classes, reshape=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self._up1 = UNetUp(encoder.q ** 6 * encoder.in_channels, \n",
    "                           encoder.q ** 5 *encoder.in_channels, \n",
    "                           encoder.q ** 5 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "\n",
    "        self._up2 = UNetUp(encoder.q ** 5 * encoder.in_channels, \n",
    "                           encoder.q ** 4 *encoder.in_channels, \n",
    "                           encoder.q ** 4 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._up3 = UNetUp(encoder.q ** 4 * encoder.in_channels, \n",
    "                           encoder.q ** 3 *encoder.in_channels, \n",
    "                           encoder.q ** 3 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._up4 = UNetUp(encoder.q ** 3 * encoder.in_channels, \n",
    "                           encoder.q ** 2 *encoder.in_channels,\n",
    "                           encoder.q ** 2 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "\n",
    "        self._up5 = UNetUp(encoder.q ** 2 * encoder.in_channels, \n",
    "                           encoder.q ** 1 *encoder.in_channels,\n",
    "                           num_classes,\n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._output = nn.Conv1d(num_classes, num_classes, kernel_size=1)\n",
    "        self.reshape = reshape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4, x5, x):\n",
    "        batch_size = len(x)\n",
    "        x = self._up1(x5, x)\n",
    "        x = self._up2(x4, x)\n",
    "        x = self._up3(x3, x)\n",
    "        x = self._up4(x2, x)\n",
    "        x = self._up5(x1, x)\n",
    "        x = self._output(x)\n",
    "        if self.reshape:\n",
    "            x = x.reshape(batch_size, 4, 12, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetNNGU(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super(UNetNNGU, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5, x = self.encoder(x) \n",
    "        a = self.decoder(x1, x2, x3, x4, x5, x)\n",
    "        return a\n",
    "    \n",
    "    def log(self):\n",
    "        return f\"UNet(in_channels={self.encoder.in_channels}, num_classes={self.decoder.num_classes}, \" \\\n",
    "                    f\"q={self.encoder.q}, reshape={self.decoder.reshape}, kernel_size={self.encoder.kernel_size})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "27e8109a-a873-4216-9dba-f3fc063e9ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 14, 5000]           3,878\n",
      "            Conv1d-2             [-1, 14, 5000]           3,878\n",
      "       BatchNorm1d-3             [-1, 14, 5000]              28\n",
      "       BatchNorm1d-4             [-1, 14, 5000]              28\n",
      "              ReLU-5             [-1, 14, 5000]               0\n",
      "              ReLU-6             [-1, 14, 5000]               0\n",
      "         Dropout1d-7             [-1, 14, 5000]               0\n",
      "         Dropout1d-8             [-1, 14, 5000]               0\n",
      "            Conv1d-9             [-1, 14, 5000]           4,522\n",
      "           Conv1d-10             [-1, 14, 5000]           4,522\n",
      "      BatchNorm1d-11             [-1, 14, 5000]              28\n",
      "      BatchNorm1d-12             [-1, 14, 5000]              28\n",
      "             ReLU-13             [-1, 14, 5000]               0\n",
      "             ReLU-14             [-1, 14, 5000]               0\n",
      "         UNetConv-15             [-1, 14, 5000]               0\n",
      "         UNetConv-16             [-1, 14, 5000]               0\n",
      "        MaxPool1d-17             [-1, 14, 2500]               0\n",
      "        MaxPool1d-18             [-1, 14, 2500]               0\n",
      "           Conv1d-19             [-1, 17, 2500]           5,491\n",
      "           Conv1d-20             [-1, 17, 2500]           5,491\n",
      "      BatchNorm1d-21             [-1, 17, 2500]              34\n",
      "      BatchNorm1d-22             [-1, 17, 2500]              34\n",
      "             ReLU-23             [-1, 17, 2500]               0\n",
      "             ReLU-24             [-1, 17, 2500]               0\n",
      "        Dropout1d-25             [-1, 17, 2500]               0\n",
      "        Dropout1d-26             [-1, 17, 2500]               0\n",
      "           Conv1d-27             [-1, 17, 2500]           6,664\n",
      "           Conv1d-28             [-1, 17, 2500]           6,664\n",
      "      BatchNorm1d-29             [-1, 17, 2500]              34\n",
      "      BatchNorm1d-30             [-1, 17, 2500]              34\n",
      "             ReLU-31             [-1, 17, 2500]               0\n",
      "             ReLU-32             [-1, 17, 2500]               0\n",
      "         UNetConv-33             [-1, 17, 2500]               0\n",
      "         UNetConv-34             [-1, 17, 2500]               0\n",
      "         UNetDown-35             [-1, 17, 2500]               0\n",
      "         UNetDown-36             [-1, 17, 2500]               0\n",
      "        MaxPool1d-37             [-1, 17, 1250]               0\n",
      "        MaxPool1d-38             [-1, 17, 1250]               0\n",
      "           Conv1d-39             [-1, 20, 1250]           7,840\n",
      "           Conv1d-40             [-1, 20, 1250]           7,840\n",
      "      BatchNorm1d-41             [-1, 20, 1250]              40\n",
      "      BatchNorm1d-42             [-1, 20, 1250]              40\n",
      "             ReLU-43             [-1, 20, 1250]               0\n",
      "             ReLU-44             [-1, 20, 1250]               0\n",
      "        Dropout1d-45             [-1, 20, 1250]               0\n",
      "        Dropout1d-46             [-1, 20, 1250]               0\n",
      "           Conv1d-47             [-1, 20, 1250]           9,220\n",
      "           Conv1d-48             [-1, 20, 1250]           9,220\n",
      "      BatchNorm1d-49             [-1, 20, 1250]              40\n",
      "      BatchNorm1d-50             [-1, 20, 1250]              40\n",
      "             ReLU-51             [-1, 20, 1250]               0\n",
      "             ReLU-52             [-1, 20, 1250]               0\n",
      "         UNetConv-53             [-1, 20, 1250]               0\n",
      "         UNetConv-54             [-1, 20, 1250]               0\n",
      "         UNetDown-55             [-1, 20, 1250]               0\n",
      "         UNetDown-56             [-1, 20, 1250]               0\n",
      "        MaxPool1d-57              [-1, 20, 625]               0\n",
      "        MaxPool1d-58              [-1, 20, 625]               0\n",
      "           Conv1d-59              [-1, 24, 625]          11,064\n",
      "           Conv1d-60              [-1, 24, 625]          11,064\n",
      "      BatchNorm1d-61              [-1, 24, 625]              48\n",
      "      BatchNorm1d-62              [-1, 24, 625]              48\n",
      "             ReLU-63              [-1, 24, 625]               0\n",
      "             ReLU-64              [-1, 24, 625]               0\n",
      "        Dropout1d-65              [-1, 24, 625]               0\n",
      "        Dropout1d-66              [-1, 24, 625]               0\n",
      "           Conv1d-67              [-1, 24, 625]          13,272\n",
      "           Conv1d-68              [-1, 24, 625]          13,272\n",
      "      BatchNorm1d-69              [-1, 24, 625]              48\n",
      "      BatchNorm1d-70              [-1, 24, 625]              48\n",
      "             ReLU-71              [-1, 24, 625]               0\n",
      "             ReLU-72              [-1, 24, 625]               0\n",
      "         UNetConv-73              [-1, 24, 625]               0\n",
      "         UNetConv-74              [-1, 24, 625]               0\n",
      "         UNetDown-75              [-1, 24, 625]               0\n",
      "         UNetDown-76              [-1, 24, 625]               0\n",
      "        MaxPool1d-77              [-1, 24, 312]               0\n",
      "        MaxPool1d-78              [-1, 24, 312]               0\n",
      "           Conv1d-79              [-1, 29, 312]          16,037\n",
      "           Conv1d-80              [-1, 29, 312]          16,037\n",
      "      BatchNorm1d-81              [-1, 29, 312]              58\n",
      "      BatchNorm1d-82              [-1, 29, 312]              58\n",
      "             ReLU-83              [-1, 29, 312]               0\n",
      "             ReLU-84              [-1, 29, 312]               0\n",
      "        Dropout1d-85              [-1, 29, 312]               0\n",
      "        Dropout1d-86              [-1, 29, 312]               0\n",
      "           Conv1d-87              [-1, 29, 312]          19,372\n",
      "           Conv1d-88              [-1, 29, 312]          19,372\n",
      "      BatchNorm1d-89              [-1, 29, 312]              58\n",
      "      BatchNorm1d-90              [-1, 29, 312]              58\n",
      "             ReLU-91              [-1, 29, 312]               0\n",
      "             ReLU-92              [-1, 29, 312]               0\n",
      "         UNetConv-93              [-1, 29, 312]               0\n",
      "         UNetConv-94              [-1, 29, 312]               0\n",
      "         UNetDown-95              [-1, 29, 312]               0\n",
      "         UNetDown-96              [-1, 29, 312]               0\n",
      "        MaxPool1d-97              [-1, 29, 156]               0\n",
      "        MaxPool1d-98              [-1, 29, 156]               0\n",
      "           Conv1d-99              [-1, 35, 156]          23,380\n",
      "          Conv1d-100              [-1, 35, 156]          23,380\n",
      "     BatchNorm1d-101              [-1, 35, 156]              70\n",
      "     BatchNorm1d-102              [-1, 35, 156]              70\n",
      "            ReLU-103              [-1, 35, 156]               0\n",
      "            ReLU-104              [-1, 35, 156]               0\n",
      "       Dropout1d-105              [-1, 35, 156]               0\n",
      "       Dropout1d-106              [-1, 35, 156]               0\n",
      "          Conv1d-107              [-1, 35, 156]          28,210\n",
      "          Conv1d-108              [-1, 35, 156]          28,210\n",
      "     BatchNorm1d-109              [-1, 35, 156]              70\n",
      "     BatchNorm1d-110              [-1, 35, 156]              70\n",
      "            ReLU-111              [-1, 35, 156]               0\n",
      "            ReLU-112              [-1, 35, 156]               0\n",
      "        UNetConv-113              [-1, 35, 156]               0\n",
      "        UNetConv-114              [-1, 35, 156]               0\n",
      "        UNetDown-115              [-1, 35, 156]               0\n",
      "        UNetDown-116              [-1, 35, 156]               0\n",
      "         Encoder-117  [[-1, 14, 5000], [-1, 17, 2500], [-1, 20, 1250], [-1, 24, 625], [-1, 29, 312], [-1, 35, 156]]               0\n",
      "         Encoder-118  [[-1, 14, 5000], [-1, 17, 2500], [-1, 20, 1250], [-1, 24, 625], [-1, 29, 312], [-1, 35, 156]]               0\n",
      " ConvTranspose1d-119              [-1, 35, 312]          26,985\n",
      "          Conv1d-120              [-1, 29, 312]          42,717\n",
      "     BatchNorm1d-121              [-1, 29, 312]              58\n",
      "            ReLU-122              [-1, 29, 312]               0\n",
      "       Dropout1d-123              [-1, 29, 312]               0\n",
      "          Conv1d-124              [-1, 29, 312]          19,372\n",
      "     BatchNorm1d-125              [-1, 29, 312]              58\n",
      "            ReLU-126              [-1, 29, 312]               0\n",
      "        UNetConv-127              [-1, 29, 312]               0\n",
      "          UNetUp-128              [-1, 29, 312]               0\n",
      " ConvTranspose1d-129              [-1, 29, 624]          18,531\n",
      "          Conv1d-130              [-1, 24, 625]          29,280\n",
      "     BatchNorm1d-131              [-1, 24, 625]              48\n",
      "            ReLU-132              [-1, 24, 625]               0\n",
      "       Dropout1d-133              [-1, 24, 625]               0\n",
      "          Conv1d-134              [-1, 24, 625]          13,272\n",
      "     BatchNorm1d-135              [-1, 24, 625]              48\n",
      "            ReLU-136              [-1, 24, 625]               0\n",
      "        UNetConv-137              [-1, 24, 625]               0\n",
      "          UNetUp-138              [-1, 24, 625]               0\n",
      " ConvTranspose1d-139             [-1, 24, 1250]          12,696\n",
      "          Conv1d-140             [-1, 20, 1250]          20,260\n",
      "     BatchNorm1d-141             [-1, 20, 1250]              40\n",
      "            ReLU-142             [-1, 20, 1250]               0\n",
      "       Dropout1d-143             [-1, 20, 1250]               0\n",
      "          Conv1d-144             [-1, 20, 1250]           9,220\n",
      "     BatchNorm1d-145             [-1, 20, 1250]              40\n",
      "            ReLU-146             [-1, 20, 1250]               0\n",
      "        UNetConv-147             [-1, 20, 1250]               0\n",
      "          UNetUp-148             [-1, 20, 1250]               0\n",
      " ConvTranspose1d-149             [-1, 20, 2500]           8,820\n",
      "          Conv1d-150             [-1, 17, 2500]          14,484\n",
      "     BatchNorm1d-151             [-1, 17, 2500]              34\n",
      "            ReLU-152             [-1, 17, 2500]               0\n",
      "       Dropout1d-153             [-1, 17, 2500]               0\n",
      "          Conv1d-154             [-1, 17, 2500]           6,664\n",
      "     BatchNorm1d-155             [-1, 17, 2500]              34\n",
      "            ReLU-156             [-1, 17, 2500]               0\n",
      "        UNetConv-157             [-1, 17, 2500]               0\n",
      "          UNetUp-158             [-1, 17, 2500]               0\n",
      " ConvTranspose1d-159             [-1, 17, 5000]           6,375\n",
      "          Conv1d-160              [-1, 4, 5000]           2,856\n",
      "     BatchNorm1d-161              [-1, 4, 5000]               8\n",
      "            ReLU-162              [-1, 4, 5000]               0\n",
      "       Dropout1d-163              [-1, 4, 5000]               0\n",
      "          Conv1d-164              [-1, 4, 5000]             372\n",
      "     BatchNorm1d-165              [-1, 4, 5000]               8\n",
      "            ReLU-166              [-1, 4, 5000]               0\n",
      "        UNetConv-167              [-1, 4, 5000]               0\n",
      "          UNetUp-168              [-1, 4, 5000]               0\n",
      "          Conv1d-169              [-1, 4, 5000]              20\n",
      "         Decoder-170              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 531,312\n",
      "Trainable params: 531,312\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 6979042742013.46\n",
      "Params size (MB): 2.03\n",
      "Estimated Total Size (MB): 6979042742015.71\n",
      "----------------------------------------------------------------\n",
      "Inference Time: 0.0144672 seconds\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(num_channels, kernel_size=23, q=1.2, p=0.1)\n",
    "decoder = Decoder(encoder, num_classes)\n",
    "model = UNetNNGU(encoder, decoder).to(device)\n",
    "\n",
    "print_information_about_model(model, batch_size, num_channels, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d38c1-7899-4490-a1b4-f0dd3da4e18b",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d8a6266-30d9-478b-b500-167b420e7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.0051921753265598\n",
      "Epoch 1/100, Validation Loss: 0.7235550217090114\n",
      "Epoch 2/100, Training Loss: 0.6560620607634787\n",
      "Epoch 2/100, Validation Loss: 0.5196660939724215\n",
      "Epoch 3/100, Training Loss: 0.5405130702474339\n",
      "Epoch 3/100, Validation Loss: 0.43315936384662507\n",
      "Epoch 4/100, Training Loss: 0.49384380665867916\n",
      "Epoch 4/100, Validation Loss: 0.3920732700536328\n",
      "Epoch 5/100, Training Loss: 0.4586034865393812\n",
      "Epoch 5/100, Validation Loss: 0.3653274459704276\n",
      "Epoch 6/100, Training Loss: 0.42623329180696234\n",
      "Epoch 6/100, Validation Loss: 0.3666616276867928\n",
      "Epoch 7/100, Training Loss: 0.4112741857887762\n",
      "Epoch 7/100, Validation Loss: 0.33045082371081075\n",
      "Epoch 8/100, Training Loss: 0.400892896690832\n",
      "Epoch 8/100, Validation Loss: 0.3395261831821934\n",
      "Epoch 9/100, Training Loss: 0.37653074621671606\n",
      "Epoch 9/100, Validation Loss: 0.3227119988972141\n",
      "Epoch 10/100, Training Loss: 0.3685295560702621\n",
      "Epoch 10/100, Validation Loss: 0.29474673732634515\n",
      "Epoch 11/100, Training Loss: 0.3604137971695618\n",
      "Epoch 11/100, Validation Loss: 0.29001968714498705\n",
      "Epoch 12/100, Training Loss: 0.3452246014767813\n",
      "Epoch 12/100, Validation Loss: 0.28443467424761865\n",
      "Epoch 13/100, Training Loss: 0.3492449696368051\n",
      "Epoch 13/100, Validation Loss: 0.3011022347115701\n",
      "Epoch 14/100, Training Loss: 0.3434039946147787\n",
      "Epoch 14/100, Validation Loss: 0.2869230460736059\n",
      "Epoch 15/100, Training Loss: 0.3337473115216383\n",
      "Epoch 15/100, Validation Loss: 0.2949513660803918\n",
      "Epoch 16/100, Training Loss: 0.3312298280266132\n",
      "Epoch 16/100, Validation Loss: 0.29190983935709924\n",
      "Epoch 17/100, Training Loss: 0.34658817409986425\n",
      "Epoch 17/100, Validation Loss: 0.2750763919564985\n",
      "Epoch 18/100, Training Loss: 0.3198282080985274\n",
      "Epoch 18/100, Validation Loss: 0.27417521587302607\n",
      "Epoch 19/100, Training Loss: 0.317409802605266\n",
      "Epoch 19/100, Validation Loss: 0.26926099749342086\n",
      "Epoch 20/100, Training Loss: 0.31277851102805815\n",
      "Epoch 20/100, Validation Loss: 0.27324384474946606\n",
      "Epoch 21/100, Training Loss: 0.32676752913094725\n",
      "Epoch 21/100, Validation Loss: 0.2698720522945927\n",
      "Epoch 22/100, Training Loss: 0.3169713820885067\n",
      "Epoch 22/100, Validation Loss: 0.2860103530749198\n",
      "Epoch 23/100, Training Loss: 0.30392330770309156\n",
      "Epoch 23/100, Validation Loss: 0.26839578536248976\n",
      "Epoch 24/100, Training Loss: 0.30473358458594274\n",
      "Epoch 24/100, Validation Loss: 0.2620716739085413\n",
      "Epoch 25/100, Training Loss: 0.30199600267506804\n",
      "Epoch 25/100, Validation Loss: 0.2602324891955622\n",
      "Epoch 26/100, Training Loss: 0.3089798275637723\n",
      "Epoch 26/100, Validation Loss: 0.25500314250107736\n",
      "Epoch 27/100, Training Loss: 0.30224310199500093\n",
      "Epoch 27/100, Validation Loss: 0.2690026572635097\n",
      "Epoch 28/100, Training Loss: 0.2991021963266226\n",
      "Epoch 28/100, Validation Loss: 0.26966878627577134\n",
      "Epoch 29/100, Training Loss: 0.29283526232126755\n",
      "Epoch 29/100, Validation Loss: 0.2570060424266323\n",
      "Epoch 30/100, Training Loss: 0.2993142446766981\n",
      "Epoch 30/100, Validation Loss: 0.2528857080446136\n",
      "Epoch 31/100, Training Loss: 0.29673657732212594\n",
      "Epoch 31/100, Validation Loss: 0.2512440504806657\n",
      "Epoch 32/100, Training Loss: 0.2942528353046309\n",
      "Epoch 32/100, Validation Loss: 0.2566950839133032\n",
      "Epoch 33/100, Training Loss: 0.2986972362165026\n",
      "Epoch 33/100, Validation Loss: 0.24510023093992664\n",
      "Epoch 34/100, Training Loss: 0.2944546857102197\n",
      "Epoch 34/100, Validation Loss: 0.2533589584692832\n",
      "Epoch 35/100, Training Loss: 0.2937739989776843\n",
      "Epoch 35/100, Validation Loss: 0.2677286787619514\n",
      "Epoch 36/100, Training Loss: 0.2850582682893344\n",
      "Epoch 36/100, Validation Loss: 0.2522204410164587\n",
      "Epoch 37/100, Training Loss: 0.2848467948707009\n",
      "Epoch 37/100, Validation Loss: 0.24808021322373422\n",
      "Epoch 38/100, Training Loss: 0.2868046909872337\n",
      "Epoch 38/100, Validation Loss: 0.24522826760526625\n",
      "Early stopping triggered\n",
      "Total training time: 192.44 seconds\n"
     ]
    }
   ],
   "source": [
    "# Тренировка модели\n",
    "train(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "da361a26-8fe8-41af-8560-eb12671ea018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.85858\n",
      "p_offset: 0.854\n",
      "t_onset: 0.92852\n",
      "t_offset: 0.93112\n",
      "qrs_onset: 0.97614\n",
      "qrs_offset: 0.97505\n"
     ]
    }
   ],
   "source": [
    "print_metric(model, test_loader)\n",
    "p_onset: \n",
    "p_offset: \n",
    "t_onset: \n",
    "t_offset: \n",
    "qrs_onset: \n",
    "qrs_offset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d65ba-fdcd-4948-a821-9cdc96af3d7a",
   "metadata": {},
   "source": [
    "### 2.0 Подведение промежуточных результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ef98a-c3a1-4c4f-b920-6699985c6791",
   "metadata": {},
   "source": [
    "|   | UNetNNGU |  DeepLabV3Plus1DDeeper | AttentionSegNet1D  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| p_onset | 0.85858  | 0.77403  | 0.83115  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| p_offset | 0.85400  | 0.78926  | 0.82901   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| t_onset | 0.92852  | 0.88835  | 0.87987  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| t_offset  | 0.93112  | 0.88879  | 0.87111  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| qrs_onset  | 0.97614  | 0.9665  | 0.96081 |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| qrs_offset  | 0.97505  | 0.96513 | 0.95714  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| Params size (MB)  | 2.03  | 13.53  | 149.48  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| Training Time (sec) | 192.44  | 34.70  | 28.39  |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n",
    "| Inference Time (sec) | 0.0144672  | 0.0298283  | 0.0282965   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef9045-547a-42c7-bfb9-d03549435900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
