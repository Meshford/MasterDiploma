{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a9bc94-9e56-45be-8f17-1967b4735b18",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    Министерство науки и высшего образования Российской Федерации<br>\n",
    "    Федеральное государственное автономное образовательное учреждение высшего образования «Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»<br>\n",
    "    <br>\n",
    "    Институт Информационных технологий, математики и механики<br>\n",
    "    <br><br><br>\n",
    "    Выпускная квалифиционная работа магистра<br>\n",
    "    <h1 style=\"text-align: center;\">Исследование влияния различных способов улучшения точности сегментации ЭКГ</h1>\n",
    "</p>\n",
    "<br><br><br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Выполнил:<br>\n",
    "    студент гр. 381803-1<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Мешалкин Н.А.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br>\n",
    "<p style = \"text-align: left; margin-left: 80%;\">\n",
    "    Проверил:<br>\n",
    "    директор ИИТММ<br>\n",
    "    <p style = \"text-align: left; margin-left: 90%;\">\n",
    "        Золотых Ю.Н.\n",
    "    </p>\n",
    "</p>\n",
    "<br><br><br><br>\n",
    "<p style=\"text-align: center\">\n",
    "    Нижний Новгород<br>\n",
    "    2024\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ee604-547d-491f-8e46-4b392d303403",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefc748-69f6-4e31-9531-996e3bbfcd20",
   "metadata": {},
   "source": [
    "**Описание работы:**\n",
    "Данная работа направлена на изучения влияния на точность сегментационных нейросетей различных способов улучшения точности сегментации. В этом исследовании будет рассмотрено несколько вариантов нейросетей с различными внутренними слоями от самых простых до самых сложных. В качестве нейронной сети, результаты которой следует превзойти, представлена сегментационная нейросеть, подготовленная учеными ННГУ. Данная сеть написана на основе популярной сегментационной сети U-Net. Отличие лишь в том, что данная нейросеть адаптирована под 1D сигнал. Также в качестве базы данных была выбрана собственная база данных ЭКГ, собранная сотрудниками ННГУ. В основе этой базы данных лежат сигналы ЭКГ в 12 отведениях 746 пациентов с частотой дискретизации 500 Гц."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419446d8-cb93-4294-8cf9-9fcce472d1a2",
   "metadata": {},
   "source": [
    "**Цель работы:**\n",
    "Необходимо проанализировать влияние на точность нейросети различных внутренних слоев. Провести сравнительный анализ, а также сделать заключение о налиучшем варианте нейронной сети, которая будет показывать наилучшую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fc8da-647d-4044-8e2e-1fafb7913b0a",
   "metadata": {},
   "source": [
    "Данная работа состоит из двух частей: \n",
    "1) Разработка собственной нейросети для сегментации сигналов ЭКГ. Разработка будет разобрана шаг за шагом, чтобы можно было отследить влияние на точность различных внутренних слоев, которые будут постепенно добавляться в нейронную сеть.\n",
    "2) Работа над сегментационной нейросетью от ученых ННГУ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8eb98e-bb96-4663-bd38-93e406ad6c0d",
   "metadata": {},
   "source": [
    "## Часть 1. Разработка собственной нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6a853-1504-49c5-90f3-64c6b0e69f6c",
   "metadata": {},
   "source": [
    "Данный раздел состоит из множества шагов, потому что разработка нейронной сети сложный и трудоемкий процесс. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12ab64-0136-4ebe-acf1-f1ab3649f632",
   "metadata": {},
   "source": [
    "### 1.1 Анализ данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c0746-42dc-4e9a-b475-520c6870e59a",
   "metadata": {},
   "source": [
    "В качестве данных мы используем сигнал ЭКГ в 12 отведениях с частотой дискретизации 500Гц. В первую очередь необходимо посмотреть на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a81426-acf2-4f0a-a7f0-69e4cb122525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import Module\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.nn.functional as functional\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c1d760-ab9c-4250-a954-a7fbc7d0bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции, превращающие маску в сегментацию\n",
    "sample_rate = 500\n",
    "v_to_del = {1:'p', 2:'qrs', 3:'t'}\n",
    "\n",
    "def remove_small(signal):\n",
    "    max_dist = 12\n",
    "    last_zero = 0\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] == 0:\n",
    "            if i - last_zero < max_dist:\n",
    "                signal[last_zero:i] = 0\n",
    "            last_zero = i\n",
    "\n",
    "def merge_small(signal):\n",
    "    max_dist = 12\n",
    "    lasts = np.full(signal.max() + 1, -(max_dist+1))\n",
    "    for i in range(len(signal)):\n",
    "        m = signal[i]\n",
    "        if i - lasts[m] < max_dist and m > 0:\n",
    "            signal[lasts[m]:i] = m\n",
    "        lasts[m] = i\n",
    "\n",
    "def mask_to_delineation(mask):\n",
    "    merge_small(mask)\n",
    "    remove_small(mask)\n",
    "    delineation = {'p':[], 'qrs':[], 't':[]}\n",
    "    i = 0\n",
    "    mask_length = len(mask)\n",
    "    while i < mask_length:\n",
    "        v = mask[i]\n",
    "        if v > 0:\n",
    "            delineation[v_to_del[v]].append([i, 0])\n",
    "            while i < mask_length and mask[i] == v:\n",
    "                delineation[v_to_del[v]][-1][1] = i\n",
    "                i += 1\n",
    "            t = delineation[v_to_del[v]][-1]\n",
    "        i += 1\n",
    "    return delineation\n",
    "\n",
    "wave_type_to_color = {\n",
    "    \"p\": \"yellow\",\n",
    "    \"qrs\": \"red\",\n",
    "    \"t\": \"green\"\n",
    "}\n",
    "\n",
    "def plot_signal_with_mask(signal, mask):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.title(\"Сигнал с маской\")\n",
    "    plt.xlabel(\"Время (сек)\")\n",
    "    plt.ylabel(\"Амплитуда (мВ)\")\n",
    "    x_axis_values = np.linspace(0, len(signal) / sample_rate, len(signal))\n",
    "    plt.plot(x_axis_values, signal, linewidth=2, color=\"black\")\n",
    "    \n",
    "    delineation = mask_to_delineation(mask)\n",
    "    for wave_type in [\"p\", \"qrs\", \"t\"]:\n",
    "        color = wave_type_to_color[wave_type]\n",
    "        for begin, end in delineation[wave_type]:\n",
    "            begin /= sample_rate\n",
    "            end /= sample_rate\n",
    "            plt.axvspan(begin, end, facecolor=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950b3649-1d36-494d-a552-6334268d0d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signals = np.load(\"/home/meshalkin/Diplom/ludb/data/signals/00001_hr_unsupervised.npy\")\n",
    "masks = np.load(\"/home/meshalkin/Diplom/ludb/data/masks/00001_hr_unsupervised.npy\")\n",
    "index = 3\n",
    "plot_signal_with_mask(signals[index], masks[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e1090-ac2e-4753-b924-9af6bb2fdcab",
   "metadata": {},
   "source": [
    "Так выглядит сигнал и оригинальная маска. Будем надеяться, что наша нейросеть, покажет такие же результаты!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6190e-524e-4398-82ee-f8ec7781fa38",
   "metadata": {},
   "source": [
    "### 1.2. Разработка метрики для контроля качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973b7a0-f74e-4bea-9342-9d5899121835",
   "metadata": {},
   "source": [
    "В коде, приведенном ниже производится разработка собственной метрики, основанной на f1score, precision, recall и confusion_matrix. Данная метрика будет отслеживать качество работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363b040a-50e5-44d0-8066-a5733ef70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetric:\n",
    "    def __init__(self,\n",
    "                 monitor: Literal['p', 'qrs', 't', 'all'] = 'all',\n",
    "                 orientation_type: Literal['onset', 'offset', 'all'] = 'all',\n",
    "                 return_type: Literal['precision', 'recall', 'f1', 'confusion_matrix'] = 'confusion_matrix',\n",
    "                 samples=75):\n",
    "\n",
    "        assert monitor in ['p', 'qrs', 't', 'all']\n",
    "        assert orientation_type in ['onset', 'offset', 'all']\n",
    "        assert return_type in ['precision', 'recall', 'f1', 'confusion_matrix']\n",
    "\n",
    "        self.samples = samples\n",
    "        self.monitor = monitor\n",
    "        self.orientation_type = orientation_type\n",
    "        self.return_type = return_type\n",
    "        \n",
    "        self.metric_to_func = {'precision': self.__precision,\n",
    "                               'recall': self.__recall,\n",
    "                               'f1': self.__f1}\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        assert len(y_pred.shape) == 2 # Это для батча или для каналов ?\n",
    "        \n",
    "        matrix = np.zeros((2, 2), dtype=int)\n",
    "        monitors = ['p', 'qrs', 't'] if self.monitor == 'all' else [self.monitor]\n",
    "        orientations = ['onset', 'offset'] if self.orientation_type == 'all' else [self.orientation_type]\n",
    "        for wave in monitors:\n",
    "            for orientation in orientations:\n",
    "                matrix += self.__handle(y_pred, y_true, wave, orientation)\n",
    "        \n",
    "        if self.return_type == 'confusion_matrix':\n",
    "            return matrix\n",
    "\n",
    "        return self.metric_to_func[self.return_type](matrix[0, 1], matrix[1, 0], matrix[1, 1])\n",
    "\n",
    "    def __handle(self, y_pred, y_true, wave, orientation) -> tuple[int, int, int]:\n",
    "        \n",
    "        index = ['p', 'qrs', 't'].index(wave) + 1\n",
    "        orientation = 2 * ['offset', 'onset'].index(orientation) - 1\n",
    "        y_pred[y_true == 4] = 0\n",
    "\n",
    "        y_true, y_pred = (y_true == index), (y_pred == index)\n",
    "\n",
    "        wave_true = np.logical_and(np.roll(y_true, orientation) != 1, y_true == 1).astype(int)\n",
    "        wave_pred = np.logical_and(np.roll(y_pred, orientation) != 1, y_pred == 1).astype(int)\n",
    "\n",
    "        true_batch, true_indexes = np.where(wave_true == 1)\n",
    "        \n",
    "        tp = fn = 0\n",
    "        \n",
    "        for batch, x in zip(true_batch, true_indexes):\n",
    "            wave = wave_pred[batch][x - self.samples // 2: x + self.samples // 2]\n",
    "            if wave.sum():\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            wave[:] = -1\n",
    "        \n",
    "        fp = (wave_pred[:, self.samples:-self.samples] == 1).sum()\n",
    "        return np.array([[0, fp], [fn, tp]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __precision(fp, fn, tp):\n",
    "        if fp + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __recall(fp, fn, tp):\n",
    "        if fn + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __f1(fp, fn, tp):\n",
    "        precision = SegmentationMetric.__precision(fp, fn, tp)\n",
    "        recall = SegmentationMetric.__recall(fp, fn, tp)\n",
    "        if precision + recall == 0:\n",
    "            return 1\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.monitor}_{self.orientation_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f352d955-6e4f-46e7-a285-9073a50b40ef",
   "metadata": {},
   "source": [
    "### 1.3. Создание датасета для загрузки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714bf6e-2004-46f7-854d-ef1a4b050c60",
   "metadata": {},
   "source": [
    "Необходимым шагом является правильная загрузка данных, уравнивание длины сигнала, если это необходимо, разделение данных на тренировочную и тестовую выбороки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffa1a9e-6378-4b50-84dc-a912267a40df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры сигналов и масок с батчом = 2:\n",
      "Размер сигнала = torch.Size([2, 12, 5000])\n",
      "Размер маски = torch.Size([2, 12, 5000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data_folder, label_folder, max_length=5000):\n",
    "        self.data_files = glob.glob(f'{data_folder}/*.npy')\n",
    "        self.label_files = glob.glob(f'{label_folder}/*.npy')\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_files[idx])\n",
    "        labels = np.load(self.label_files[idx])\n",
    "\n",
    "        # Обрезка данных и меток, если длина превышает max_length\n",
    "        if data.shape[1] > self.max_length:\n",
    "            data = data[:, :self.max_length]\n",
    "            labels = labels[:, :self.max_length]\n",
    "\n",
    "        return torch.from_numpy(data).float(), torch.from_numpy(labels).long()\n",
    "\n",
    "# Использование DataLoader\n",
    "data_folder = '/home/meshalkin/Diplom/ludb/data/signals'\n",
    "label_folder = '/home/meshalkin/Diplom/ludb/data/masks'\n",
    "dataset = SignalDataset(data_folder, label_folder)\n",
    "\n",
    "# Например, 20% для валидации\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "# Разделите датасет на тренировочный и валидационный\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Создайте DataLoader для обоих датасетов\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # shuffle обычно не нужен для валидации\n",
    "\n",
    "for i, (signal, label) in enumerate(train_loader):\n",
    "    print(f\"Размеры сигналов и масок с батчом = {batch_size}:\")\n",
    "    print(f\"Размер сигнала = {label.shape}\")\n",
    "    print(f\"Размер маски = {signal.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775384b-81da-4a09-b704-93c104d4d53a",
   "metadata": {},
   "source": [
    "### 1.4. Разработка собственной неросети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ac786-7925-4f6d-b459-603f5a291f84",
   "metadata": {},
   "source": [
    "#### 1.4.1 Разработка версии №1. Простейшая full-convolutional сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c62cb9-3987-4327-917f-2ab1ae6536fa",
   "metadata": {},
   "source": [
    "Начнем с простой нейронной сети с тремя сверточноми слоями внутри. Так как маска распространяется вдоль всех каналов, мы можем объединить их и выдавать результат в виде распределения вероятностей по нашим классам. Точнее будет сказать, что все таки выход будет иметь ненормализированные числа, они нормализуются в процессе обучения.  \n",
    "То есть, наши данные имеют размер [2,12,5000], где 2 - размер батча, 12 - количество каналов, 5000 - длина сигнала, то выход нейронной сети будет иметь размер [2,4,5000], где 2 - размер батча, 12 - количество классов, 5000 - длина сигнала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db80ec24-4b2d-407b-89b2-f79cb945a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SegmentationNetwork(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(SegmentationNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetwork(num_channels, num_classes).to(device)\n",
    "\n",
    "# Создание случайных входных данных\n",
    "inputs = torch.randn(batch_size, num_channels, length)\n",
    "\n",
    "# Проход через сеть\n",
    "outputs = model(inputs.to(device))\n",
    "print(f\"Размер входа: {inputs.shape}\")\n",
    "print(f\"Размер выхода: {outputs.shape}\")  # Распечатает: torch.Size([2, 4, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a973dfe-bba3-4e52-a4b6-7678d72ea151",
   "metadata": {},
   "source": [
    "Напишем обучающую функцию для данной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199223ef-c246-4df2-8394-4676d41714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.9107116305982912\n",
      "Epoch 2/20, Loss: 0.8310911239354641\n",
      "Epoch 3/20, Loss: 0.810581589093456\n",
      "Epoch 4/20, Loss: 0.7957175445634049\n",
      "Epoch 5/20, Loss: 0.7766511578645025\n",
      "Epoch 6/20, Loss: 0.758515783331611\n",
      "Epoch 7/20, Loss: 0.743146370273906\n",
      "Epoch 8/20, Loss: 0.7289919098476311\n",
      "Epoch 9/20, Loss: 0.7179090499684408\n",
      "Epoch 10/20, Loss: 0.7074661811257338\n",
      "Epoch 11/20, Loss: 0.6982653497101424\n",
      "Epoch 12/20, Loss: 0.6892857104539871\n",
      "Epoch 13/20, Loss: 0.6840200850909407\n",
      "Epoch 14/20, Loss: 0.6729757837080336\n",
      "Epoch 15/20, Loss: 0.6651047398517658\n",
      "Epoch 16/20, Loss: 0.6566105393039716\n",
      "Epoch 17/20, Loss: 0.6494584144516424\n",
      "Epoch 18/20, Loss: 0.6419491538560236\n",
      "Epoch 19/20, Loss: 0.6393212319000975\n",
      "Epoch 20/20, Loss: 0.6341367575835872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, train_loader, num_epochs=20, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            targets = targets[:, 0, :].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs.to(device), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetwork(num_channels, num_classes)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5e8403-3764-4a0a-b251-ba6be897cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.38%\n",
      "p_offset: 0.43%\n",
      "t_onset: 0.46%\n",
      "t_offset: 0.51%\n",
      "qrs_onset: 0.82%\n",
      "qrs_offset: 0.85%\n"
     ]
    }
   ],
   "source": [
    "def validate_model_with_metrics(model, validation_loader, metric, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "\n",
    "    for inputs, labels in validation_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "            \n",
    "        # Переводим outputs в формат [batch_size, length, num_channels], где num_channels - это наши классы\n",
    "        _, outputs = torch.max(F.softmax(outputs, dim=1), dim=1)  # получаем наиболее вероятные классы\n",
    "        if(outputs.shape[0] > 1):\n",
    "            outputs = torch.cat([outputs[0], outputs[1]], dim=0).cpu() \n",
    "        else:\n",
    "            outputs = outputs[0]\n",
    "        \n",
    "        outputs = outputs.unsqueeze(0) \n",
    "        outputs = outputs.expand(12, *outputs.shape[1:]).cpu() # считаем по батчу и объединяем, дублируем на 12 -> (12,10000)\n",
    "        if(labels.shape[0] > 1):\n",
    "            labels = torch.cat([labels[0],labels[1]], dim=1).cpu() # считаем по батчу и объединяем -> (12,10000)\n",
    "        else:\n",
    "            labels = labels[0]\n",
    "        all_metrics.append(metric(outputs.numpy(), labels.numpy()))\n",
    "    \n",
    "    # Средний расчет всех метрик по всем батчам\n",
    "    if metric.return_type == 'confusion_matrix':\n",
    "        final_metrics = np.sum(all_metrics, axis=0)\n",
    "    else:\n",
    "        final_metrics = np.mean(all_metrics, axis=0)\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f67d2888-88ad-4d6e-818a-187c2f61405f",
   "metadata": {},
   "source": [
    "Результаты выше - результаты нашей собственной метрики самой простейшей модели с тремя внутренними сверточными слоями. Как можно заметить, результаты лишь в половине случаев предсказывают верное расположение t и qrs волн. Что касается p волны, то здесь результаты хуже, лишь в ~30% случаев расположение p волны будет указано верно. Такие результаты говорят о том, что нам следует усложнить нашу модель, чтобы улучшить значения метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4741d-8210-4678-9dc8-3e800d748023",
   "metadata": {},
   "source": [
    "#### 1.4.2 Разработка версии №2. Усложненная full-convolutional сеть с добавлением дополнительных сверточных слоев и слоев пулинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c11f0b-eab2-4b98-8d32-d9007ae89191",
   "metadata": {},
   "source": [
    "В данном разделе интересно было бы проверить предыдущую нейронную сеть с добавлением дополнительных сверточных слоев лои пулинга для увеличения ее способности к извлечению признаков и повышения точности сегментации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "020ef2f7-a645-4be0-9455-b15224b96867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер входа: torch.Size([2, 12, 5000])\n",
      "Размер выхода: torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class SegmentationNetworkWithPooling(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(SegmentationNetworkWithPooling, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(128, num_classes, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)  # Добавляем пулинг со stride=1 и kernel_size=3\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetwork(num_channels, num_classes).to(device)\n",
    "\n",
    "# Создание случайных входных данных\n",
    "inputs = torch.randn(batch_size, num_channels, length)\n",
    "\n",
    "# Проход через сеть\n",
    "outputs = model(inputs.to(device))\n",
    "\n",
    "print(f\"Размер входа: {inputs.shape}\")\n",
    "print(f\"Размер выхода: {outputs.shape}\")  # Распечатает: torch.Size([2, 4, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6aa5ef-0de9-4783-8d1c-0d3147d319e3",
   "metadata": {},
   "source": [
    "Теперь обучим данную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f14f7c6e-895f-4aa4-a40f-b7684117a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.8732695236995622\n",
      "Epoch 2/20, Loss: 0.7724130362659306\n",
      "Epoch 3/20, Loss: 0.7358157496367183\n",
      "Epoch 4/20, Loss: 0.7136388083363508\n",
      "Epoch 5/20, Loss: 0.6984711809978856\n",
      "Epoch 6/20, Loss: 0.6791554085620037\n",
      "Epoch 7/20, Loss: 0.6684322147206827\n",
      "Epoch 8/20, Loss: 0.6475532745773142\n",
      "Epoch 9/20, Loss: 0.6362113259829484\n",
      "Epoch 10/20, Loss: 0.6229480428548603\n",
      "Epoch 11/20, Loss: 0.6239411302588203\n",
      "Epoch 12/20, Loss: 0.610577665656418\n",
      "Epoch 13/20, Loss: 0.6070154219285234\n",
      "Epoch 14/20, Loss: 0.5999381524788869\n",
      "Epoch 15/20, Loss: 0.591483116730467\n",
      "Epoch 16/20, Loss: 0.5896994816985998\n",
      "Epoch 17/20, Loss: 0.58695823708912\n",
      "Epoch 18/20, Loss: 0.5838740701218704\n",
      "Epoch 19/20, Loss: 0.5759387813605271\n",
      "Epoch 20/20, Loss: 0.5732320650637924\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetworkWithPooling(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28104072-2a00-4c15-b398-c81eaddee241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.42%\n",
      "p_offset: 0.5%\n",
      "t_onset: 0.5%\n",
      "t_offset: 0.56%\n",
      "qrs_onset: 0.88%\n",
      "qrs_offset: 0.9%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f727-c8c7-402d-ab2a-b871e5639c6f",
   "metadata": {},
   "source": [
    "Можно заметить как увеличились значения наших метрик. Теперь p волна определяется правильно примерно в ~80% случаев, t волна определяется правильно примерно в ~60% случаев, а qrs сегмент остался на уровне ~55%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b951bb-1c67-4ef4-86aa-1cc38785c196",
   "metadata": {},
   "source": [
    "#### 1.4.3 Разработка версии №3. Более глубокая усложненная full-convolutional сеть с добавлением дополнительных сверточных слоев и слоев пулинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb966544-0950-4980-80cf-8bb371d8450a",
   "metadata": {},
   "source": [
    "Давайте добавим еще один блок свертки-пулинга для увеличения глубины и сложности модели. Также мы можем увеличить количество фильтров в каждом сверточном слое для более глубокого извлечения признаков. Вот обновленная версия модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a19ece1-1e60-4b6f-a10e-e6e06d93db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HardSegmentationNetworkWithPooling(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(HardSegmentationNetworkWithPooling, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv1d(512, num_classes, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv7(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.conv8(x)\n",
    "        return x\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegmentationNetwork(num_channels, num_classes)\n",
    "\n",
    "# Создание случайных входных данных\n",
    "inputs = torch.randn(batch_size, num_channels, length)\n",
    "\n",
    "# Проход через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs.shape)  # Распечатает: torch.Size([2, 4, 5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79d909-1a54-4934-9d4c-0404a2809673",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f0033ff-44c0-4729-b873-c1ce41f9faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.8525674770791809\n",
      "Epoch 2/20, Loss: 0.7283802487246402\n",
      "Epoch 3/20, Loss: 0.6798245737498457\n",
      "Epoch 4/20, Loss: 0.6460889961038317\n",
      "Epoch 5/20, Loss: 0.6244799911782339\n",
      "Epoch 6/20, Loss: 0.6081230048235361\n",
      "Epoch 7/20, Loss: 0.5868251238550458\n",
      "Epoch 8/20, Loss: 0.567217147679298\n",
      "Epoch 9/20, Loss: 0.5652847698369583\n",
      "Epoch 10/20, Loss: 0.5492625278118369\n",
      "Epoch 11/20, Loss: 0.5452114213016126\n",
      "Epoch 12/20, Loss: 0.5414040609226598\n",
      "Epoch 13/20, Loss: 0.5317328899324715\n",
      "Epoch 14/20, Loss: 0.5262701879074048\n",
      "Epoch 15/20, Loss: 0.5280979278606254\n",
      "Epoch 16/20, Loss: 0.5152999461180978\n",
      "Epoch 17/20, Loss: 0.5135620918076533\n",
      "Epoch 18/20, Loss: 0.509175465285004\n",
      "Epoch 19/20, Loss: 0.5025882630959734\n",
      "Epoch 20/20, Loss: 0.4986351662158192\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = HardSegmentationNetworkWithPooling(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2564215a-eec3-484d-b204-052981a3a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.49%\n",
      "p_offset: 0.51%\n",
      "t_onset: 0.61%\n",
      "t_offset: 0.61%\n",
      "qrs_onset: 0.9%\n",
      "qrs_offset: 0.93%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f0bb8-2237-4905-bb17-e539c91bb5b8",
   "metadata": {},
   "source": [
    "В данном случае мы видим, что метрика показывает результаты хуже, после усложнения модели дополнительными слоями, потому что увеличение сложности модели не всегда приводит к улучшению ее производительности. Наоборот, в некоторых случаях это может привести к переобучению или затуханию градиентов, особенно если модель становится слишком глубокой или сложной для данной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdf301-f078-405b-bc32-2afe18d12ef7",
   "metadata": {},
   "source": [
    "#### 1.4.4 Разработка версии №4. UNet-подобная сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4455f3-755a-46af-be1c-b781a74fc7fb",
   "metadata": {},
   "source": [
    "Так как элементарное углубление модели для данной задачи с имеющимся количеством данных не приносит ожидаемых результатов, мы можем привести модель к уже имеющимся архитектурам, которые зарекомендовали себя в задаче сегментаци данных, поэтому ниже произведено приведение нашей модели к Unet-подобной архитектуре, добавив соединения между сверточными слоями и их транспонированными аналогами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df6c0359-a619-4a33-9ac3-4afa2ab0ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # Энкодер\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='linear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Прямой проход через энкодер\n",
    "        x1 = self.encoder(x)\n",
    "        \n",
    "        # Прямой проход через декодер\n",
    "        output = self.decoder(x1)\n",
    "        return output\n",
    "\n",
    "# Пример использования\n",
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SimpleUNet(num_channels, num_classes)\n",
    "\n",
    "# Создание случайных входных данных\n",
    "inputs = torch.randn(batch_size, num_channels, length)\n",
    "\n",
    "# Проход через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs.shape)  # Распечатает: torch.Size([2, 4, 5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d355ce-894a-4372-a666-666591b50fd3",
   "metadata": {},
   "source": [
    "В данном случае, чтобы исследовать поведение UNet-подобной архитектуры мы начнем с простой версии Unet с одним энкодером и одним декодером. Она включает в себя сверточные слои для энкодера и декодера, а также операцию апсэмплинга для увеличения размера выходного изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43520b66-b0f8-4495-939e-ff2b858add1e",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c025cb24-5c7b-421b-b54a-916e74302aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.300088524044334\n",
      "Epoch 2/10, Loss: 1.2709616337503706\n",
      "Epoch 3/10, Loss: 1.0858693807930142\n",
      "Epoch 4/10, Loss: 0.7836202448838717\n",
      "Epoch 5/10, Loss: 0.7666925230583588\n",
      "Epoch 6/10, Loss: 0.7525445749233295\n",
      "Epoch 7/10, Loss: 0.738971393700544\n",
      "Epoch 8/10, Loss: 0.7270432562603579\n",
      "Epoch 9/10, Loss: 0.7169951970701094\n",
      "Epoch 10/10, Loss: 0.7065320601323982\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SimpleUNet(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a730b0c-0604-43ec-8f78-58e6bdef5d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.06%\n",
      "p_offset: 0.06%\n",
      "t_onset: 0.59%\n",
      "t_offset: 0.61%\n",
      "qrs_onset: 0.86%\n",
      "qrs_offset: 0.86%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bde65-2c34-49f4-aba8-62539f54fdb7",
   "metadata": {},
   "source": [
    "Можно заметить, что метрики хуже, чем версия с усложненной версии full-convolutional сетью. Проблема в том, что сеть, которая реализована выше, состоит из двух сверточных слоев в энкодере и двух в декодере, что может быть недостаточно для эффективной сегментации сложных данных, таких как сигналы ЭКГ. Важно учитывать, что для успешной сегментации требуются глубокие и сложные архитектуры сетей, способные улавливать различные уровни признаков в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dddacd-1756-4516-9b7f-e8c54d524778",
   "metadata": {},
   "source": [
    "#### 1.4.5 Разработка версии №5. Усложненная UNet-подобная сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59742c65-6cad-4531-a70a-5dd9ddad16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06f53f76-f97d-477e-b217-c4db77c0f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab1d4b40-738c-47f0-926c-6c1d56afff3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetDecoder, self).__init__()\n",
    "        # Увеличиваем размер с 2500 до 5000 и количество каналов с 128 до 64\n",
    "        self.upconv1 = nn.ConvTranspose1d(128, 64, kernel_size=8, stride=4, padding=2)\n",
    "        # Сверточные слои после конкатенации\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64)\n",
    "        )\n",
    "        # Выходной слой, предполагая что нужно num_classes каналов на выходе\n",
    "        self.final_conv = nn.Conv1d(64, num_classes, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        # Применяем апсемплинг\n",
    "        x = self.upconv1(x)  # x теперь [2, 64, 5000]\n",
    "        # Конкатенация с соответствующим слоем из skips\n",
    "        x = torch.cat((x, skips[0]), dim=1)  # x теперь [2, 128, 5000]\n",
    "        # Применяем сверточные слои\n",
    "        x = self.conv1(x)\n",
    "        # Применяем выходной слой\n",
    "        x = self.final_conv(x)  # x теперь [2, num_classes, 5000]\n",
    "        return x\n",
    "\n",
    "class ImprovedUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ImprovedUNet, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.ModuleList([\n",
    "            nn.Sequential(nn.Conv1d(in_channels, 64, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm1d(64)),\n",
    "            nn.MaxPool1d(2),  # Уменьшает размерность в 2 раза\n",
    "            nn.Sequential(nn.Conv1d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm1d(128)),\n",
    "            nn.MaxPool1d(2)   # Уменьшает размерность в 2 раза\n",
    "        ])\n",
    "\n",
    "        self.decoder = UNetDecoder()\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.Sequential):\n",
    "                skips.append(x)\n",
    "        x = self.decoder(x, skips) \n",
    "        return x\n",
    "\n",
    "# Создадим модель\n",
    "model = ImprovedUNet(in_channels=12, out_channels=4)\n",
    "\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfe9a501-e962-4571-98ca-bf5217474888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 5000]           2,368\n",
      "              ReLU-2             [-1, 64, 5000]               0\n",
      "       BatchNorm1d-3             [-1, 64, 5000]             128\n",
      "         MaxPool1d-4             [-1, 64, 2500]               0\n",
      "            Conv1d-5            [-1, 128, 2500]          24,704\n",
      "              ReLU-6            [-1, 128, 2500]               0\n",
      "       BatchNorm1d-7            [-1, 128, 2500]             256\n",
      "         MaxPool1d-8            [-1, 128, 1250]               0\n",
      "   ConvTranspose1d-9             [-1, 64, 5000]          65,600\n",
      "           Conv1d-10             [-1, 64, 5000]          24,640\n",
      "             ReLU-11             [-1, 64, 5000]               0\n",
      "      BatchNorm1d-12             [-1, 64, 5000]             128\n",
      "           Conv1d-13              [-1, 4, 5000]             772\n",
      "      UNetDecoder-14              [-1, 4, 5000]               0\n",
      "================================================================\n",
      "Total params: 118,596\n",
      "Trainable params: 118,596\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 27.16\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 27.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to(device), input_size=(12, 5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea8450-291b-4a81-8eed-53b85e66815d",
   "metadata": {},
   "source": [
    "Давайте разберемся в этом коде:\n",
    "1. Энкодер: Он состоит из последовательности сверточных слоев и слоев максимального пулинга, которые уменьшают размерность входных данных вдоль оси длины сигнала.\n",
    "2. Декодер: Он состоит из слоев транспонированной свертки и слоев двойной свертки. Важно отметить, что каждый выход из слоя энкодера используется для соединения с соответствующим слоем декодера в процессе декодирования.\n",
    "3. Проход через декодер: В цикле for происходит перебор слоев декодера. В каждой итерации, если индекс i четный, то происходит объединение выхода из текущего слоя декодера с соответствующим выходом из энкодера. Затем, через текущий слой декодера пропускается объединенный тензор.\n",
    "4. cropped_encoder_output: Для каждого четного слоя декодера выбирается соответствующий выход из энкодера, который затем обрезается до размера выхода из декодера перед объединением.  \n",
    "5. Возвращаемый результат: Возвращается выход из последнего слоя декодера, который представляет собой предсказание модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4b84ed6-a839-4c14-8f5f-5910d11070bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8298514181530321\n",
      "Epoch 2/10, Loss: 0.6662266855309535\n",
      "Epoch 3/10, Loss: 0.6308915077091811\n",
      "Epoch 4/10, Loss: 0.5975242975083265\n",
      "Epoch 5/10, Loss: 0.5761517037625437\n",
      "Epoch 6/10, Loss: 0.5618595191604131\n",
      "Epoch 7/10, Loss: 0.5520611503101015\n",
      "Epoch 8/10, Loss: 0.5374854013517305\n",
      "Epoch 9/10, Loss: 0.533187630695182\n",
      "Epoch 10/10, Loss: 0.521397644726487\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = ImprovedUNet(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d790bc1-6eb1-42cf-b4e4-a27ae8eda420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.45%\n",
      "p_offset: 0.46%\n",
      "t_onset: 0.53%\n",
      "t_offset: 0.57%\n",
      "qrs_onset: 0.87%\n",
      "qrs_offset: 0.88%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d4c3f-cd95-44b3-b335-201f368058ae",
   "metadata": {},
   "source": [
    "Для задач сегментации изображений существует множество архитектур нейронных сетей, каждая из которых имеет свои особенности и применяется в зависимости от специфики задачи. Вот несколько популярных архитектур:\n",
    "\n",
    "1. **UNet**: Одна из самых популярных архитектур для медицинской сегментации. Она использует скип-соединения для передачи информации между слоями энкодера и декодера, что помогает сохранить пространственную информацию при восстановлении изображения.  \n",
    "2. **SegNet**: Архитектура, похожая на UNet, с акцентом на использование индексов максимального пулинга из энкодера для нелинейной деиндексации в декодере. Это позволяет более эффективно использовать пространственные признаки при меньшем количестве параметров.  \n",
    "3. **DeepLab (v3 и v3+)**: Использует атроус свертки (dilated convolutions) для увеличения поля зрения сверточных слоев, а также включает ASPP (Atrous Spatial Pyramid Pooling), что позволяет захватывать контекст на нескольких масштабах. DeepLabv3+ добавляет к этому еще и улучшенный декодер для уточнения границ объектов.  \n",
    "4. **Mask R-CNN**: Расширение Faster R-CNN, добавляющее ветвь для предсказания масок на каждый ROI, позволяя проводить сегментацию на уровне экземпляра. Это хорошо подходит для задач, где необходимо различать отдельные объекты одного класса.  \n",
    "5. **PSPNet (Pyramid Scene Parsing Network)**: Использует пирамиду глобального пулинга для улавливания информации на различных масштабах. Это особенно полезно для сцен анализа, где контекст важен для точной сегментации.  \n",
    "6. **RefineNet**: Сеть для мультипатового рафинирования, которая использует информацию из всех уровней глубины для улучшения качества сегментации. Эта архитектура направлена на использование информации с высоким разрешением на всех этапах обработки.  \n",
    "7. **LinkNet**: Основана на идее эффективного использования энкодера, предназначенного для классификации (например, ResNet) с добавлением декодера, который восстанавливает размерность изображения, используя скип-соединения для улучшения точности.  \n",
    "8. **HRNet (High-Resolution Network)**: Уникально сочетает высокое разрешение с возможностями углубленного анализа через сеть, сохраняя высокое разрешение через все слои сети.  \n",
    "Эти архитектуры подходят для различных видов сегментационных задач и выбор конкретной архитектуры зависит от специфических требований приложения, доступности вычислительных ресурсов и требуемой точности.  \n",
    "**UNet мы опробовали, есть смысл протестировать несколько архитектур из этого списка в качестве экспериментов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2b2e1-66f1-45a8-b010-7c5ad1d6b232",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка SegNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69dd9c-16f7-4189-b25b-5119baf7055a",
   "metadata": {},
   "source": [
    "Для построения архитектуры SegNet, адаптированной под нашу задачу сегментации сигналов, мы можем воспользоваться модификацией стандартного подхода SegNet для работы с 1D данными, поскольку большинство стандартных реализаций SegNet предназначены для работы с изображениями (2D данных).\n",
    "\n",
    "В этом случае, основная идея заключается в использовании 1D сверточных слоев вместо 2D, и адаптации слоев пулинга и апсемплинга для работы с одномерными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450baf56-89bf-4d32-a4ce-9e667cb50ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class SegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(SegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices2)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices1)\n",
    "        x = self.decoder_conv2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = SegNet1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc496d08-5c49-47a0-b6cc-dd1baa05432d",
   "metadata": {},
   "source": [
    "##### Ключевые особенности:\n",
    "**1D сверточные слои**: Позволяют обрабатывать временные ряды или одномерные сигналы.  \n",
    "**MaxPool1d с return_indices**: Это позволяет в процессе пулинга сохранять индексы максимальных значений, которые затем используются в слое MaxUnpool1d для восстановления данных до исходного размера.  \n",
    "**MaxUnpool1d**: Используется для апсемплинга данных в декодере, возвращая значения в исходные позиции на основе сохраненных индексов.  \n",
    "Этот подход позволяет модели эффективно учиться на данных, представляющих собой одномерные сигналы, и проводить сегментацию, восстанавливая исходные размеры выходных данных для каждого класса.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0d461-511d-485f-b779-1e136ac187a6",
   "metadata": {},
   "source": [
    "Теперь натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7a30b3-dbc4-4776-a275-d40372c9ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9576759168079921\n",
      "Epoch 2/10, Loss: 0.799306452080801\n",
      "Epoch 3/10, Loss: 0.7056014337516451\n",
      "Epoch 4/10, Loss: 0.6449206212124268\n",
      "Epoch 5/10, Loss: 0.6055860993537036\n",
      "Epoch 6/10, Loss: 0.5760808304532782\n",
      "Epoch 7/10, Loss: 0.5463730433544556\n",
      "Epoch 8/10, Loss: 0.5304551280357621\n",
      "Epoch 9/10, Loss: 0.5137173408618221\n",
      "Epoch 10/10, Loss: 0.5015593867797357\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = SegNet1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceee918-af98-4b68-a8cb-5f2ad8fc24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321f057-f081-4ed7-8457-0bacd1971c63",
   "metadata": {},
   "source": [
    "Модель показала неплохие результаты для такой небольшой глубины, можем попробовать усложнить эту сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992dbd22-e9e5-418d-8814-1d4631e71690",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка улучшенного SegNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e273e-f856-494a-b488-c391e3feba36",
   "metadata": {},
   "source": [
    "Для улучшения производительности и точности сегментации в модели SegNet для одномерных данных, мы можем внести несколько изменений, направленных на улучшение изучения признаков и увеличение глубины сети. Это включает добавление дополнительных слоев, увеличение количества каналов в сверточных слоях, а также внедрение дополнительных элементов, таких как Dropout для предотвращения переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "717fec3c-75e4-4e8a-ba4f-b8d8c2bb770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class AdvancedSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(AdvancedSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices3)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices2)\n",
    "        x = self.decoder_conv2(x)\n",
    "\n",
    "        x = self.decoder_unpool3(x, indices1)\n",
    "        x = self.decoder_conv3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = AdvancedSegNet1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe906f7-dd58-460a-9cc6-8a8324a095d4",
   "metadata": {},
   "source": [
    "##### Ключевые особенности и улучшения:\n",
    "**Больше сверточных слоев**: Каждый блок свертки теперь содержит два сверточных слоя, что позволяет извлекать более сложные признаки на каждом уровне.  \n",
    "**Увеличенное количество фильтров**: Увеличение количества каналов в сверточных слоях помогает сети обучаться на более сложной иерархии признаков.  \n",
    "**Больше уровней глубины**: Добавление дополнительного уровня глубины в энкодер и декодер улучшает способность сети восстанавливать детализированные сегментации.  \n",
    "Эти изменения направлены на улучшение способности модели извлекать сложные признаки из данных и более точно восстанавливать детали в процессе сегментации, что потенциально приведет к улучшению точности сегментации.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e861abda-ee0f-4e51-b8b3-b6aeaf5a147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8915555186859974\n",
      "Epoch 2/10, Loss: 0.7044457411998278\n",
      "Epoch 3/10, Loss: 0.6147651332732919\n",
      "Epoch 4/10, Loss: 0.5539327933416738\n",
      "Epoch 5/10, Loss: 0.5102888993048048\n",
      "Epoch 6/10, Loss: 0.4851705684483825\n",
      "Epoch 7/10, Loss: 0.46359497357111473\n",
      "Epoch 8/10, Loss: 0.44176350045320273\n",
      "Epoch 9/10, Loss: 0.42519436762123913\n",
      "Epoch 10/10, Loss: 0.41051154496607845\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = AdvancedSegNet1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f3cfe-96b6-4087-99ae-3e5bff54d6c6",
   "metadata": {},
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd655f-c98a-430a-879a-ce179d578df7",
   "metadata": {},
   "source": [
    "#### 1.4.6. Разработка улучшенного SegNet с добавлением дополнительных сверточных слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d039b-40e5-4bfb-ba9c-a20556f1f234",
   "metadata": {},
   "source": [
    "Предыдущая модель показала неплохие результаты, мы можем попробовать увеличить глубину сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aa94a47-c19b-46f7-842e-7911d4bd2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class DeeperAdvancedSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(DeeperAdvancedSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "\n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "\n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeeperAdvancedSegNet1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4933c5a8-8bbe-446b-aeff-004c1d55fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8636775500588603\n",
      "Epoch 2/10, Loss: 0.6755266141194802\n",
      "Epoch 3/10, Loss: 0.5861208029575162\n",
      "Epoch 4/10, Loss: 0.5274247819340074\n",
      "Epoch 5/10, Loss: 0.49196176559894117\n",
      "Epoch 6/10, Loss: 0.45921954619032995\n",
      "Epoch 7/10, Loss: 0.4362997434936561\n",
      "Epoch 8/10, Loss: 0.423144176408842\n",
      "Epoch 9/10, Loss: 0.40815963523534987\n",
      "Epoch 10/10, Loss: 0.3899886745040293\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeeperAdvancedSegNet1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f0c0553-09df-4f54-bdbc-83ddfc2fe90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.8%\n",
      "p_offset: 0.81%\n",
      "t_onset: 0.85%\n",
      "t_offset: 0.88%\n",
      "qrs_onset: 0.96%\n",
      "qrs_offset: 0.96%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2326684-726c-4c38-a331-684ddd59e953",
   "metadata": {},
   "source": [
    "Можем видеть, что теперь метрики стали еще выше, расположение p-волны правильно сегментируется в 80% случаев, t-волны примерно в 86% случаев, а qrs сегмента в 96% случаев. Однако последующее увеличение глубины сети скорее всего не покажет метрики сильно выше этих, но сильно утежелит модель, что повлияет на ее быстродействие и скорость обученик, поэтому предлагается попробовать другие способы увеличения точности сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a082c-886f-43da-9b36-57b4b06eb8e1",
   "metadata": {},
   "source": [
    "#### 1.4.7. Разработка улучшенного SegNet с добавлением механизма влияния."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43f17a-690c-4c00-aaf5-40b3f48ae30f",
   "metadata": {},
   "source": [
    "Для дальнейшего улучшения качества сегментации, одним из эффективных подходов может быть внедрение механизма внимания или \"attention\", который помогает сети фокусироваться на наиболее информативных частях входных данных. Это может особенно хорошо работать в задачах, где не все части входных данных одинаково важны для определения класса каждой точки данных.  \n",
    "\n",
    "##### Добавление Attention механизма  \n",
    "Мы можем добавить простой self-attention механизм в вашу модель. Это можно сделать путём внедрения специального attention слоя, который будет учитывать веса каждого канала в данных после каждого блока декодирования. Этот подход позволит модели уделять больше внимания важным признакам.  \n",
    "\n",
    "##### Реализация Channel Attention  \n",
    "Один из простых и эффективных способов внедрения attention — использование channel attention, который фокусируется на важности каждого канала. Простой способ реализации — использовать global average pooling для получения средних значений по каждому каналу, затем применить полносвязный слой для расчёта весов каналов, и, наконец, умножить исходные каналы на вычисленные веса.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf22264d-d039-4c82-8895-40dd6b23ac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=16):\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c) \n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class AttentionSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(AttentionSegNet1D, self).__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Внедрение модуля внимания\n",
    "        self.attention1 = ChannelAttentionModule(256)\n",
    "        self.attention2 = ChannelAttentionModule(128)\n",
    "        self.attention3 = ChannelAttentionModule(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "        \n",
    "        # Декодер\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.attention1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "        x = self.attention2(x)\n",
    "        \n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "        x = self.attention3(x)\n",
    "        \n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "       \n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = AttentionSegNet1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916047d-2d2e-445d-8c50-9c71c198fe37",
   "metadata": {},
   "source": [
    "Эта модификация позволяет улучшить способность модели к фокусировке на ключевых признаках, что может повысить точность сегментации, особенно в сложных условиях или при наличии шума в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab906acd-bda8-4094-8511-f1319fbc58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8829428987069563\n",
      "Epoch 2/10, Loss: 0.6775972660292279\n",
      "Epoch 3/10, Loss: 0.5664214093189734\n",
      "Epoch 4/10, Loss: 0.526828769352529\n",
      "Epoch 5/10, Loss: 0.4784901292099581\n",
      "Epoch 6/10, Loss: 0.45517311932204607\n",
      "Epoch 7/10, Loss: 0.42557853866707196\n",
      "Epoch 8/10, Loss: 0.4085462321708729\n",
      "Epoch 9/10, Loss: 0.3976931290870363\n",
      "Epoch 10/10, Loss: 0.3852117707009439\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = AttentionSegNet1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08fdeb67-bf2f-4963-8d63-7d243566b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.79%\n",
      "p_offset: 0.81%\n",
      "t_onset: 0.9%\n",
      "t_offset: 0.88%\n",
      "qrs_onset: 0.95%\n",
      "qrs_offset: 0.95%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb6c54-09cc-4e59-a6dd-9ea4f7ef6938",
   "metadata": {},
   "source": [
    "Можем заметить, что attention механизм действительно помог улучшить определение t волны, на данный момент она определяется с точностью примерно в 89%. P волна определяется с точностью 80%, qrs сегмент с точностью 95%. Попробуем интегрировать дополнительные алгоритмы для повышения точности сегментации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5174bc-058b-442b-98b1-f956c9761d89",
   "metadata": {},
   "source": [
    "#### 1.4.8. Разработка SegNet с добавлением механизма влияния и остаточными блоками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d31bf-6afe-4b7f-8b1e-b5864afff2e3",
   "metadata": {},
   "source": [
    "Для дальнейшего повышения эффективности модели можно рассмотреть добавление дополнительных усовершенствований, таких как использование глубоких остаточных блоков (deep residual blocks).  \n",
    "\n",
    "Остаточные блоки (Residual Blocks) могут помочь уменьшить проблему исчезающих градиентов в глубоких сетях, улучшая обучение и способность сети к извлечению сложных признаков без потери информации на промежуточных слоях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "593c78c4-55ba-4c12-bbaa-a199b4dfc3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResAttentionSegNet1D(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(ResAttentionSegNet1D, self).__init__()\n",
    "        # Энкодер\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool1 = nn.MaxPool1d(2, return_indices=True)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool2 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool3 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        self.encoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encoder_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unpool1 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, kernel_size=8, padding=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool2 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool3 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder_unpool4 = nn.MaxUnpool1d(2)\n",
    "        self.decoder_conv4 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, output_channels, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Внедрение модуля внимания\n",
    "        self.attention1 = ChannelAttentionModule(256)\n",
    "        self.attention2 = ChannelAttentionModule(128)\n",
    "        self.attention3 = ChannelAttentionModule(64)\n",
    "        \n",
    "        # Добавление остаточных блоков\n",
    "        self.res_block1 = ResidualBlock(256)\n",
    "        self.res_block2 = ResidualBlock(128)\n",
    "        self.res_block3 = ResidualBlock(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Энкодер\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, indices1 = self.encoder_pool1(x)\n",
    "        \n",
    "        x = self.encoder_conv2(x)\n",
    "        x, indices2 = self.encoder_pool2(x)\n",
    "\n",
    "        x = self.encoder_conv3(x)\n",
    "        x, indices3 = self.encoder_pool3(x)\n",
    "\n",
    "        x = self.encoder_conv4(x)\n",
    "        x, indices4 = self.encoder_pool4(x)\n",
    "\n",
    "        # Декодер с остаточными блоками\n",
    "        x = self.decoder_unpool1(x, indices4)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.res_block1(x)  # Применение остаточного блока\n",
    "        x = self.attention1(x)\n",
    "        \n",
    "        x = self.decoder_unpool2(x, indices3)\n",
    "        x = self.decoder_conv2(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.attention2(x)\n",
    "        \n",
    "        x = self.decoder_unpool3(x, indices2)\n",
    "        x = self.decoder_conv3(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.attention3(x)\n",
    "        \n",
    "        x = self.decoder_unpool4(x, indices1)\n",
    "        x = self.decoder_conv4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = ResAttentionSegNet1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac0bbbd-2506-4302-91b1-c11d196a9142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9126963269013864\n",
      "Epoch 2/10, Loss: 0.6644276843055502\n",
      "Epoch 3/10, Loss: 0.5640548729857842\n",
      "Epoch 4/10, Loss: 0.516757537985777\n",
      "Epoch 5/10, Loss: 0.4730615314918679\n",
      "Epoch 6/10, Loss: 0.4480995312333107\n",
      "Epoch 7/10, Loss: 0.43274807320399716\n",
      "Epoch 8/10, Loss: 0.41909791582397055\n",
      "Epoch 9/10, Loss: 0.40922268422006014\n",
      "Epoch 10/10, Loss: 0.3888601592995904\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = ResAttentionSegNet1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ed9196-ce63-45c5-ba57-08469792367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.83%\n",
      "p_offset: 0.83%\n",
      "t_onset: 0.84%\n",
      "t_offset: 0.85%\n",
      "qrs_onset: 0.91%\n",
      "qrs_offset: 0.89%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05704e-e8c3-49e6-a5ab-82eb582d6631",
   "metadata": {},
   "source": [
    "Можно заметить, что применение остаточных блоков ухудшили результаты метрик.\n",
    "Добавление остаточных блоков или других архитектурных компонентов не всегда гарантирует улучшение результатов, поскольку это зависит от ряда факторов:\n",
    "\n",
    "1. **Глубина сети и сложность задачи**:  \n",
    "Если модель изначально уже хорошо справлялась с задачей, дополнительная глубина может создать излишнюю сложность и привести к переобучению, особенно если данных для обучения недостаточно.  \n",
    "2. **Гиперпараметры**:  \n",
    "Возможно, что параметры оптимизатора, такие как скорость обучения, не были скорректированы для новой, более сложной модели, что могло замедлить или затруднить обучение.  \n",
    "3. **Собственный шум в данных**:  \n",
    "Если данные содержат много шума или погрешностей, более сложная модель может быть более чувствительна к этим ошибкам и переобучаться на них.  \n",
    "4. **Совместимость с другими компонентами**:  \n",
    "Остаточные блоки могут нарушить взаимодействие с другими частями модели, например, с механизмами внимания. Это приводит к проблемам в передаче признаков между слоями.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cdbc25-3eb5-4072-a87f-3445d0e5e0bc",
   "metadata": {},
   "source": [
    "Мы можем запомнить нашу модель AttentionSegNet1D (которая на данный момент показывает наилучший результат) для дальнейших экспериментов, и попробовать другие известные архитектуры нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bbb4f-7f99-49fe-9f21-8dedde5e5d2d",
   "metadata": {},
   "source": [
    "#### 1.4.9. Разработка DeepLabV3Plus1D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce18ce2-a735-4c0b-9f75-d452ba6bc305",
   "metadata": {},
   "source": [
    "Для адаптации DeepLabV3+ под нашу задачу с одномерными сигналами, необходимо модифицировать архитектуру так, чтобы она подходила для обработки одномерных данных, вместо двумерных, как в стандартной версии, используемой для изображений. Это потребует замены всех двумерных сверточных операций на одномерные аналоги.  \n",
    "\n",
    "Основные компоненты модификации DeepLabV3+:  \n",
    "1. Одномерные сверточные слои вместо двумерных.  \n",
    "2. Одномерный Atrous Spatial Pyramid Pooling (ASPP), который адаптируется к одномерным данным.  \n",
    "3. Декодер, который адаптирован для восстановления одномерных данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d5fd7c-f245-435e-8aa6-35dac4d39816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 4, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x = torch.cat((x1, x6, x12, x18), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1D, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(64, 256)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)  # Upsample to match input size\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10a7c7-f215-45a4-b1c9-60971351a92d",
   "metadata": {},
   "source": [
    "В коде данной модели используются основные элементы:  \n",
    "**ASPP: Atrous Spatial Pyramid Pooling** адаптирован для 1D. Это позволяет сети захватывать контекст на разных масштабах.  \n",
    "**Декодер**: Простой декодер используется для восстановления размера до исходного, используя интерполяцию для увеличения размера выхода ASPP до размера входного сигнала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02efa98a-40fc-40d0-82da-66a7146de362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5216100996771416\n",
      "Epoch 2/10, Loss: 0.43652423863093576\n",
      "Epoch 3/10, Loss: 0.4058155930274493\n",
      "Epoch 4/10, Loss: 0.38357892342202077\n",
      "Epoch 5/10, Loss: 0.36650029105412496\n",
      "Epoch 6/10, Loss: 0.3555025284650264\n",
      "Epoch 7/10, Loss: 0.3475207235518988\n",
      "Epoch 8/10, Loss: 0.33776968819173897\n",
      "Epoch 9/10, Loss: 0.3327000017773795\n",
      "Epoch 10/10, Loss: 0.33076096045506465\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeepLabV3Plus1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1246618-777d-4a0a-8e9d-1eba378dde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.78%\n",
      "p_offset: 0.8%\n",
      "t_onset: 0.83%\n",
      "t_offset: 0.83%\n",
      "qrs_onset: 0.95%\n",
      "qrs_offset: 0.94%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4daf93-2e4f-4e25-b8cc-3f94980edf43",
   "metadata": {},
   "source": [
    "Сходу DeepLabV3 показал неплохой потенциал. Можно попробовать увеличить глубину сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9ffe9-5963-41f2-9478-9e41126a9aa9",
   "metadata": {},
   "source": [
    "#### 1.4.10. Разработка DeepLabV3Plus1D с увеличинной глубиной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacaf69-df51-49fc-9015-df051ebe7d3d",
   "metadata": {},
   "source": [
    "Чтобы увеличить глубину модели, можно добавить больше сверточных слоев в features и decoder, а также расширить сам модуль ASPP. Однако важно сбалансировать увеличение глубины с вычислительной эффективностью и избежать излишнего усложнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105c0f6e-cfce-4294-9068-c59dbf18915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DDeeper(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DDeeper, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DDeeper(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7aee0-c218-409f-8010-b06030088f65",
   "metadata": {},
   "source": [
    "##### Основные изменения:  \n",
    "**ASPP**: Добавлен еще один atrous_block для улавливания еще более широкого контекста.  \n",
    "**Features**: Увеличена глубина путем добавления нескольких дополнительных сверточных слоев.  \n",
    "**Decoder**: Используется простой декодер, но он обрабатывает выход более глубокой сети.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7941522f-9d33-4923-a5fb-582c3f1402df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4955700777180783\n",
      "Epoch 2/10, Loss: 0.4043426334664419\n",
      "Epoch 3/10, Loss: 0.37184404843039326\n",
      "Epoch 4/10, Loss: 0.3540850069325466\n",
      "Epoch 5/10, Loss: 0.3397613818479049\n",
      "Epoch 6/10, Loss: 0.3222640781336791\n",
      "Epoch 7/10, Loss: 0.31029119511896913\n",
      "Epoch 8/10, Loss: 0.2984010766852986\n",
      "Epoch 9/10, Loss: 0.2897985517591625\n",
      "Epoch 10/10, Loss: 0.28214107478013284\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeepLabV3Plus1DDeeper(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76cf19e1-8ffa-45eb-898c-5df4fe7d45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.84%\n",
      "p_offset: 0.84%\n",
      "t_onset: 0.87%\n",
      "t_offset: 0.87%\n",
      "qrs_onset: 0.97%\n",
      "qrs_offset: 0.97%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01275f-df22-4002-ba02-9a3a03f2f56c",
   "metadata": {},
   "source": [
    "Отлично! С увеличением глубины сети, метрики улучшили свои показатели. Теперь p-волна определяется верно в 84% случаев, t-волна определяется верно в 87% случаев, а qrs-сегмент в 97% случаев. Можно попробовать еще увеличить глубину сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926e2e-1467-400f-8430-4b6a227f7dda",
   "metadata": {},
   "source": [
    "#### 1.4.11. Разработка DeepLabV3Plus1D с увеличинной глубиной V2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d12f3-4070-4fbf-992f-71642689bfd1",
   "metadata": {},
   "source": [
    "В коде ниже приведена модель с еще большим количеством внутренних сверточных слоев в сравнении с моделью выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aecdd2a-3bc9-4c67-9998-37b25b66e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeeperV2DeepLabV3Plus1D(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeeperV2DeepLabV3Plus1D, self).__init__()\n",
    "        \n",
    "        # Глубокая часть features\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Расширенный ASPP\n",
    "        self.aspp = ASPP(1024, 512)\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeeperV2DeepLabV3Plus1D(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ac196a-f3c0-44a0-b6ab-99e05dd467e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6515575771207933\n",
      "Epoch 2/10, Loss: 0.510515233622743\n",
      "Epoch 3/10, Loss: 0.46010751838420894\n",
      "Epoch 4/10, Loss: 0.43143183486415193\n",
      "Epoch 5/10, Loss: 0.4098713038029609\n",
      "Epoch 6/10, Loss: 0.3902985785978955\n",
      "Epoch 7/10, Loss: 0.37068793022787416\n",
      "Epoch 8/10, Loss: 0.359357797383488\n",
      "Epoch 9/10, Loss: 0.34757704336147804\n",
      "Epoch 10/10, Loss: 0.3353833139620044\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeeperV2DeepLabV3Plus1D(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c7c0f0-0218-41de-a981-8b2f42ec69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.79%\n",
      "p_offset: 0.83%\n",
      "t_onset: 0.88%\n",
      "t_offset: 0.87%\n",
      "qrs_onset: 0.96%\n",
      "qrs_offset: 0.96%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcaa6b-aecc-490e-ad79-65d61d439b57",
   "metadata": {},
   "source": [
    "Как и ожидалось, еще большее увеличение глубины сети не привело к положительным результатам. Причин этому может быть множество: \n",
    "\n",
    "\n",
    "**Переобучение**: Более глубокая модель может быть более склонна к переобучению на данных обучения, особенно если обучающий набор данных невелик. Проверка на переобучение может помочь выявить проблему.  \n",
    "**Недостаточно данных:** Глубокие модели обычно требуют большого количества данных для эффективного обучения. Если данных недостаточно, модель не сможет учиться на всех уровнях глубины.  \n",
    "**Избыточная сложность:** Глубокие сети могут стать слишком сложными для задачи, в результате чего они не могут правильно учить необходимые признаки.\n",
    "Проблемы с обучением: Увеличение глубины может затруднить обучение, приводя к затуханию градиентов или другим проблемам. Добавление слоев нормализации, изменения функции активации или уменьшение шага обучения может улучшить стабильность.  \n",
    "**Время тренировки:** Более глубокая модель может потребовать больше времени для конвергенции. Возможно, стоит увеличить количество эпох или проверить кривые обучения, чтобы понять, достигается ли стабильная точка.  \n",
    "\n",
    "**Поэтому есть смысл вернуться к предыдущей версии и продолжить работу над ней.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a638578-db14-4103-830a-f097bccdf25d",
   "metadata": {},
   "source": [
    "#### 1.4.12. Разработка DeepLabV3Plus1D с применением регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14afbc-6bb6-4362-bf31-3b76acd7a895",
   "metadata": {},
   "source": [
    "В коде модели ниже попробуем применить алгоритм регуляризации. Чтобы избежать переобучения, добавим слой Dropout в декодер. Это помогает случайно отключать некоторые нейроны во время тренировки, что повышает обобщающую способность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ee830da-3d40-45ad-801f-2a6568389181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DWithDropout(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DWithDropout, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DWithDropout(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8783872c-3071-4b01-a2a3-b4c447aa33de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5073283406627642\n",
      "Epoch 2/10, Loss: 0.4183159870180217\n",
      "Epoch 3/10, Loss: 0.37850316894518865\n",
      "Epoch 4/10, Loss: 0.36429170761015506\n",
      "Epoch 5/10, Loss: 0.3447778277195893\n",
      "Epoch 6/10, Loss: 0.33459307954876455\n",
      "Epoch 7/10, Loss: 0.32322686291360236\n",
      "Epoch 8/10, Loss: 0.3092404562834795\n",
      "Epoch 9/10, Loss: 0.30152198256223234\n",
      "Epoch 10/10, Loss: 0.2921982475302436\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeepLabV3Plus1DWithDropout(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f98e8945-2dc3-4b71-b07f-a010eb45c549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.82%\n",
      "p_offset: 0.82%\n",
      "t_onset: 0.88%\n",
      "t_offset: 0.87%\n",
      "qrs_onset: 0.96%\n",
      "qrs_offset: 0.96%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9c631-fd7e-4189-98d2-65d484ecbb8d",
   "metadata": {},
   "source": [
    "Можно сказать, что при применении Dropout метрики несколько ухудшились, возможно, это произошло по одной из нескольких причин:  \n",
    "\n",
    "**1. Недостаточное количество данных:** Если тренировочный набор данных невелик, использование Dropout может привести к потере важных признаков, необходимых для обобщения. Это особенно заметно, когда Dropout слишком высок или применяется к большим слоям.  \n",
    "**2. Слишком высокое значение Dropout:** Если коэффициент Dropout слишком высок, модель может потерять слишком много нейронов в процессе тренировки, что приведет к недостаточной производительности.  \n",
    "**3. Изменения в структуре нейронной сети:** При использовании Dropout меняется структура нейронной сети, так как случайным образом отключаются нейроны. Если отключенные нейроны несут существенную информацию, модель не сможет должным образом обучиться на ограниченном наборе данных.  \n",
    "**4. Недостаточное время тренировки:** Dropout обычно требует большего времени для тренировки, чтобы модель могла обобщить признаки из данных. Если модель обучается недостаточно долго, она может не достичь своего полного потенциала.  \n",
    "**Чтобы минимизировать негативный эффект от Dropout, можно использовать более низкие значения коэффициента (например, 0.2 - 0.3) или применять его только к верхним слоям сети.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf857-7368-464d-b79d-01625108e8a9",
   "metadata": {},
   "source": [
    "#### 1.4.13. Разработка DeepLabV3Plus1D с применением регуляризации на верхнем слое."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb473ff2-fabf-4f41-b73b-b142893e72c4",
   "metadata": {},
   "source": [
    "В данном коде происходят эксперименты с различным местоположением Dropout, а также со значением регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db7d8cec-690d-489c-a673-4ae0e831fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv1d(in_channels, out_channels, 1, padding=0)\n",
    "        self.atrous_block6 = nn.Conv1d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv1d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv1d(in_channels, out_channels, 3, padding=18, dilation=18)\n",
    "        self.atrous_block24 = nn.Conv1d(in_channels, out_channels, 3, padding=24, dilation=24)\n",
    "        self.conv_out = nn.Conv1d(out_channels * 5, out_channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.atrous_block1(x)\n",
    "        x6 = self.atrous_block6(x)\n",
    "        x12 = self.atrous_block12(x)\n",
    "        x18 = self.atrous_block18(x)\n",
    "        x24 = self.atrous_block24(x)\n",
    "        x = torch.cat((x1, x6, x12, x18, x24), dim=1)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3Plus1DWithDropoutExp(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DWithDropoutExp, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_channels = 12  # количество каналов входных данных\n",
    "output_channels = 4  # количество каналов выходных данных (классы)\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DWithDropoutExp(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6313ff0-21b7-4bab-a245-850c71bd2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5175894674929705\n",
      "Epoch 2/10, Loss: 0.41570269069694854\n",
      "Epoch 3/10, Loss: 0.37689673474856783\n",
      "Epoch 4/10, Loss: 0.3630341315134005\n",
      "Epoch 5/10, Loss: 0.34501567981266357\n",
      "Epoch 6/10, Loss: 0.33349452070988617\n",
      "Epoch 7/10, Loss: 0.31776258102678634\n",
      "Epoch 8/10, Loss: 0.30863238556625006\n",
      "Epoch 9/10, Loss: 0.3008251528364497\n",
      "Epoch 10/10, Loss: 0.29363260171436645\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeepLabV3Plus1DWithDropout(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d17f6d-1c1a-4a8a-bf7c-e9455cc383b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.83%\n",
      "p_offset: 0.83%\n",
      "t_onset: 0.84%\n",
      "t_offset: 0.84%\n",
      "qrs_onset: 0.95%\n",
      "qrs_offset: 0.95%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991226df-facb-4018-adbf-092f2b8ead85",
   "metadata": {},
   "source": [
    "После различных экспериментов с местоположением Dropout и значением коэффициента регуляризации, так и не получилось найти оптимальные значения для Dropout, чтобы повысить точность сегментации. Давайте аналогично с SegNet попробуем применить механизм внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e617e1-57cb-4a97-b3cc-002688641bd8",
   "metadata": {},
   "source": [
    "#### 1.4.14. Разработка DeepLabV3Plus1D с применением механизма внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08432f32-4705-46a8-a2c9-4284b98292af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5000])\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# Внедрение модуля внимания в DeepLabV3+ модель\n",
    "class DeepLabV3Plus1DAttention(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(DeepLabV3Plus1DAttention, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(64),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(128),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(256),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1)\n",
    "        )\n",
    "        self.aspp = ASPP(256, 512)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            ChannelAttention(256),\n",
    "            nn.Conv1d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.aspp(x)\n",
    "        x = F.interpolate(x, size=5000, mode='linear', align_corners=False)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model = DeepLabV3Plus1DAttention(input_channels, output_channels)\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(2, 12, 5000)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4f357d4-282a-41ce-a673-b9d494c74706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.5096973515563197\n",
      "Epoch 2/5, Loss: 0.4027113329570789\n",
      "Epoch 3/5, Loss: 0.3721889052781966\n",
      "Epoch 4/5, Loss: 0.3489404898378756\n",
      "Epoch 5/5, Loss: 0.3320257574223079\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "# Создание модели\n",
    "model = DeepLabV3Plus1DAttention(num_channels, num_classes).to(device)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37743e08-a192-4fd8-a493-80728c195caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.84%\n",
      "p_offset: 0.82%\n",
      "t_onset: 0.85%\n",
      "t_offset: 0.85%\n",
      "qrs_onset: 0.95%\n",
      "qrs_offset: 0.95%\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {round(validation_metrics, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea2290-7013-445c-b49c-75193c1f60bd",
   "metadata": {},
   "source": [
    "Механзим внимания к DeepLabV3 не дал ожидаемых результатов, поэтому есть смысл запомнить модель из раздела DeepLab с названием DeepLabV3Plus1DDeeper для дальнейших экспериментов, так как эта модель показала неплохие результаты на данный момент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565ffaf-c02b-4b89-a0e0-527b91dd2e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c52fbc-a31c-4335-9159-88dd84ecf8ef",
   "metadata": {},
   "source": [
    "### 1.5 Работа и анализ UNet от ученых ННГУ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d2f0-60c6-4118-8e05-26f477d6463e",
   "metadata": {},
   "source": [
    "Объявим модель, которую разработали ученые ННГУ и проверим точность на ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c933f9b9-1037-4358-80b4-e65597748c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNetConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ks, p):\n",
    "        in_channels = int(in_channels)\n",
    "        out_channels = int(out_channels)\n",
    "        super(UNetConv, self).__init__()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=ks, padding=ks//2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(p=p),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=ks, padding=ks//2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self._model(X)\n",
    "    \n",
    "    \n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ks, p):\n",
    "        super(UNetDown, self).__init__()\n",
    "        self._model = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            UNetConv(in_channels, out_channels, ks, p)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self._model(X)\n",
    "    \n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, in_channels_skip, out_channels, ks, p):\n",
    "        super(UNetUp, self).__init__()\n",
    "        in_channels = int(in_channels)\n",
    "        in_channels_skip = int(in_channels_skip)\n",
    "        out_channels = int(out_channels)\n",
    "        \n",
    "        self._up = nn.ConvTranspose1d(in_channels, in_channels, \n",
    "                                      kernel_size=ks - 1,\n",
    "                                      stride=2, \n",
    "                                      padding=(ks - 1) // 2 - 1)\n",
    "        self._model = UNetConv(in_channels + in_channels_skip, out_channels, ks, p)\n",
    "    \n",
    "    def forward(self, X_skip, X):\n",
    "        X = self._up(X)  \n",
    "        diff = X_skip.size()[2] - X.size()[2]\n",
    "        X = F.pad(X, (diff // 2, diff - diff // 2))  \n",
    "        return self._model(torch.cat([X_skip, X], dim=1))\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, channels_coeff=1, q=2, kernel_size=23, p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.q = q\n",
    "        self.p = p\n",
    "        self._input = UNetConv(q ** 0 * self.in_channels, q ** 1 * in_channels, kernel_size, p)\n",
    "        self._down1 = UNetDown(q ** 1 * self.in_channels, q ** 2 * self.in_channels, kernel_size, p)\n",
    "        self._down2 = UNetDown(q ** 2 * self.in_channels, q ** 3 * self.in_channels, kernel_size, p)\n",
    "        self._down3 = UNetDown(q ** 3 * self.in_channels, q ** 4 * self.in_channels, kernel_size, p)\n",
    "        self._down4 = UNetDown(q ** 4 * self.in_channels, q ** 5 * self.in_channels, kernel_size, p)\n",
    "        self._down5 = UNetDown(q ** 5 * self.in_channels, q ** 6 * self.in_channels, kernel_size, p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self._input(x)\n",
    "        x2 = self._down1(x1)\n",
    "        x3 = self._down2(x2)\n",
    "        x4 = self._down3(x3)\n",
    "        x5 = self._down4(x4)\n",
    "        print(\"end of encoder\")\n",
    "        return x1, x2, x3, x4, x5, self._down5(x5)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, num_classes, reshape=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        print(\"we are here\")\n",
    "        self.encoder = encoder\n",
    "        self._up1 = UNetUp(encoder.q ** 6 * encoder.in_channels, \n",
    "                           encoder.q ** 5 *encoder.in_channels, \n",
    "                           encoder.q ** 5 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "\n",
    "        self._up2 = UNetUp(encoder.q ** 5 * encoder.in_channels, \n",
    "                           encoder.q ** 4 *encoder.in_channels, \n",
    "                           encoder.q ** 4 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._up3 = UNetUp(encoder.q ** 4 * encoder.in_channels, \n",
    "                           encoder.q ** 3 *encoder.in_channels, \n",
    "                           encoder.q ** 3 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._up4 = UNetUp(encoder.q ** 3 * encoder.in_channels, \n",
    "                           encoder.q ** 2 *encoder.in_channels,\n",
    "                           encoder.q ** 2 * encoder.in_channels, \n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "\n",
    "        self._up5 = UNetUp(encoder.q ** 2 * encoder.in_channels, \n",
    "                           encoder.q ** 1 *encoder.in_channels,\n",
    "                           num_classes,\n",
    "                           encoder.kernel_size,\n",
    "                           encoder.p)\n",
    "        \n",
    "        self._output = nn.Conv1d(num_classes, num_classes, kernel_size=1)\n",
    "        self.reshape = reshape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4, x5, x):\n",
    "        print(\"start of decoder\")\n",
    "        batch_size = len(x)\n",
    "        x = self._up1(x5, x)\n",
    "        x = self._up2(x4, x)\n",
    "        x = self._up3(x3, x)\n",
    "        x = self._up4(x2, x)\n",
    "        x = self._up5(x1, x)\n",
    "        x = self._output(x)\n",
    "        if self.reshape:\n",
    "            x = x.reshape(batch_size, 4, 12, -1)\n",
    "        print(\"end of decoder\")    \n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetNNGU(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super(UNetNNGU, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5, x = self.encoder(x) \n",
    "        print(type(self.decoder))\n",
    "        a = self.decoder(x1, x2, x3, x4, x5, x)\n",
    "        print(type(a))\n",
    "        return a\n",
    "    \n",
    "    def log(self):\n",
    "        return f\"UNet(in_channels={self.encoder.in_channels}, num_classes={self.decoder.num_classes}, \" \\\n",
    "                    f\"q={self.encoder.q}, reshape={self.decoder.reshape}, kernel_size={self.encoder.kernel_size})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e8109a-a873-4216-9dba-f3fc063e9ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      4\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m(num_channels, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m, q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      7\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(encoder, num_classes)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m UNetNNGU(encoder, decoder)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_channels = 12\n",
    "length = 5000\n",
    "num_classes = 4\n",
    "\n",
    "encoder = Encoder(num_channels, kernel_size=23, q=1.2, p=0.1)\n",
    "decoder = Decoder(encoder, num_classes)\n",
    "model = UNetNNGU(encoder, decoder).to(device)\n",
    "\n",
    "# Подготовим случайные входные данные\n",
    "inputs = torch.randn(batch_size, num_channels, length)\n",
    "# Прогоним через сеть\n",
    "outputs = model(inputs.to(device))\n",
    "\n",
    "# Проверим размерность выхода\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d38c1-7899-4490-a1b4-f0dd3da4e18b",
   "metadata": {},
   "source": [
    "Натренируем модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d8a6266-30d9-478b-b500-167b420e7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of encoder\n",
      "<class 'int'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m UNetNNGU(encoder, num_classes)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Тренировка модели\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     10\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mto(device), targets)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[108], line 139\u001b[0m, in \u001b[0;36mUNetNNGU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m x1, x2, x3, x4, x5, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x) \n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder))\n\u001b[0;32m--> 139\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a))\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Создание модели\n",
    "model = UNetNNGU(encoder, num_classes)\n",
    "\n",
    "# Тренировка модели\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da361a26-8fe8-41af-8560-eb12671ea018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
