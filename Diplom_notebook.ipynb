{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "950b3649-1d36-494d-a552-6334268d0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import Module\n",
    "from typing import Literal\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "363b040a-50e5-44d0-8066-a5733ef70f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationMetric:\n",
    "    def __init__(self,\n",
    "                 monitor: Literal['p', 'qrs', 't', 'all'] = 'all',\n",
    "                 orientation_type: Literal['onset', 'offset', 'all'] = 'all',\n",
    "                 return_type: Literal['precision', 'recall', 'f1', 'confusion_matrix'] = 'confusion_matrix',\n",
    "                 samples=75):\n",
    "\n",
    "        assert monitor in ['p', 'qrs', 't', 'all']\n",
    "        assert orientation_type in ['onset', 'offset', 'all']\n",
    "        assert return_type in ['precision', 'recall', 'f1', 'confusion_matrix']\n",
    "\n",
    "        self.samples = samples\n",
    "        self.monitor = monitor\n",
    "        self.orientation_type = orientation_type\n",
    "        self.return_type = return_type\n",
    "        \n",
    "        self.metric_to_func = {'precision': self.__precision,\n",
    "                               'recall': self.__recall,\n",
    "                               'f1': self.__f1}\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        assert len(y_pred.shape) == 2\n",
    "        \n",
    "        matrix = np.zeros((2, 2), dtype=int)\n",
    "        monitors = ['p', 'qrs', 't'] if self.monitor == 'all' else [self.monitor]\n",
    "        orientations = ['onset', 'offset'] if self.orientation_type == 'all' else [self.orientation_type]\n",
    "        for wave in monitors:\n",
    "            for orientation in orientations:\n",
    "                matrix += self.__handle(y_pred, y_true, wave, orientation)\n",
    "        \n",
    "        if self.return_type == 'confusion_matrix':\n",
    "            return matrix\n",
    "\n",
    "        return self.metric_to_func[self.return_type](matrix[0, 1], matrix[1, 0], matrix[1, 1])\n",
    "\n",
    "    def __handle(self, y_pred, y_true, wave, orientation) -> tuple[int, int, int]:\n",
    "        \n",
    "        index = ['p', 'qrs', 't'].index(wave) + 1\n",
    "        orientation = 2 * ['offset', 'onset'].index(orientation) - 1\n",
    "        y_pred[y_true == 4] = 0\n",
    "\n",
    "        y_true, y_pred = (y_true == index), (y_pred == index)\n",
    "\n",
    "        wave_true = np.logical_and(np.roll(y_true, orientation) != 1, y_true == 1).astype(int)\n",
    "        wave_pred = np.logical_and(np.roll(y_pred, orientation) != 1, y_pred == 1).astype(int)\n",
    "\n",
    "        true_batch, true_indexes = np.where(wave_true == 1)\n",
    "        \n",
    "        tp = fn = 0\n",
    "        \n",
    "        for batch, x in zip(true_batch, true_indexes):\n",
    "            wave = wave_pred[batch][x - self.samples // 2: x + self.samples // 2]\n",
    "            if wave.sum():\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "            wave[:] = -1\n",
    "        \n",
    "        fp = (wave_pred[:, self.samples:-self.samples] == 1).sum()\n",
    "        return np.array([[0, fp], [fn, tp]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def __precision(fp, fn, tp):\n",
    "        if fp + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __recall(fp, fn, tp):\n",
    "        if fn + tp == 0:\n",
    "            return 1\n",
    "        return tp / (tp + fn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __f1(fp, fn, tp):\n",
    "        precision = SegmentationMetric.__precision(fp, fn, tp)\n",
    "        recall = SegmentationMetric.__recall(fp, fn, tp)\n",
    "        if precision + recall == 0:\n",
    "            return 1\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.monitor}_{self.orientation_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ffa1a9e-6378-4b50-84dc-a912267a40df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label.size = torch.Size([2, 12, 5000])\n",
      "signal.size = torch.Size([2, 12, 5000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data_folder, label_folder, max_length=5000):\n",
    "        self.data_files = glob.glob(f'{data_folder}/*.npy')\n",
    "        self.label_files = glob.glob(f'{label_folder}/*.npy')\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_files[idx])\n",
    "        labels = np.load(self.label_files[idx])\n",
    "\n",
    "        # Обрезка данных и меток, если длина превышает max_length\n",
    "        if data.shape[1] > self.max_length:\n",
    "            data = data[:, :self.max_length]\n",
    "            labels = labels[:, :self.max_length]\n",
    "\n",
    "        return torch.from_numpy(data).float(), torch.from_numpy(labels).long()\n",
    "\n",
    "# Использование DataLoader\n",
    "data_folder = '/home/meshalkin/Diplom/ludb/data/signals'\n",
    "label_folder = '/home/meshalkin/Diplom/ludb/data/masks'\n",
    "dataset = SignalDataset(data_folder, label_folder)\n",
    "\n",
    "# Например, 20% для валидации\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "# Разделите датасет на тренировочный и валидационный\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Создайте DataLoader для обоих датасетов\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)  # shuffle обычно не нужен для валидации\n",
    "\n",
    "for i, (signal, label) in enumerate(data_loader):\n",
    "    print(f\"label.size = {label.shape}\")\n",
    "    print(f\"signal.size = {signal.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db80ec24-4b2d-407b-89b2-f79cb945a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 4, 5000])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesSegmentationNet(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes, length):\n",
    "        super(TimeSeriesSegmentationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, num_channels * 8, kernel_size=3, padding=1, groups=num_channels)\n",
    "        self.conv2 = nn.Conv1d(num_channels * 8, num_channels * 16, kernel_size=3, padding=1, groups=num_channels)\n",
    "        self.conv3 = nn.Conv1d(num_channels * 16, num_channels * num_classes, kernel_size=3, padding=1, groups=num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1, num_channels, num_classes)  # изменение формы для выравнивания по каналам и классам\n",
    "        x = x.permute(0, 2, 3, 1)  # Перестановка для получения [batch_size, num_channels, length, num_classes]\n",
    "        return x\n",
    "        \n",
    "# Параметры модели\n",
    "num_channels = 12\n",
    "num_classes = 4\n",
    "length = 5000\n",
    "batch_size = 2\n",
    "\n",
    "# Создание и тестирование модели\n",
    "model = TimeSeriesSegmentationNet(num_channels, num_classes, length)\n",
    "x = torch.randn(batch_size, num_channels, length)\n",
    "output = model(x)\n",
    "print(output.shape)  # Должно быть torch.Size([batch_size, num_channels, length])\n",
    "print(output.dtype)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "199223ef-c246-4df2-8394-4676d41714df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3861336568733313\n",
      "Epoch 2/10, Loss: 1.3858669311195224\n",
      "Epoch 3/10, Loss: 1.3858243532769092\n",
      "Epoch 4/10, Loss: 1.3858045177026228\n",
      "Epoch 5/10, Loss: 1.3858002621632117\n",
      "Epoch 6/10, Loss: 1.385805590973272\n",
      "Epoch 7/10, Loss: 1.3858186258124066\n",
      "Epoch 8/10, Loss: 1.385849343104796\n",
      "Epoch 9/10, Loss: 1.3859313339382022\n",
      "Epoch 10/10, Loss: 1.3861123729835858\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, num_epochs=10, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)  # [batch_size, num_channels, length, num_classes]\n",
    "            outputs = outputs.permute(0, 3, 1, 2)  # [batch, num_classes, num_channels, length]\n",
    "            \n",
    "            # labels должны быть в формате [batch_size, num_channels, length]\n",
    "            # Перестраиваем labels для соответствия ожидаемой размерности CrossEntropyLoss\n",
    "            labels = labels.view(-1)  # Превращаем в одномерный массив\n",
    "\n",
    "            # Так как CrossEntropyLoss ожидает вход в размерности [N, C, d1, d2, ...], где C - количество классов,\n",
    "            # мы должны также изменить размер outputs\n",
    "            outputs = outputs.view(-1, num_classes)  # [N * d1 * d2, C]\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader.dataset)}')\n",
    "    \n",
    "    print('Training complete.')\n",
    "train_model(model, train_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "041957bc-c436-47d4-8306-22cba75520ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([153, 12, 5000])\n",
      "torch.Size([153, 12, 5000])\n"
     ]
    }
   ],
   "source": [
    "metric = SegmentationMetric('all', 'all', 'f1', 153)\n",
    "def collect_outputs(model, validation_loader, device):\n",
    "    model.eval()  # Переключаем модель в режим валидации\n",
    "    all_predictions = []\n",
    "    all_inputs = []\n",
    "    with torch.no_grad():  # Отключаем градиенты для валидации\n",
    "        for i, (signal, label) in enumerate(validation_loader):\n",
    "            inputs = signal.to(device)\n",
    "            outputs = model(inputs)  # [batch_size, num_channels, length, num_classes]\n",
    "            # Получаем наибольшие вероятности и соответствующие индексы (классы) вдоль размерности num_classes\n",
    "            probabilities, predicted_classes = torch.max(outputs, dim=2)\n",
    "            # Для сохранения структуры [batch_size, num_channels, num_classes], где num_classes показывает наиболее вероятный класс\n",
    "            all_predictions.append(predicted_classes.cpu())\n",
    "            all_inputs.append(inputs.cpu())\n",
    "    \n",
    "    # Собираем все результаты из всех батчей в один тензор\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_inputs = torch.cat(all_inputs, dim=0)\n",
    "    return all_predictions, all_inputs\n",
    "\n",
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "predicted_classes, all_inputs = collect_outputs(model, val_loader, device)\n",
    "print(predicted_classes.shape)  # Ожидаемый результат: [batch_size, num_channels, length]\n",
    "print(all_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da5e8403-3764-4a0a-b251-ba6be897cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current f1 score:\n",
      "p_onset: 0.035103539923211344%\n",
      "p_offset: 0.02212866333925467%\n",
      "t_onset: 0.024143800359484324%\n",
      "t_offset: 0.024190360265371358%\n",
      "qrs_onset: 0.030280805007428777%\n",
      "qrs_offset: 0.03040188273220351%\n"
     ]
    }
   ],
   "source": [
    "# ____target f1-score___\n",
    "#p_onset: 97.487%\n",
    "#p_offset: 97.639%\n",
    "#t_onset: 96.464%\n",
    "#t_offset: 96.402%\n",
    "#qrs_onset: 99.949%\n",
    "#qrs_offset: 99.949%\n",
    "\n",
    "def validate_model_with_metrics(model, validation_loader, metric, device):\n",
    "    model.eval()\n",
    "    all_metrics = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Переводим outputs в формат [batch_size, length, num_channels], где num_channels - это наши классы\n",
    "            outputs = torch.argmax(outputs, dim=2).cpu().numpy()  # получаем наиболее вероятные классы\n",
    "            labels = labels.cpu().numpy()\n",
    "            # Подсчет метрик для каждого батча\n",
    "            batch_metrics = metric(outputs[0], labels[0])\n",
    "            all_metrics.append(batch_metrics)\n",
    "    \n",
    "    # Средний расчет всех метрик по всем батчам\n",
    "    if metric.return_type == 'confusion_matrix':\n",
    "        final_metrics = np.sum(all_metrics, axis=0)\n",
    "    else:\n",
    "        final_metrics = np.mean(all_metrics, axis=0)\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "# Пример использования:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "monitor= ['p', 't', 'qrs']\n",
    "orintation_type = ['onset', 'offset']\n",
    "print(\"Current f1 score:\")\n",
    "for m in monitor:\n",
    "    for o in orintation_type:   \n",
    "        metric = SegmentationMetric(monitor=m, orientation_type=o, return_type='f1', samples=75)\n",
    "        validation_metrics = validate_model_with_metrics(model, val_loader, metric, device)\n",
    "        print(f\"{m}_{o}: {validation_metrics}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
